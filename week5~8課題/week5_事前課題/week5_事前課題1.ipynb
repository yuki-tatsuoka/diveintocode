{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】train_test_splitのスクラッチ\n",
    "スクラッチの練習として、scikit-learnのtrain_test_splitを自作してみます。以下の雛形をベースとして関数を完成させてください。\n",
    "\n",
    "\n",
    "sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "なお、作成した関数がscikit-learnのtrain_test_splitと同じ動作をしているか必ず確認をするようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def scratch_train_test_split(X, y, train_size=0.8):\n",
    "    \n",
    "    # サイズ定義(roundは浮動小数点の後半が悪さをするので完全に切り捨てる)\n",
    "    test_size = round(1 - train_size, 1)\n",
    "    \n",
    "    #サイズ変換(80%, 20%)  \n",
    "    X_train_shape = int(X.shape[0] * train_size)\n",
    "    X_test_shape = int(X.shape[0] * test_size) \n",
    "    y_train_shape = int(y.shape[0] * train_size)\n",
    "    y_test_shape = int(y.shape[0] * test_size)\n",
    "    \n",
    "    #X,yにサイズを適用させる\n",
    "    X_train = X[:X_train_shape]\n",
    "    X_test = X[:X_test_shape]\n",
    "    y_train = y[:y_train_shape]\n",
    "    y_test =  y[:y_test_shape]\n",
    "    \n",
    "    # シャッフル\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(X_train)\n",
    "    np.random.shuffle(y_train)\n",
    "    np.random.shuffle(X_test)\n",
    "    np.random.shuffle(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4)\n",
      "(30, 4)\n",
      "(120,)\n",
      "(30,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.9, 3.1, 1.5, 0.1],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.9, 3. , 5.1, 1.8],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.9, 3.2, 5.7, 2.3]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape) \n",
    "\n",
    "# １つだけ中身を見てみる\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】 分類問題を解くコードの作成\n",
    "下記3種類の手法で3種類のデータセットを学習・推定するコードを作成してください。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類問題\n",
    "分類は3種類の手法をスクラッチします。\n",
    "\n",
    "\n",
    "ロジスティック回帰\n",
    "SVM\n",
    "決定木\n",
    "\n",
    "ロジスティック回帰はscikit-learnにおいてLogisticRegressionクラスとSGDClassifierクラスの2種類から使用できます。ここでは勾配降下法を用いて計算するSGDClassifierクラスを利用してください。引数でloss=\"log\"とすることでロジスティック回帰の計算になります。\n",
    "\n",
    "\n",
    "sklearn.linear_model.SGDClassifier — scikit-learn 0.21.3 documentation\n",
    "sklearn.svm.SVC — scikit-learn 0.21.3 documentation\n",
    "sklearn.tree.DecisionTreeClassifier — scikit-learn 0.21.3 documentation\n",
    "\n",
    "データセットは3種類用意します。\n",
    "\n",
    "\n",
    "1つ目は事前学習期間同様にirisデータセットです。\n",
    "\n",
    "\n",
    "sklearn.datasets.load_iris — scikit-learn 0.20.2 documentation\n",
    "\n",
    "\n",
    "2値分類としたいため、以下の2つの目的変数のみ利用します。特徴量は4種類全て使います。\n",
    "\n",
    "\n",
    "virgicolorとvirginica\n",
    "\n",
    "残り2つは特徴量が2つのデータセットを人工的に用意します。以下のコードで説明変数X,目的変数yが作成可能です。「シンプルデータセット1」「シンプルデータセット2」とします。特徴量が2つであるため可視化が容易です。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. SGDClassifierのロジスティック回帰\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# irisをダウンロード（２値分類のため、virgicolorとvirginicaのデータのみ選択するう）\n",
    "iris = load_iris()\n",
    "X = iris.data[50:150]\n",
    "y = iris.target[50:150]\n",
    "\n",
    "# trainデータとtestデータに分割\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# SGDClassifierをダウンロード\n",
    "model = SGDClassifier(loss='log')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "pred = model.predict(X_test)\n",
    "print(pred)\n",
    "\n",
    "# 正解率\n",
    "accuracy_score(pred, y_test)\n",
    "\n",
    "# 推定がオール1だったので正解率を見たが、どうやら精度の問題だったらしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット2\n",
    "import numpy as np\n",
    "np.random.seed(seed=0)\n",
    "n_samples = 500\n",
    "f0 = [-1, 2]\n",
    "f1 = [2, -1]\n",
    "cov = [[1.0,0.8], [0.8, 1.0]]\n",
    "f0 = np.random.multivariate_normal(f0, cov, int(n_samples/2))\n",
    "f1 = np.random.multivariate_normal(f1, cov, int(n_samples/2))\n",
    "\n",
    "X = np.concatenate((f0, f1))\n",
    "y = np.concatenate((np.ones((int(n_samples/2))), np.ones((int(n_samples/2))) *(-1))).astype(np.int)\n",
    "\n",
    "random_index = np.random.permutation(np.arange(n_samples))\n",
    "X = X[random_index]\n",
    "y = y[random_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1,  1,  1,  1, -1,  1, -1,\n",
       "        1,  1, -1,  1,  1,  1, -1, -1,  1, -1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1, -1,  1,  1,  1,  1,  1,  1,  1, -1,  1, -1, -1, -1,  1, -1,\n",
       "        1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1, -1,  1, -1,  1,  1, -1,\n",
       "        1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1, -1,  1,  1, -1,  1, -1,  1,  1])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. SVCで分類する\n",
    "# データを分割する(データセット2参照)\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# SVCをダウンロード\n",
    "model_svc = SVC()\n",
    "model_svc.fit(X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "pred_svc = model_svc.predict(X_test)\n",
    "\n",
    "pred_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセット3\n",
    "X = np.array([[-0.44699 , -2.8073  ],[-1.4621  , -2.4586  ],\n",
    "       [ 0.10645 ,  1.9242  ],[-3.5944  , -4.0112  ],\n",
    "       [-0.9888  ,  4.5718  ],[-3.1625  , -3.9606  ],\n",
    "       [ 0.56421 ,  0.72888 ],[-0.60216 ,  8.4636  ],\n",
    "       [-0.61251 , -0.75345 ],[-0.73535 , -2.2718  ],\n",
    "       [-0.80647 , -2.2135  ],[ 0.86291 ,  2.3946  ],\n",
    "       [-3.1108  ,  0.15394 ],[-2.9362  ,  2.5462  ],\n",
    "       [-0.57242 , -2.9915  ],[ 1.4771  ,  3.4896  ],\n",
    "       [ 0.58619 ,  0.37158 ],[ 0.6017  ,  4.3439  ],\n",
    "       [-2.1086  ,  8.3428  ],[-4.1013  , -4.353   ],\n",
    "       [-1.9948  , -1.3927  ],[ 0.35084 , -0.031994],\n",
    "       [ 0.96765 ,  7.8929  ],[-1.281   , 15.6824  ],\n",
    "       [ 0.96765 , 10.083   ],[ 1.3763  ,  1.3347  ],\n",
    "       [-2.234   , -2.5323  ],[-2.9452  , -1.8219  ],\n",
    "       [ 0.14654 , -0.28733 ],[ 0.5461  ,  5.8245  ],\n",
    "       [-0.65259 ,  9.3444  ],[ 0.59912 ,  5.3524  ],\n",
    "       [ 0.50214 , -0.31818 ],[-3.0603  , -3.6461  ],\n",
    "       [-6.6797  ,  0.67661 ],[-2.353   , -0.72261 ],\n",
    "       [ 1.1319  ,  2.4023  ],[-0.12243 ,  9.0162  ],\n",
    "       [-2.5677  , 13.1779  ],[ 0.057313,  5.4681  ]])\n",
    "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1,  1,  1, -1,  1,  1,  1,\n",
       "       -1, -1,  1,  1,  1, -1, -1,  1, -1,  1, -1,  1, -1,  1,  1,  1, -1,\n",
       "        1,  1,  1,  1, -1, -1,  1, -1, -1,  1, -1, -1,  1,  1,  1, -1, -1,\n",
       "        1,  1,  1,  1, -1,  1,  1,  1, -1, -1,  1,  1,  1, -1,  1, -1, -1,\n",
       "       -1, -1, -1,  1, -1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1, -1,  1,\n",
       "       -1, -1,  1,  1, -1, -1,  1,  1, -1,  1,  1,  1, -1,  1, -1])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.決定木にて分類する(データセット3参照)\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# 決定木をダウンロード\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_tree.fit(X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "pred_tree = model_tree.predict(X_test)\n",
    "pred_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】 回帰問題を解くコードの作成\n",
    "線形回帰でHouse Pricesデータセットを学習・推定するコードを作成してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回帰問題\n",
    "回帰は1種類をスクラッチします。\n",
    "\n",
    "\n",
    "線形回帰\n",
    "\n",
    "線形回帰は勾配降下法を用いて計算するSGDRegressorクラスを利用してください。\n",
    "\n",
    "\n",
    "sklearn.linear_model.SGDRegressor — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "データセットは事前学習期間同様にHouse Pricesコンペティションのものを使います。\n",
    "\n",
    "\n",
    "House Prices: Advanced Regression Techniques\n",
    "\n",
    "\n",
    "train.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#House Pricesデータ\n",
    "dir_path = '/Users/yuki.tatsuoka/Downloads/house-prices-advanced-regression-techniques (1)/'\n",
    "df = pd.read_csv(dir_path + \"train.csv\")\n",
    "\n",
    "X = df.loc[:, ['GrLivArea', 'YearBuilt']]\n",
    "y = df.loc[:, 'SalePrice']\n",
    "\n",
    "# 標準化\n",
    "scaler = StandardScaler()\n",
    "X_norm = scaler.fit_transform(X)\n",
    "\n",
    "# X,yを分割する\n",
    "X_train, X_test, y_train, y_test = scratch_train_test_split(X_norm, y, train_size=0.8)\n",
    "\n",
    "# モデルをダウンロード\n",
    "model_sgd = SGDRegressor()\n",
    "model_sgd.fit(X_train, y_train)\n",
    "\n",
    "# 推定\n",
    "pred_sgd = model_sgd.predict(X_test)\n",
    "pred_sgd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5519064183.451536"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 評価もしてみる\n",
    "mean_squared_error(pred_sgd, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
