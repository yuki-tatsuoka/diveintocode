{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】ラグランジュの未定乗数法による最急降下\n",
    "SVMの学習は、ラグランジュの未定乗数法を用います。サンプル数分のラグランジュ乗数 \n",
    "λを用意して、以下の式により更新していきます。この計算を行うメソッドをScratchSVMClassifierクラスに実装してください。\n",
    "\n",
    "$$\n",
    "λ\n",
    "n\n",
    "e\n",
    "w\n",
    "i\n",
    "=\n",
    "λ\n",
    "i\n",
    "+\n",
    "α\n",
    "(\n",
    "1\n",
    "−\n",
    "n\n",
    "∑\n",
    "j\n",
    "=\n",
    "1\n",
    "λ\n",
    "j\n",
    "y\n",
    "i\n",
    "y\n",
    "j\n",
    "k\n",
    "(\n",
    "x\n",
    "i\n",
    ",\n",
    "x\n",
    "j\n",
    ")\n",
    ")\n",
    "$$ \n",
    "ここで \n",
    "k\n",
    "(\n",
    "x\n",
    "i\n",
    ",\n",
    "x\n",
    "j\n",
    ")\n",
    " はカーネル関数です。線形カーネルの場合は次のようになります。他のカーネル関数にも対応できるように、この部分は独立したメソッドとしておきましょう。\n",
    "\n",
    "$$\n",
    "k\n",
    "(\n",
    "x\n",
    "i\n",
    ",\n",
    "x\n",
    "j\n",
    ")\n",
    "=\n",
    "x\n",
    "T\n",
    "i\n",
    "x\n",
    "j\n",
    "$$\n",
    "条件として、更新毎に \n",
    "λ\n",
    "i\n",
    ">=\n",
    "0\n",
    "を満たす必要があります。満たさない場合は \n",
    "λ\n",
    "i\n",
    "=\n",
    "0\n",
    "とします。\n",
    "\n",
    "\n",
    "i\n",
    ",\n",
    "j\n",
    " : サンプルのインデックス\n",
    "\n",
    "\n",
    "λ\n",
    "n\n",
    "e\n",
    "w\n",
    "i\n",
    " : 更新後のi番目のサンプルのラグランジュ乗数\n",
    "\n",
    "\n",
    "λ\n",
    "i\n",
    " : 更新前のi番目のサンプルのラグランジュ乗数\n",
    "\n",
    "\n",
    "α\n",
    " : 学習率\n",
    "\n",
    "\n",
    "λ\n",
    "j\n",
    " : j番目のサンプルのラグランジュ乗数\n",
    "\n",
    "\n",
    "y\n",
    "i\n",
    " : i番目のサンプルのラベル\n",
    "\n",
    "\n",
    "y\n",
    "j\n",
    " : j番目のサンプルのラベル\n",
    "\n",
    "\n",
    "x\n",
    "i\n",
    " : i番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "x\n",
    "j\n",
    " : j番目のサンプルの特徴量ベクトル\n",
    "\n",
    "\n",
    "あるサンプルに対しての全てのサンプルとの関係を計算していくことになります。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSVMClassifier():\n",
    "    \"\"\"\n",
    "    SVM分類器のスクラッチ実装\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    kernel : str\n",
    "      カーネルの種類。線形カーネル（linear）か多項式カーネル（polly）\n",
    "    threshold : float\n",
    "      サポートベクターを選ぶための閾値\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.n_support_vectors : int\n",
    "      サポートベクターの数（線を引く時の最小値の数）\n",
    "    self.index_support_vectors : 次の形のndarray, shape (n_support_vectors,)\n",
    "      サポートベクターのインデックス\n",
    "    self.X_sv :  次の形のndarray, shape(n_support_vectors, n_features)\n",
    "      サポートベクターの特徴量\n",
    "    self.lam_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "      サポートベクターの未定乗数\n",
    "    self.y_sv :  次の形のndarray, shape(n_support_vectors, 1)\n",
    "      サポートベクターのラベル\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, kernel='linear', threshold=1e-5, verbose=False):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.kernel = kernel\n",
    "        self.threshold = threshold\n",
    "        self.verbose = verbose\n",
    "        self.support_vector = []\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        SVM分類器を学習する。検証データが入力された場合はそれに対する精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.lam_sv = np.random.rand(X.shape[0], 1)\n",
    "        \n",
    "        for i in range(self.iter):\n",
    "            self._upgrade_svm(X, y)\n",
    "            #lam_sv_max = np.max()\n",
    "            \n",
    "            if self.verbose:\n",
    "                #verboseをTrueにした際は学習過程を出力\n",
    "                print('{}/{} lamda{}'.format(i+1, self.iter, self.lam_sv.max()))\n",
    "        \n",
    "         # サポートベクターを決定しインデックスとして保存する\n",
    "        self.support_vector = np.where(self.lam_sv >= self.threshold)\n",
    "        # サポートベクターの2次元のインデックスを保存する\n",
    "        # 問題3の計算をここで保存する（yの値が必要なのでpredictで実装すると引数にyが必要）\n",
    "        support_vector = self.support_vector[0]\n",
    "        print(\"suport vector\", support_vector)\n",
    "        print(\"suport vector\", support_vector.shape)\n",
    "        self.kernel_sv =  np.dot(X, X[support_vector].T) # カーネル(100,2) (2,100) 転置必要？？\n",
    "        self.calucation = self.lam_sv[support_vector].T*y[support_vector] #λ*y\n",
    "        print(\"kernel_sv\", self.kernel_sv)\n",
    "        print(\"kernel_sv\", self.kernel_sv.shape)\n",
    "        print(\"suport vector\", self.calucation)\n",
    "        print(\"suport vector\", self.calucation.shape)\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        SVM分類器を使いラベルを推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            SVM分類器による推定結果\n",
    "        \"\"\"\n",
    "\n",
    "        f_x = np.dot(self.calucation.T, self.kernel_sv)\n",
    "        f_x = np.sign(f_x)\n",
    "        return f_x # -1、１のどちらかを出力する\n",
    "    \n",
    "    def _upgrade_svm(self, X, y):\n",
    "        # y_dot = (100,100) \n",
    "        # self.lam_sv = (100,1) \n",
    "        #np.dot(self.lam_sv, y_dot) = (100,1)\n",
    "        # _kernel(X) = (100,100) \n",
    "        np.random.seed(0)\n",
    "        y = y.reshape(-1,1)\n",
    "        y_dot = np.dot(y, y.T) # (100,1) (1,100)\n",
    "        self.lam_sv = self.lam_sv + self.lr*(1 - np.dot(self.lam_sv.T, (y_dot*kernel(X)))) #計算の順番注意\n",
    "        self.lam_sv = np.where(self.lam_sv<=0, 0, self.lam_sv) # ０以下を０に変換する\n",
    "        \n",
    "    def _kernel(self, X):\n",
    "        kernel = np.dot(X, X.T)  # (100,1), X(1,100) (100,100)\n",
    "        return kernel\n",
    "    \n",
    "    def _sign(self, X):\n",
    "        w = np.dot(np.dot(self.lam_sv, y).T, X) #λ(100,100) y(100,1) X(100,2) = (1,2) \n",
    "        y_sign = np.sign(w, X.T) # (1,2) (2, 100) wを転置するならwの計算前から\n",
    "        return y_sign # (1,100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suport vector [ 0  0  0 ... 74 74 74]\n",
      "suport vector (2889,)\n",
      "kernel_sv [[ 2.41  2.41  2.41 ...  7.35  7.35  7.35]\n",
      " [ 2.07  2.07  2.07 ...  6.3   6.3   6.3 ]\n",
      " [ 6.82  6.82  6.82 ... 20.85 20.85 20.85]\n",
      " ...\n",
      " [ 1.88  1.88  1.88 ...  5.7   5.7   5.7 ]\n",
      " [ 6.48  6.48  6.48 ... 19.8  19.8  19.8 ]\n",
      " [ 7.35  7.35  7.35 ... 22.5  22.5  22.5 ]]\n",
      "kernel_sv (75, 2889)\n",
      "suport vector [[0.         0.         0.         ... 0.83926358 0.83926358 0.83926358]\n",
      " [0.         0.         0.         ... 0.83926358 0.83926358 0.83926358]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.83926358 0.83926358 0.83926358]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "suport vector (75, 2889)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)\n",
    "\n",
    "model_sc = ScratchSVMClassifier(1000,0.0001, verbose=None)\n",
    "\n",
    "model_sc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 0, 0, 1, 1, 2, 2, 2]), array([0, 2, 4, 1, 3, 0, 2, 4]))\n",
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "np.printoptions(threshold=None)\n",
    "\n",
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "X = X.loc[:, ['petal length (cm)', 'petal width (cm)']][0:100].to_numpy()\n",
    "y = iris.target[0:100]\n",
    "\n",
    "a = np.random.rand(X.shape[0], 1)\n",
    "b = np.arange(0,12).reshape(3,4)\n",
    "c = np.arange(0,15).reshape(3,5)\n",
    "where = np.where(c%2==0)\n",
    "print(where)\n",
    "print(c)\n",
    "c[where]\n",
    "y.reshape(-1,1)[where[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5489135 , 0.5489135 , 0.5489135 , ..., 0.50731877, 0.51935739,\n",
       "        0.50908534],\n",
       "       [0.71528937, 0.71528937, 0.71528937, ..., 0.67369464, 0.68573325,\n",
       "        0.6754612 ],\n",
       "       [0.60286338, 0.60286338, 0.60286338, ..., 0.56126865, 0.57330726,\n",
       "        0.56303521],\n",
       "       ...,\n",
       "       [0.02020755, 0.02020755, 0.02020755, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.82904003, 0.82904003, 0.82904003, ..., 0.7874453 , 0.79948392,\n",
       "        0.78921187],\n",
       "       [0.00479548, 0.00479548, 0.00479548, ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gradient(X, y, lr=0.0001, threshold=1e-5):\n",
    "    # y_dot = (100,100) \n",
    "    # self.lam_sv = (100,1) \n",
    "    #np.dot(self.lam_sv, y_dot) = (100,1)\n",
    "    # _kernel(X) = (100,100) \n",
    "    np.random.seed(0)\n",
    "    lam_sv = np.random.rand(X.shape[0], 1)\n",
    "    y = y.reshape(-1,1)\n",
    "    \n",
    "    y_dot = np.dot(y, y.T) # (100,1) (1,100)  (100,100)\n",
    "    lam_sv = lam_sv + lr*(1 - np.dot(lam_sv.T, (y_dot*kernel(X))))\n",
    "    lam_sv = np.where(lam_sv <= 0, 0, lam_sv)\n",
    "    support_vector = np.where(lam_sv >= threshold)\n",
    "    return lam_sv, support_vector\n",
    "\n",
    "\n",
    "def kernel(X):\n",
    "    kernel = np.dot(X, X.T)  # (100,2), X(2,100) (100,100)\n",
    "    return kernel\n",
    "\n",
    "a, b = gradient(X,y)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】サポートベクターの決定\n",
    "計算したラグランジュ乗数 $\\lambda$ が設定した閾値より大きいサンプルをサポートベクターとして扱います。推定時にサポートベクターが必要になります。サポートベクターを決定し、インスタンス変数として保持しておくコードを書いてください。\n",
    "\n",
    "\n",
    "閾値はハイパーパラメータですが、1e-5程度からはじめると良いでしょう。サポートベクターの数を出力させられるようにしておくと学習がうまく行えているかを確認できます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】推定\n",
    "推定時には、推定したいデータの特徴量とサポートベクターの特徴量をカーネル関数によって計算します。求めた \n",
    "f\n",
    "(\n",
    "x\n",
    ")\n",
    " の符号が分類結果です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したシンプルデータセット1の2値分類に対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。\n",
    "\n",
    "\n",
    "AccuracyやPrecision、Recallなどの指標値はscikit-learnを使用してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】決定領域の可視化\n",
    "決定領域を可視化してください。\n",
    "\n",
    "\n",
    "以下の例のようにサポートベクターは異なる色で示してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】（アドバンス課題）多項式カーネル関数の作成\n",
    "最初に作成した実装では線形カーネルを使用していました。多項式カーネルにも切り替えられるようにしましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
