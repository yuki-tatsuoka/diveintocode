{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】仮定関数\n",
    "ロジスティック回帰の仮定関数のメソッドをScratchLogisticRegressionクラスに実装してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def logistic_hypothesis(X):\n",
    "    np.random.seed(0)\n",
    "    theta = np.random.rand(1,X.shape[1])\n",
    "    hypothesis = 1/(1 + np.exp(-1 * (np.dot(X, theta.T))))\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        ],\n",
       "       [0.4236548 ],\n",
       "       [0.64589411],\n",
       "       [0.43758721],\n",
       "       [0.891773  ]])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[50:150]\n",
    "y = pd.DataFrame(iris.target[50:150])\n",
    "\n",
    "y = y.replace({1:0, 2:1})\n",
    "y = y.to_numpy().flatten()\n",
    "\n",
    "logistic_hypothesis(X).ravel()\n",
    "\n",
    "ones = np.ones((1,1))\n",
    "theta = np.random.rand(1,X.shape[1])\n",
    "theta = np.insert(theta, 0, ones, axis=1).reshape(-1,1)\n",
    "\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】最急降下法\n",
    "最急降下法により学習させる実装を行なってください。以下の式で表されるパラメータの更新式のメソッド_gradient_descentを追加し、fit\n",
    "メソッドから呼び出すようにしてください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】推定\n",
    "推定する仕組みを実装してください。ScratchLogisticRegressionクラスの雛形に含まれるpredictメソッドとpredict_probaメソッドに書き加えてください。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(X):\n",
    "    pred = logistic_hypothesis(X)\n",
    "    pred = np.where(pred < 0.5, 0, 1)\n",
    "    return pred\n",
    "\n",
    "predict(X_train).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.68298478e-05, 9.99913170e-01],\n",
       "       [5.07860087e-05, 9.99949214e-01],\n",
       "       [2.11383242e-05, 9.99978862e-01],\n",
       "       [2.11881591e-04, 9.99788118e-01],\n",
       "       [2.62677388e-04, 9.99737323e-01],\n",
       "       [3.61152393e-04, 9.99638848e-01],\n",
       "       [1.21392045e-04, 9.99878608e-01],\n",
       "       [2.08969845e-05, 9.99979103e-01],\n",
       "       [1.08076884e-03, 9.98919231e-01],\n",
       "       [5.96996425e-05, 9.99940300e-01],\n",
       "       [2.02246650e-04, 9.99797753e-01],\n",
       "       [4.87954129e-04, 9.99512046e-01],\n",
       "       [8.93494038e-05, 9.99910651e-01],\n",
       "       [1.04126635e-04, 9.99895873e-01],\n",
       "       [2.54866048e-05, 9.99974513e-01],\n",
       "       [1.05167159e-04, 9.99894833e-01],\n",
       "       [9.33344552e-05, 9.99906666e-01],\n",
       "       [8.04607388e-05, 9.99919539e-01],\n",
       "       [4.00564818e-04, 9.99599435e-01],\n",
       "       [5.47261484e-04, 9.99452739e-01],\n",
       "       [1.07666791e-05, 9.99989233e-01],\n",
       "       [9.02801142e-05, 9.99909720e-01],\n",
       "       [8.35014786e-05, 9.99916499e-01],\n",
       "       [3.01173148e-04, 9.99698827e-01],\n",
       "       [1.66985048e-04, 9.99833015e-01]])"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_proba(X):\n",
    "    pred_0 = 1- logistic_hypothesis(X)\n",
    "    pred_1 = logistic_hypothesis(X)\n",
    "    pred_proba = np.hstack([pred_0, pred_1])\n",
    "    return pred_proba\n",
    "\n",
    "predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】目的関数\n",
    "以下の数式で表されるロジスティック回帰の 目的関数（損失関数） を実装してください。そして、これをself.loss, self.val_lossに記録するようにしてください。\n",
    "\n",
    "\n",
    "なお、この数式には正則化項が含まれています。\n",
    "\n",
    "\n",
    "＊数式が見切れる場合、DIVERを全画面にして御覧ください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8977907443338955"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cost_function(X, y,lamda=0.01):\n",
    "    theta = np.random.rand(1,X.shape[1])\n",
    "    y = y.reshape(-1,1)\n",
    "    cross_entropy = (1/X.shape[0]) * np.sum((-y * np.log(logistic_hypothesis(X))) - ((1- y) * np.log(1-logistic_hypothesis(X))))\n",
    "    regularization_term = lamda/2*X.shape[0] * np.sum(theta**2)\n",
    "    cost_loss =  (cross_entropy + regularization_term).tolist()\n",
    "    return cost_loss\n",
    "\n",
    "cost_function(X_test, y_test)\n",
    "#(-y * np.log(logistic_hypothesis(X))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.342162555710892"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証用に調べたが、あまり間違っていなさそう。\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "pred_sklearn = model.predict(X_test)\n",
    "pred_sklearn\n",
    "\n",
    "log_loss(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】学習と推定\n",
    "機械学習スクラッチ入門のSprintで用意したirisデータセットのvirgicolorとvirginicaの2値分類に対してスクラッチ実装の学習と推定を行なってください。\n",
    "\n",
    "\n",
    "scikit-learnによる実装と比べ、正しく動いているかを確認してください。\n",
    "\n",
    "\n",
    "AccuracyやPrecision、Recallなどの指標値はscikit-learnを使用してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合体版\n",
    "class ScratchLogisticRegression():\n",
    "    \"\"\"\n",
    "    ロジスティック回帰のスクラッチ実装\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_iter : int\n",
    "      イテレーション数\n",
    "    lr : float\n",
    "      学習率\n",
    "    no_bias : bool\n",
    "      バイアス項を入れない場合はTrue\n",
    "    verbose : bool\n",
    "      学習過程を出力する場合はTrue\n",
    "    Attributes\n",
    "    ----------\n",
    "    self.coef_ : 次の形のndarray, shape (n_features,)\n",
    "      パラメータ\n",
    "    self.loss : 次の形のndarray, shape (self.iter,)\n",
    "      訓練データに対する損失の記録\n",
    "    self.val_loss : 次の形のndarray, shape (self.iter,)\n",
    "      検証データに対する損失の記録\n",
    "    \"\"\"\n",
    "    def __init__(self, num_iter, lr, bias, verbose):\n",
    "        # ハイパーパラメータを属性として記録\n",
    "        self.iter = num_iter\n",
    "        self.lr = lr\n",
    "        self.bias = bias\n",
    "        self.verbose = verbose\n",
    "        # 損失を記録する配列を用意\n",
    "        self.loss = np.zeros(self.iter)\n",
    "        self.val_loss = np.zeros(self.iter)\n",
    "        self.lamda = 0.001\n",
    "        self.list_train_loss = []\n",
    "        self.list_val_loss = []\n",
    "        \n",
    "    # 問題１    \n",
    "    def _logistic_hypothesis(self, X):\n",
    "        z = np.dot(X, self.theta.T)\n",
    "        y_hot = 1/(1 + np.exp(-z))\n",
    "        return y_hot\n",
    "\n",
    "    # 問題2\n",
    "    def fit(self, X, y, X_val, y_val):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を学習する。検証データが入力された場合はそれに対する損失と精度もイテレーションごとに計算する。\n",
    "        Parameters\n",
    "        \n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        self.theta = np.random.rand(1,X.shape[1])\n",
    "\n",
    "        # バイアスをthetaとX, X_valに追加\n",
    "        if self.bias:\n",
    "            X = np.insert(X, 0,1, axis=1)\n",
    "            X_val = np.insert(X_val, 0, 1, axis=1) ###相違点\n",
    "            self.theta = np.insert(self.theta, 0, 1, axis=1)\n",
    "        \n",
    "        # 訓練データを勾配計算からpredict〜cost_functionを計算\n",
    "        for i in range(self.iter):\n",
    "            error = self._logistic_hypothesis(X)  \n",
    "            self._gradient_descent(X, error, y)\n",
    "           # y_pred = self.predict_proba(X)[:,1]\n",
    "            loss, _ = self.cost_function(X, y, error)\n",
    "            self.list_train_loss.append(loss)\n",
    "            \n",
    "            if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程を出力\n",
    "                print(\"{}/{}, train_loss {}\".format(i+1, self.iter, loss))\n",
    "        \n",
    "\n",
    "        # テストデータを勾配計算からpredict〜cost_functionを計算\n",
    "        if X_val is not None and y_val is not None:\n",
    "            for i in range(self.iter):\n",
    "                error = self._logistic_hypothesis(X_val) \n",
    "                self._gradient_descent(X_val, error, y_val)\n",
    "                #y_val_pred = self.predict_proba(X_val)[:, 1]\n",
    "                _, val_loss = self.cost_function(X_val, y_val, error)\n",
    "                self.list_val_loss.append(val_loss)\n",
    "        \n",
    "                if self.verbose:\n",
    "                #verboseをTrueにした際は学習過程を出力\n",
    "                    print(\"{}/{}, test_loss {}\".format(i+1, self.iter, val_loss))\n",
    "             \n",
    "            \n",
    "    # 問題3\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を使いラベルを推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            ロジスティック回帰による推定結果\n",
    "        \"\"\" \n",
    "        if self.bias:\n",
    "            X = np.insert(X, 0, 1, axis=1)    \n",
    "            \n",
    "        pred = self._logistic_hypothesis(X)\n",
    "        pred = np.where(pred < 0.5, 0, 1)\n",
    "        return pred\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        ロジスティック回帰を使い確率を推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            ロジスティック回帰による推定結果\n",
    "        \"\"\"\n",
    "        if self.bias:\n",
    "            X = np.insert(X, 0, 1, axis=1)  \n",
    "        \n",
    "        pred_0 = 1- self._logistic_hypothesis(X)\n",
    "        pred_1 = self._logistic_hypothesis(X)\n",
    "        pred_proba = np.hstack([pred_0, pred_1])\n",
    "        return pred_proba\n",
    "    \n",
    "    # 問題2\n",
    "    def _gradient_descent(self, X, error, y):\n",
    "        y = y.reshape(-1,1)\n",
    "        new_error = error - y\n",
    "        new_erro = new_error.reshape(-1,1)\n",
    "        self.theta = self.theta - (self.lr*np.dot(X.T, new_error)) + (self.lamda*self.theta)/X.shape[0]\n",
    "        return self.theta\n",
    "\n",
    "\n",
    "    \n",
    "    # 問題4\n",
    "    def cost_function(self, X,y, y_pred):\n",
    "        cross_entropy = 1/X.shape[0] * np.sum(-y * np.log(y_pred) - (1- y) * np.log(1-y_pred))\n",
    "        regularization_term = self.lamda * np.sum(self.theta**2) / 2*X.shape[0]\n",
    "        cost_loss =  cross_entropy + regularization_term\n",
    "        self.loss = cost_loss\n",
    "        self.val_loss = cost_loss\n",
    "        return self.loss, self.val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "[[ 15  18  21]\n",
      " [ 42  54  66]\n",
      " [ 69  90 111]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7. , 3.2, 4.7, 1.4])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.random.rand(1,X.shape[1])\n",
    "theta\n",
    "\n",
    "a = np.arange(0,9).reshape(3,3)\n",
    "b = np.arange(0,9).reshape(3,3)\n",
    "\n",
    "print(np.sum(a*b))\n",
    "print(a@b)\n",
    "X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1000, train_loss 371.98804185155063\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (75,) (75,5) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-374-37d151e0c147>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_scratch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScratchLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_scratch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-373-3ef83dc9c24a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, X_val, y_val)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m            \u001b[0;31m# y_pred = self.predict_proba(X)[:,1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_train_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-373-3ef83dc9c24a>\u001b[0m in \u001b[0;36mcost_function\u001b[0;34m(self, X, y, y_pred)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# 問題4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mcross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mregularization_term\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlamda\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mcost_loss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcross_entropy\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mregularization_term\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (75,) (75,5) "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score ,precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "model_scratch = ScratchLogisticRegression(1000, 0.001, True, True)\n",
    "model_scratch.fit(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[0.99999083 0.99999079 0.99999299 0.99999508 0.99999861 0.99983059\n",
      " 0.99996835 0.99999927 0.99993073 0.99996335 0.99999324 0.99999195\n",
      " 0.99998162 0.9999818  0.99982532 0.99992929 0.99998517 0.99998177\n",
      " 0.99998412 0.99998761 0.99983567 0.99999907 0.99993778 0.99999571\n",
      " 0.99999298]\n",
      "--------------------------------------------------\n",
      "[[ 0  0]\n",
      " [14 11]]\n",
      "0.44\n",
      "1.0\n",
      "0.44\n",
      "0.6111111111111112\n",
      "log loss: 155.8747722855166\n"
     ]
    }
   ],
   "source": [
    "# 評価の確認\n",
    "pred = model_scratch.predict(X_test)\n",
    "pred_proba = model_scratch.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(pred.ravel())\n",
    "print(pred_proba)\n",
    "print(\"-\"*50)\n",
    "# 混合行列、正解率、適合率、再現率、F値\n",
    "print(confusion_matrix(pred, y_test))\n",
    "print(accuracy_score(pred, y_test))\n",
    "print(precision_score(pred, y_test))\n",
    "print(recall_score(pred, y_test))\n",
    "print(f1_score(pred, y_test))\n",
    "\n",
    "# スクラッチのクロスエントロピー\n",
    "_, cost = model_scratch.cost_function(X_test, y_test, pred_proba)\n",
    "print(\"log loss: {}\".format(cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0 0 0 0 1 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1]\n",
      "[0.54645183 0.89594754 0.95960762 0.05054654 0.07560458 0.05182233\n",
      " 0.45569541 0.97205303 0.01100832 0.17350702 0.25509376 0.0213071\n",
      " 0.58417041 0.63124837 0.96149306 0.22305241 0.5059302  0.54943092\n",
      " 0.02981109 0.01313685 0.99445254 0.48639945 0.272587   0.03704218\n",
      " 0.58968991]\n",
      "[[9 6]\n",
      " [5 5]]\n",
      "0.56\n",
      "0.45454545454545453\n",
      "0.5\n",
      "0.47619047619047616\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.197221533246738"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearnのロジスティック回帰と比較する\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)\n",
    "\n",
    "X = iris.data[50:150]\n",
    "y = pd.DataFrame(iris.target[50:150])\n",
    "\n",
    "y = y.replace({1:0, 2:1})\n",
    "y = y.to_numpy().flatten()\n",
    "\n",
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "pred_sk = model.predict(X_test)\n",
    "pred_sk_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# predとprobaの確認\n",
    "print(pred_sk)\n",
    "print(pred_sk_proba)\n",
    "\n",
    "# 混合行列、正解率、適合率、再現率、F値\n",
    "print(confusion_matrix(pred, y_test))\n",
    "print(accuracy_score(pred, y_test))\n",
    "print(precision_score(pred, y_test))\n",
    "print(recall_score(pred, y_test))\n",
    "print(f1_score(pred, y_test))\n",
    "\n",
    "# sklearnのクロスエントロピー\n",
    "\n",
    "log_loss(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】学習曲線のプロット\n",
    "学習曲線を見て損失が適切に下がっているかどうか確認してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n考察\\nvalはほとんど誤差に変化がないが、、、\\n計算が正しいという前提の元でいうと\\n訓練データと比べてテストデータが低いので、汎化性が高いと言える\\n（※計算があっているのか？）\\n'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(1000), model_scratch.list_train_loss, c='y', label='train_loss')  \n",
    "plt.plot(range(1000), model_scratch.list_val_loss, c='b', label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "考察\n",
    "valはほとんど誤差に変化がないが、、、\n",
    "計算が正しいという前提の元でいうと\n",
    "訓練データと比べてテストデータが低いので、汎化性が高いと言える\n",
    "（※計算があっているのか？）\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】決定領域の可視化\n",
    "決定領域を可視化してください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     7.0\n",
       "1     6.4\n",
       "2     6.9\n",
       "3     5.5\n",
       "4     6.5\n",
       "5     5.7\n",
       "6     6.3\n",
       "7     4.9\n",
       "8     6.6\n",
       "9     5.2\n",
       "10    5.0\n",
       "11    5.9\n",
       "12    6.0\n",
       "13    6.1\n",
       "14    5.6\n",
       "15    6.7\n",
       "16    5.6\n",
       "17    5.8\n",
       "18    6.2\n",
       "19    5.6\n",
       "20    5.9\n",
       "21    6.1\n",
       "22    6.3\n",
       "23    6.1\n",
       "24    6.4\n",
       "25    6.6\n",
       "26    6.8\n",
       "27    6.7\n",
       "28    6.0\n",
       "29    5.7\n",
       "30    5.5\n",
       "31    5.5\n",
       "32    5.8\n",
       "33    6.0\n",
       "34    5.4\n",
       "35    6.0\n",
       "36    6.7\n",
       "37    6.3\n",
       "38    5.6\n",
       "39    5.5\n",
       "40    5.5\n",
       "41    6.1\n",
       "42    5.8\n",
       "43    5.0\n",
       "44    5.6\n",
       "45    5.7\n",
       "46    5.7\n",
       "47    6.2\n",
       "48    5.1\n",
       "49    5.7\n",
       "Name: sepal length (cm), dtype: float64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = pd.DataFrame(iris.data[50:150], columns=iris.feature_names)\n",
    "y = pd.DataFrame(iris.target[50:150], columns=['target'])\n",
    "X = X.loc[:, [\"sepal length (cm)\", \"petal length (cm)\"]]\n",
    "df = pd.concat([X,y], axis=1)\n",
    "df[df['target'] == 1].iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.9        4.96122449 5.02244898 ... 7.77755102 7.83877551 7.9       ]\n",
      " [4.9        4.96122449 5.02244898 ... 7.77755102 7.83877551 7.9       ]\n",
      " [4.9        4.96122449 5.02244898 ... 7.77755102 7.83877551 7.9       ]\n",
      " ...\n",
      " [4.9        4.96122449 5.02244898 ... 7.77755102 7.83877551 7.9       ]\n",
      " [4.9        4.96122449 5.02244898 ... 7.77755102 7.83877551 7.9       ]\n",
      " [4.9        4.96122449 5.02244898 ... 7.77755102 7.83877551 7.9       ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df[df['target'] == 1].iloc[:, 0], df[df['target'] == 1].iloc[:, 1], color='b', label='1')\n",
    "plt.scatter(df[df['target'] == 2].iloc[:, 0], df[df['target'] == 2].iloc[:, 1], color='r', label='2')\n",
    "plt.legend()\n",
    "\n",
    "x1_min, x1_max = X.iloc[:,0].min(), X.iloc[:,0].max(),\n",
    "x2_min, x2_max = X.iloc[:,1].min(), X.iloc[:,1].max(),\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max))\n",
    "print(xx1)\n",
    "grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "#probs = model.predict_proba(grid).reshape(xx1.shape)\n",
    "#plt.contour(xx1, xx2, probs, [0.5], linewidths=1, colors='black')\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (109200,3) and (5,75) not aligned: 3 (dim 1) != 5 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-b257212257b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mdecision_region\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-139-b257212257b8>\u001b[0m in \u001b[0;36mdecision_region\u001b[0;34m(X, y, model1, step, title, xlabel, ylabel, target_names)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mmesh_f0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmesh_f1\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeshgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_f0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_f1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesh_f0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-4f567f55a277>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_logistic_hypothesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-127-4f567f55a277>\u001b[0m in \u001b[0;36m_logistic_hypothesis\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# 問題１\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_logistic_hypothesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0my_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_hot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (109200,3) and (5,75) not aligned: 3 (dim 1) != 5 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "def decision_region(X, y, model, step=0.01, title='decision region', xlabel='xlabel', ylabel='ylabel', target_names=['versicolor', 'virginica']):\n",
    "    \"\"\"\n",
    "    2値分類を2次元の特徴量で学習したモデルの決定領域を描く。\n",
    "    背景の色が学習したモデルによる推定値から描画される。\n",
    "    散布図の点は訓練データまたは検証データである。\n",
    "    Parameters\n",
    "    ----------------\n",
    "    X : ndarray, shape(n_samples, 2)\n",
    "        特徴量\n",
    "    y : ndarray, shape(n_samples,)\n",
    "        ラベル\n",
    "    model : object\n",
    "        学習したモデルのインスンタスを入れる\n",
    "    step : float, (default : 0.1)\n",
    "        推定値を計算する間隔を設定する\n",
    "    title : str\n",
    "        グラフのタイトルの文章を与える\n",
    "    xlabel, ylabel : str\n",
    "        軸ラベルの文章を与える\n",
    "    target_names= : list of str\n",
    "        凡例の一覧を与える\n",
    "    \"\"\"\n",
    "    # setting\n",
    "    scatter_color = ['red', 'blue']\n",
    "    contourf_color = ['pink', 'skyblue']\n",
    "    n_class = 2\n",
    "    # pred\n",
    "    mesh_f0, mesh_f1  = np.meshgrid(np.arange(np.min(X[:,0])-0.5, np.max(X[:,0])+0.5, step), np.arange(np.min(X[:,1])-0.5, np.max(X[:,1])+0.5, step))\n",
    "    mesh = np.c_[np.ravel(mesh_f0),np.ravel(mesh_f1)]\n",
    "    y_pred = model.predict(mesh).reshape(mesh_f0.shape)\n",
    "    # plot\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.contourf(mesh_f0, mesh_f1, y_pred, n_class-1, cmap=ListedColormap(contourf_color))\n",
    "    plt.contour(mesh_f0, mesh_f1, y_pred, n_class-1, colors='y', linewidths=3, alpha=0.5)\n",
    "    for i, target in enumerate(set(y)):\n",
    "        plt.scatter(X[y==target][:, 0], X[y==target][:, 1], s=80, color=scatter_color[i], label=target_names[i], marker='o')\n",
    "    patches = [mpatches.Patch(color=scatter_color[i], label=target_names[i]) for i in range(n_class)]\n",
    "    plt.legend(handles=patches)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "decision_region(X_train, y_train, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】（アドバンス課題）重みの保存\n",
    "検証が容易になるように、学習した重みを保存および読み込みができるようにしましょう。pickleモジュールやNumPyのnp.savezを利用します。\n",
    "\n",
    "\n",
    "pickle — Python オブジェクトの直列化 — Python 3.7.4 ドキュメント\n",
    "\n",
    "\n",
    "numpy.savez — NumPy v1.17 Manual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
