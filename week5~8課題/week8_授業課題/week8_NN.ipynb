{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 1\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
      "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
      "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
      "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
      "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
      "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
      "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
      "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
      "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
      "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
      "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
      "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
      "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
      "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
      "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
      "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
      "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
      "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "print(image) # 値を確認\n",
    "\n",
    "# plt.imshowには自動的に0~255に変換してくれてる（そもそもuintなのでそのままだとエラー）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 何故？\n",
    "plt.imshow(image, 'gray', vmin = 0, vmax = 255)\n",
    "plt.show()\n",
    "\n",
    "# 元々マイナスの数字なので、範囲が-105~145だが\n",
    "#0~255にするので、色の情報を失っている可能性あり\n",
    "\n",
    "\n",
    "plt.imshow(image, 'gray', vmin = -105, vmax = 150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# 前処理\n",
    "# DLでは0~1しか扱わないので画像データmaxの255でデータを割る\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# one-hot変換\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ３層のネットワークをここで作る\n",
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        pass\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチ\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([5, 7, 6, 3, 0, 0, 4, 1, 8, 7, 7, 9, 1, 8, 1, 3, 5, 7, 4, 4],\n",
      "      dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】重みの初期値を決めるコードの作成\n",
    "ニューラルネットワークの各層の重みの初期値を決めるコードを作成してください。\n",
    "\n",
    "\n",
    "重みの初期値は様々な方法が提案されていますが、今回はガウス分布による単純な初期化を行います。バイアスに関しても同様です。\n",
    "\n",
    "\n",
    "以下のコードを参考にしてください。標準偏差の値sigmaはハイパーパラメータです。発展的な重みの初期化方法については次のSprintで扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "sigma = 0.01 # ガウス分布の標準偏差\n",
    "\n",
    "# 重みの初期値\n",
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "# W1: (784, 400)\n",
    "\n",
    "n_nodes2 = 200 # 自由(理由なし)\n",
    "W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "# W2: (400, 200)\n",
    "\n",
    "# バイアス\n",
    "bias1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "# baias1：（784, 400）\n",
    "\n",
    "bias2 = sigma * np.random.randn(n_nodes1, n_nodes1)\n",
    "# baias2：（400, 200）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】フォワードプロパゲーションの実装\n",
    "三層のニューラルネットワークの フォワードプロパゲーション を作成してください。以下の説明ではノード数は1層目は400、2層目は200としますが、変更しても構いません。\n",
    "\n",
    "\n",
    "各層の数式を以下に示します。今回はそれぞれの記号が表す配列が、実装上どのようなndarrayのshapeになるかを併記してあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ３層のネットワークをここで作る\n",
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma, n_nodes1, n_nodes2,n_output,batch_size, epoch, verbose = False):\n",
    "        self.verbose = verbose\n",
    "        self.sigma = sigma # ガウス分布の標準偏差\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = epoch\n",
    "        self.n_output = n_output\n",
    "        self.W1 = self.sigma * np.random.randn(n_features, self.n_nodes1)# W1: (784, 400)\n",
    "        self.W2 = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2) # (400, 200)\n",
    "        self.W3 =  self.sigma * np.random.randn(self.n_nodes2, self.n_output) #(200, 10)\n",
    "        self.bias1 = self.sigma * np.random.randn(self.n_nodes1) # baias1：（784,）\n",
    "        self.bias3 = self.sigma * np.random.randn(self.n_output) # (10,)\n",
    "        self.bias2 = self.sigma * np.random.randn(self.n_nodes2) # \n",
    "        self.train_score_list =[]\n",
    "        self.val_score_list = []\n",
    "        self.train_loss_list = []\n",
    "        self.val_loss_list = []\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        #n_features = X.shape[1] #(784)\n",
    "         \n",
    "                \n",
    "        # ワンホット（ブロードキャスト版）\n",
    "        y_one_hot = y.reshape(-1,1) == np.arange(10) # (48000, 10)\n",
    "        y_val_one_hot = y_val.reshape(-1,1) == np.arange(10) # (12000, 10)\n",
    "        \n",
    "        \n",
    "        # エポックで学習\n",
    "        for epoch in range(self.epoch):\n",
    "            train_loss = 0\n",
    "            val_loss = 0\n",
    "            get_mini_batch = GetMiniBatch(X, y_one_hot, batch_size=self.batch_size)\n",
    "            # イテレーション\n",
    "            for mini_X_train, mini_y_train in get_mini_batch: # バッチサイズ20なら2400回繰り返し\n",
    "                self.forward(mini_X_train)\n",
    "                train_loss += self.log_loss(mini_X_train, mini_y_train)\n",
    "                self.back_propagation(mini_X_train, mini_y_train, alpha=0.01)\n",
    "                #val_loss += self.log_loss(X_val, y_val_one_hot)\n",
    "           \n",
    "            # 問題6 accuracyのスコア\n",
    "            train_score = len(self.predict(X)[self.predict(X) == y]) / len(y)\n",
    "            self.train_score_list.append(train_score)\n",
    "            train_loss = train_loss/ len(get_mini_batch)\n",
    "            self.train_loss_list.append(train_loss)\n",
    "            \n",
    "            val_score = len(self.predict(X_val)[self.predict(X_val) == y_val]) / len(y_val)\n",
    "            self.val_score_list.append(val_score)\n",
    "            #val_loss = val_loss / len(val_loss)\n",
    "            #val_loss_list.append(val_loss)\n",
    "            \n",
    "            if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "                print(\"train loss {}, train_score{}, val_score{}\".format(train_loss,train_score, val_score))\n",
    "            \n",
    "                \n",
    "    \n",
    "    # 問題5\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        return np.argmax(self.forward(X), axis=1)\n",
    "   \n",
    "\n",
    "    # 問題2 \n",
    "    def forward(self, X):\n",
    "        self.a1 = X@self.W1 + self.bias1 #((20, 784), (784, 400)) + (400, ) (20, 400)\n",
    "        self.Z1 =  self.sigmoid(self.a1) \n",
    "        self.a2 = self.Z1@self.W2 + self.bias2 # (20, 400) (400, 200) + (200,) (20,200)\n",
    "        self.Z2 = np.tanh(self.a2)    \n",
    "        self.a3 = self.Z2@self.W3 + self.bias3  #  (20,200) (200,10)  + (10,) (20,10)\n",
    "        self.Z3= self.soft_max(self.a3) # (20,10) \n",
    "        return self.Z3\n",
    "        \n",
    "    # シグモイド関数\n",
    "    def sigmoid(self, X):\n",
    "        return 1/(1 + np.exp(-X))\n",
    "    \n",
    "    # ソフトマックス関数\n",
    "    def soft_max(self, X):\n",
    "        # オーバーフロー対策 \n",
    "        X_max = np.max(X) # (20,10)\n",
    "        return np.exp(X - X_max)/ np.sum(np.exp(X - X_max), axis=1, keepdims=True)\n",
    "        \n",
    "   # 問題3\n",
    "    def log_loss(self, X, y):\n",
    "        #y = (20, ) \n",
    "        # output_layer = (20,10) \n",
    "        self.loss = -(1/self.batch_size) * np.sum(y*np.log(self.forward(X)))\n",
    "        return self.loss\n",
    "    \n",
    "    # 問題4 \n",
    "    def back_propagation(self, X, y, alpha):\n",
    "        # Z = sotmax(A) (20,10)\n",
    "        # A = zx+b (20,10)\n",
    "        # ３層\n",
    "        delta_A3 = (1/self.batch_size)*(self.Z3 - y) # (20,10) (20, 10)\n",
    "        self.bias3 -= alpha * np.sum(delta_A3, axis=0) # (10,)\n",
    "        self.W3 -= alpha * self.Z2.T@delta_A3 # (200,20) (20,10) (200,10)\n",
    "        delta_Z2 = delta_A3@self.W3.T # (20,10) (10,200) (20,200)\n",
    "        \n",
    "        # ２層 \n",
    "        delta_A2 = delta_Z2*(1 - (self.Z2**2)) #(20,200) (20,200)\n",
    "        self.bias2 -= alpha * np.sum(delta_A2, axis=0) # (200,)\n",
    "        self.W2 -= alpha * self.Z1.T@delta_A2 # (400,20) (20,200) (400,200) \n",
    "        delta_Z1 = delta_A2@self.W2.T # (20,200) (200, 400) (20,400)\n",
    "        \n",
    "        #1層\n",
    "        # シグモイドの微分\n",
    "        delta_A1 = delta_Z1 * (1-self.Z1)*self.Z1 # (20,400) \n",
    "        self.bias1 -= alpha * np.sum(delta_A1, axis=0) # (400,)\n",
    "        self.W1 -= alpha * X.T@delta_A1 # (784, 20) (20,400) (784, 400)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 2.299703570160704, train_score0.11333333333333333, val_score0.1154\n",
      "train loss 2.209337854052349, train_score0.3725833333333333, val_score0.379\n",
      "train loss 1.3230934073594909, train_score0.6859583333333333, val_score0.6936\n",
      "train loss 0.8048595152882637, train_score0.7797708333333333, val_score0.7863\n",
      "train loss 0.6358169854169954, train_score0.8310625, val_score0.8305\n",
      "train loss 0.5375642227601893, train_score0.8542291666666667, val_score0.8528\n",
      "train loss 0.47119658319752555, train_score0.8718125, val_score0.8699\n",
      "train loss 0.42393044020658666, train_score0.8832083333333334, val_score0.8805\n",
      "train loss 0.39540081743117045, train_score0.8906666666666667, val_score0.887\n",
      "train loss 0.37472913813547154, train_score0.896625, val_score0.8921\n",
      "train loss 0.3586909527807854, train_score0.9004375, val_score0.8979\n",
      "train loss 0.3462259259220685, train_score0.9033125, val_score0.9011\n",
      "train loss 0.33610937019766146, train_score0.9060833333333334, val_score0.9041\n",
      "train loss 0.3273651300737275, train_score0.9081875, val_score0.9072\n",
      "train loss 0.31936804575506345, train_score0.9102083333333333, val_score0.9091\n",
      "train loss 0.3117191949032497, train_score0.9121458333333333, val_score0.9113\n",
      "train loss 0.3041650284939996, train_score0.9142291666666666, val_score0.9129\n",
      "train loss 0.29655942706382626, train_score0.9160625, val_score0.915\n",
      "train loss 0.28884872301785386, train_score0.9178958333333334, val_score0.9174\n",
      "train loss 0.2810636140014356, train_score0.9201458333333333, val_score0.9183\n",
      "train loss 0.2732997737031373, train_score0.9220208333333333, val_score0.9193\n",
      "train loss 0.2656815596394782, train_score0.9237291666666667, val_score0.9209\n",
      "train loss 0.25832191548942823, train_score0.9256666666666666, val_score0.9225\n",
      "train loss 0.2512962653112809, train_score0.9273958333333333, val_score0.9251\n",
      "train loss 0.24463677045889398, train_score0.9287708333333333, val_score0.9262\n",
      "train loss 0.23834050943471993, train_score0.9305625, val_score0.9277\n",
      "train loss 0.23238211261829614, train_score0.9322708333333334, val_score0.9285\n",
      "train loss 0.22672515340312938, train_score0.9334791666666666, val_score0.9295\n",
      "train loss 0.22133050133877172, train_score0.9351666666666667, val_score0.9308\n",
      "train loss 0.21616167709386067, train_score0.9365416666666667, val_score0.9329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nn = ScratchSimpleNeuralNetrowkClassifier(sigma=0.01, n_nodes1=400, n_nodes2=200,n_output=10,batch_size=20, epoch=30, verbose=True)\n",
    "nn.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n",
      "0.9329\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.predict(X_test)\n",
    "print(a)\n",
    "print(len(a[a == y_test]) / len(X_test))\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([5, 7, 6, 3, 0, 0, 4, 1, 8, 7, 7, 9, 1, 8, 1, 3, 5, 7, 4, 4],\n",
      "      dtype=uint8))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20, 784), (784, 400))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    pass\n",
    "\n",
    "# バッチサイズの20個を60000件の中から１個取り出している(max3000個)\n",
    "get_mini_batch[0][0].shape, W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(get_mini_batch[0][0]@W1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias1 = np.zeros((n_nodes1))\n",
    "#get_mini_batch[0][0]@bias1\n",
    "get_mini_batch[0][0].shape, bias1.shape\n",
    "\n",
    "(get_mini_batch[0][0]).shape\n",
    "((get_mini_batch[0][0]@W1) + bias1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = (get_mini_batch[0][0]@W1) + bias1\n",
    "np.tanh(nn).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(10):\n",
    "    np.exp(X_train[:, k])/ np.sum(np.exp(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(X_train[:, 1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(X_train).shape\n",
    "#20,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45486954.67838862"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.19843251e-08, 2.19843251e-08, 2.19843251e-08, ...,\n",
       "        2.19843251e-08, 2.19843251e-08, 2.19843251e-08],\n",
       "       [2.19843251e-08, 2.19843251e-08, 2.19843251e-08, ...,\n",
       "        2.19843251e-08, 2.19843251e-08, 2.19843251e-08],\n",
       "       [2.19843251e-08, 2.19843251e-08, 2.19843251e-08, ...,\n",
       "        2.19843251e-08, 2.19843251e-08, 2.19843251e-08],\n",
       "       ...,\n",
       "       [2.19843251e-08, 2.19843251e-08, 2.19843251e-08, ...,\n",
       "        2.19843251e-08, 2.19843251e-08, 2.19843251e-08],\n",
       "       [2.19843251e-08, 2.19843251e-08, 2.19843251e-08, ...,\n",
       "        2.19843251e-08, 2.19843251e-08, 2.19843251e-08],\n",
       "       [2.19843251e-08, 2.19843251e-08, 2.19843251e-08, ...,\n",
       "        2.19843251e-08, 2.19843251e-08, 2.19843251e-08]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.exp(X_train)/np.sum(np.exp(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.exp(X_train)/np.sum(np.exp(X_train), axis=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.exp(X_train)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 784), (10000, 784))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False,  True, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [ True, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False,  True, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False,  True, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(-1,1) == np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.79254585, -0.14509158, -1.28713287, ..., -2.81962169,\n",
       "        -1.14406001,  1.47568564],\n",
       "       [-1.32275668,  1.60840454,  1.18336099, ...,  0.67863041,\n",
       "         1.51854652, -0.70275234],\n",
       "       [ 0.44494317, -1.38090756,  0.34876935, ..., -0.4658047 ,\n",
       "         0.50559737,  0.89300135],\n",
       "       ...,\n",
       "       [-0.43481017, -0.22796111,  1.54043006, ...,  1.46430167,\n",
       "         1.25701103,  1.86759362],\n",
       "       [-0.14210812, -3.07987899, -0.32067736, ..., -0.53407238,\n",
       "         0.28473852, -1.91870176],\n",
       "       [-0.4993296 ,  0.47490048,  0.56264197, ..., -0.02634771,\n",
       "         0.22502908,  0.98097986]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((20, 10))\n",
    "log = np.zeros((20,10))\n",
    "np.random.randn(200, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-718076a99941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "np.exp(X - X_max)/ np.sum(np.exp(X - X_max), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.zeros((20,10))/20).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((2 / np.zeros((20,10))), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(X_test, axis=1)\n",
    "\n",
    "#np.argmax(self.foward(X), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】交差エントロピー誤差の実装\n",
    "目的関数（損失関数）を作成します。\n",
    "\n",
    "\n",
    "多クラス分類の目的関数である交差エントロピー誤差 \n",
    "L\n",
    " は次の数式です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 問題3\n",
    "def log_loss(self, X, y):\n",
    "    #y = (20, ) \n",
    "    # output_layer = (20,10) \n",
    "    self.loss = -(1/self.batch_size) * np.sum(y*np.log(self.forward(X)))\n",
    "    return self.loss\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】バックプロパゲーションの実装\n",
    "三層のニューラルネットワークのバックプロパゲーションを作成してください。確率的勾配降下法を行う部分です。\n",
    "\n",
    "\n",
    "数式を以下に示します。\n",
    "\n",
    "\n",
    "まず、i層目の重みとバイアスの更新式です。 \n",
    "W\n",
    "i\n",
    " と \n",
    "B\n",
    "i\n",
    " に対し、更新後の \n",
    "W\n",
    "′\n",
    "i\n",
    " と \n",
    "B\n",
    "′\n",
    "i\n",
    " は次の数式で求められます。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 問題4 \n",
    "def back_propagation(self, X, y, alpha):\n",
    "    # Z = sotmax(A) (20,10)\n",
    "    # A = zx+b (20,10)\n",
    "    # ３層\n",
    "    delta_A3 = (1/self.batch_size)*(self.Z3 - y) # (20,10) (20, 10)\n",
    "    self.bias3 -= alpha * np.sum(delta_A3, axis=0) # (10,)\n",
    "    self.W3 -= alpha * self.Z2.T@delta_A3 # (200,20) (20,10) (200,10)\n",
    "    delta_Z2 = delta_A3@self.W3.T # (20,10) (10,200) (20,200)\n",
    "        \n",
    "    # ２層 \n",
    "    delta_A2 = delta_Z2*(1 - (self.Z2**2)) #(20,200) (20,200)\n",
    "    self.bias2 -= alpha * np.sum(delta_A2, axis=0) # (200,)\n",
    "    self.W2 -= alpha * self.Z1.T@delta_A2 # (400,20) (20,200) (400,200) \n",
    "    delta_Z1 = delta_A2@self.W2.T # (20,200) (200, 400) (20,400)\n",
    "        \n",
    "    #1層\n",
    "    # シグモイドの微分\n",
    "    delta_A1 = delta_Z1 * (1-self.Z1)*self.Z1 # (20,400) \n",
    "    self.bias1 -= alpha * np.sum(delta_A1, axis=0) # (400,)\n",
    "    self.W1 -= alpha * X.T@delta_A1 # (784, 20) (20,400) (784, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】推定\n",
    "推定を行うメソッドを作成してください。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションによって出力された10個の確率の中で、最も高いものはどれかを判定します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        return np.argmax(self.forward(X), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】学習と推定\n",
    "MNISTのデータを学習・推定し、Accuracyを計算してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 2.300104491803988, train_score0.11225, val_score0.1135\n",
      "train loss 2.2503002803581533, train_score0.33129166666666665, val_score0.3296\n",
      "train loss 1.3948868541332324, train_score0.7021875, val_score0.7109\n",
      "train loss 0.7834597527719704, train_score0.7946666666666666, val_score0.8007\n",
      "train loss 0.6119719292209882, train_score0.8374583333333333, val_score0.8384\n",
      "train loss 0.524335243899074, train_score0.856875, val_score0.8566\n",
      "train loss 0.4684783214203002, train_score0.8730416666666667, val_score0.8701\n",
      "train loss 0.42677472529225646, train_score0.8820833333333333, val_score0.8795\n",
      "train loss 0.4020864086963545, train_score0.8875833333333333, val_score0.8848\n",
      "train loss 0.38458996475177787, train_score0.8922708333333333, val_score0.8893\n",
      "train loss 0.3692937357592445, train_score0.8969166666666667, val_score0.894\n",
      "train loss 0.3548978897102255, train_score0.9011458333333333, val_score0.8989\n",
      "train loss 0.341809835064269, train_score0.9043125, val_score0.9023\n",
      "train loss 0.3304356633983506, train_score0.9078541666666666, val_score0.9061\n",
      "train loss 0.3204435487353722, train_score0.9098125, val_score0.9089\n",
      "train loss 0.31126292416562096, train_score0.9122083333333333, val_score0.9117\n",
      "train loss 0.30246362213914846, train_score0.9141041666666667, val_score0.9132\n",
      "train loss 0.29381825514335685, train_score0.9165625, val_score0.9161\n",
      "train loss 0.2852781667658983, train_score0.91875, val_score0.9174\n",
      "train loss 0.27691511860498397, train_score0.921, val_score0.919\n",
      "train loss 0.268837779414957, train_score0.92275, val_score0.9211\n",
      "train loss 0.2611210595740079, train_score0.9242916666666666, val_score0.9231\n",
      "train loss 0.25378317655651106, train_score0.9266041666666667, val_score0.9249\n",
      "train loss 0.24680369287871454, train_score0.9284166666666667, val_score0.9263\n",
      "train loss 0.240149994590341, train_score0.9304791666666666, val_score0.9281\n",
      "train loss 0.23379274601267316, train_score0.9320416666666667, val_score0.9286\n",
      "train loss 0.22770989859105217, train_score0.933625, val_score0.93\n",
      "train loss 0.2218850259556787, train_score0.9352291666666667, val_score0.9318\n",
      "train loss 0.21630449051359504, train_score0.93675, val_score0.9331\n",
      "train loss 0.21095555767037563, train_score0.9387291666666666, val_score0.9351\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nn = ScratchSimpleNeuralNetrowkClassifier(sigma=0.01, n_nodes1=400, n_nodes2=200,n_output=10,batch_size=20, epoch=30, verbose=True)\n",
    "nn.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】学習曲線のプロット\n",
    "学習曲線をプロットしてください。\n",
    "\n",
    "\n",
    "ニューラルネットワークは過学習が発生しやすいため、学習曲線の確認が重要です。訓練データと検証データに対するエポックごとの損失（交差エントロピー誤差）を記録できるようにする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe49795b670>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdYklEQVR4nO3de5BcZ33m8e+v791zH2lGI81IlnzDkg0WWAhjbjJgY0MFYxaCTRIuu+A44BTs1qYg2UqWXWq3djewUAtmjcGu4EpYLxsIGMqJ411CgDgYy1iWLRkb3awZzV1z6Z7pe/e7f3RLHo9npBlPz5zp08+nqqv7nD7d/Xt1ah6/ft9zMeccIiLiDwGvCxARkdpRqIuI+IhCXUTERxTqIiI+olAXEfGRkFc/vHHjRrd9+3avfl5EpC49/vjj4865rsXe9yzUt2/fzv79+736eRGRumRmz5/rfQ2/iIj4iEJdRMRHFOoiIj6iUBcR8RGFuoiIjyjURUR8RKEuIuIjnh2nLiLiF+WyI1Mokc6XSOeLL3qezZXIFIrM5l5Yd9UFHbzpkkXPH1oRhbqI+E657MgWS2TyJbLFMtlCac6jfPY586L1L7yXOfO6WCI39zPFEtl8iUIhjyvkoJjFFXMEyjli5EmQI2HZyjNZmixHnCxNc9ZvsCynX/EOuOQPV6XtCnURWVPOOXLFMpl8idmzvdl5z/ki6dwL758N3XyJXKFAvpCnUChSKBTIFYtnX5eKeayQJVDOEaVAlDxRKxAjX10unF1OkCNmORLkiJOns/q6KZCnyfIkLE/cXvieiCsQokDY5QlQvbmQAeEltjsYg0gCIk3Y9tJq/fMq1EVkcaWyI1esDCHM5IrM5oqkssXK62yeTHqGXGaGQjpFPjtLMTdLKZ/FFbK4QgZXyEIxhytlsWKOQDFLoJwnQp44eeLkSFiOOJVHp+XpI0dszvoYBQJWJkj5hTA9lyWGLIDDcOEEhBNYZO5zK4Tj1UcCghEIxSB05jkKwehL10WaIdJU+cyZ15EEhJuw4NrErUJdpE6Vy450odK7PRO4M7kimXxl+CBT7eFmsjlKuRlK2RlcbgaXS0EhjeVnCBTSBAppgqU04VKaUClDpJQhWs4QcRniLns2XBPkaLc8W8hWe7mF5RcdqDxKFqIYjFEKJnChOOVqeFqkHYskCEaaCMaaCEabCIRjYEEIBOc8B15Ynvt6bsCG4tXn2Iufw/HK63ACC0Uxs5rvGy8p1EXWUL5YZiZXZCadJZ2aIDOTJJtNk8tmyWfT5HIZCrkMpVyGQj5LKZ+hVMhSLmShkIFilkAxS7CUJVjOEiVPrNrrjZEnZnk6yNFMloRlaSK7rPAtWph8IEYhlKAQilMMJiiFmnHh7rO92Fy0iVIkQSbWRDjeTKT6bNUeL+HYvCCdvxwlGAgSXMV/50amUBdZhHOObKFMKldgZjZNZjZFLjNLLpemkK08irkzjwzlQoZyPoPLpwnmk4Tz00SKSWLFFIlyiqbyDC3M0sYs2yzzsusqEaQQjFGKRCkFY5RD8cp4bTiOhTsh0kQg2oxFWyjHmsnHWgjFmwlEm6tDAnOGBSItZ8d5CTcRCkUUCnVO+098JV8sM5XOk8wWz07EZfIl0rk8+dkpyukpSplJyE5j2WkCuWksmyRUSBLOJ4kWU0RLKRLlGZrKM7RamlbSdFtu2bVkLUo60EI22EI+1kIhvJWZSBvJWBsu1kEg3kYo3kIkGicSixGJJojGm4jFYoQi8TljttE5wwZxgsGQermyKIW6rFulsiOZKTCVKTCZzjOVznN6Js/kbI7Z5DiF6VHczBiWHiecHSeWn6ClOMkGS9LOLG02S5/N0kqaZjIEbPFJthIB0tZENthMNtJKPtRCMbKFyUgbp2NtWKyVQKyFUCROMJogHE0QiSUIx+JE481EYwmCkUQ1fBMQayMWihJbw38vEVCoyxoqlsqMz+QZS+UYTWUZTeUYS+VIplIUUmOUZ09jmQlC2QnCuUlixWk6SNFpKTpIsclS7LIkG0gStpceEuYwsrE2ctFOirEOXLQHF2sjG2sjH+8gmGgn3NRBuLmTSFM7Fu+AWCvE2glGW2gxo8WDfxeRWlKoy4qVyo6xVI7hZJbh6SwjySzDyWwlsKcnYPoUkdkhmnMj9NhpNjPBZjvNHpugxyZoWWx8OQS5UCuFaAelWCckLiHY0k25rRvXuglr7oamjdDUBU1dWLyTeDBEfG2bL7KuKNTlnNL5IsPT2bOBPZzMMjKdZXg6Q3p6DDd9imhmhE1MsMkm2MwEO2yCa2yCzYFJmkm/8GXhSm86F9tIqXkLgfbdhDt6oXUzJDohseHFj1g70WCIqHfNF6k7CvUGNpMrcmoyw6mpNEPT1bBOZjk9OUVxeojAzBDN+XG6bZIem2STTXKVTdIbmKCbSSJUD5WrnuzhLEAx3gWtmwm17cba+qCtF1qrj7ZerLmHWCjiXaNFfE6h7mOzuSKnpjL0T6QZmMwwMJlm+PQ0+YmT2PRJWvMj9No4vXaarUzyWpugJzBFK7MvfEk1f0vBGOWmHgJtWwi2vxJaNlfDejO0bIHWLVjzJsJrdNaciCxMf4E+MTGb5+DAFAcHpjn6fD9u8HE6Mv1ssXF6bZwrbZx32jhdNv3Ch8LgCFBIbILWLYTaX0OgdTO09FRC++yjh2CsjaDPzrwT8SOFeh1KZQs8fSrJwYEpDvWPk+1/gp6Zw+wOHOW37Ag7AsOVDcNQCkQpNPcS6NhKuPMN0L4N2rdC21Zo68NatxAJLuNiGSKyrinU68SR0Rn+5lf9HHz6STonD7LbjrA3cJSPBk4QoQhhyMe7sb49sG0P9O6B7p0Em7rUwxZpIAr1dWxyNs+PDpzk8C//Lxee/kfeH3ycP7KRSg88GKe8+UrC226sBHjfHiKtvaAAF2loCvV1Jl8s87NDJ/jNIz+ge+j/8S57gt+zGUrhMMUL3gS7/gi2XU2waydBTUqKyDxKhXXAOcfh537D0Z//Ne39D/NG9xRvswKZcAu5HdfDq28iePHbCEZ1vqOInJtC3UPZTJonHrqPpqfu44riYS43x3ioh9ELP8iW1/0L4tuvIa5JTBFZBoW6B06fOsqRv/0KFw98j9czzanAZp6+9BPseNMH2Lj1VRoXF5GXTaG+Vspl+h//Ecmf3sVlyUfYAxxMvJ7ha25j1xveTW9AF1MVkZVTqK+y8uwExx6+m+anv8XW4iCnXSs/6/lddlx/B6++6DKvyxMRn1Gor5LC1CAn/88f03fqQS4mzwHbycGdn2TvjR9mX6smPEVkdSjUV0F+8ClS97yXLcUpfhx7K9HX38Yb33gtu0MBr0sTEZ9TqNdY/td/T+l/f5hCOcrDV9/Hb91wg+/uVi4i65dCvYbyv7iH4N/9W46Ut/LsW7/Jzfv2el2SiDQYhXotlMvkH/pTIo9+lR+XdjP9rq9z89WaBBWRtadQX6l8msJff5zIcz/ivtJ1tN/8RW5+zQVeVyUiDUqhvhKpEYrf/gDBoQN8vvghXvP+P+ZdV27xuioRaWBLOhzDzG4ws2fN7IiZfXaB99vM7Idm9qSZHTKzj9a+1HVm5DDlb7yV4tBhPlH8N+y99d8p0EXEc+cNdTMLAncCNwK7gFvNbNe8zT4JHHbOXQnsA75oZv69EeXRH1O+53qmUrN8sPhn/Pbv/j7vuLzH66pERJbUU98LHHHOHXPO5YH7gZvmbeOAFqscu9cMTADFmla6Xhz4Nu4v38fzxU7eW/g8n/7QB3jrZZu8rkpEBFhaqPcC/XOWB6rr5voqsBMYBJ4CPuWcK8//IjO7zcz2m9n+sbGxl1myh1IjuB/+aw4EdvL+wuf4zx+5kTdf2uV1VSIiZy0l1Bc6c8bNW34HcADYAuwGvmpmrS/5kHN3O+f2OOf2dHXVXxi6R75CuZTnTwof42v/ch/XXLzR65JERF5kKaE+AGyds9xHpUc+10eB77mKI8BxwF8Has+epvTLe/hh6Wo+/p7r2Luj0+uKREReYimh/hhwiZntqE5+3gI8MG+bk8DbAMxsE/AK4FgtC/Wa++c7CZQyfLfpFt6to1xEZJ0673Hqzrmimd0BPAQEgXudc4fM7Pbq+3cBnwf+wsyeojJc8xnn3Pgq1r22MpOUHv06D5Veyzv27SMU1IW5RGR9WtLJR865B4EH5627a87rQeD62pa2jjz6dUKFGf4q+gHuvarP62pERBalLuf5ZJMUH7mTh0tX8ZY3XUssrDsUicj6pVA/n8e+QSif5J7g+/idq3VNFxFZ3xTq55KbofRPX+EfSley95q30RzVpXJEZH1TqJ/L/nsJZie5m/fxkTfs8LoaEZHzUtdzMYUMpX/6H/yifAU7976dzib/XspGRPxDPfXFPP4tgukxvla+mY+/Wb10EakP6qkvpJij9PMv8yt3GX27r2dzW9zrikRElkQ99YU88ZcEZ4b4SuFmbt93kdfViIgsmXrq85UKlH/2JZ5yl9By+XXs2NjkdUUiIkumnvp8T95PINnPlwvv4Q/2Xex1NSIiy6Ke+lylIuWffZFnuRB38XVc0dvmdUUiIsuinvpcT3+XwORxvpy/iU9ce4nX1YiILJt66meUS7iffoGjdgGTW9+u66WLSF1ST/2Mw9/HTj/Hl3I38QfXXup1NSIiL4t66gDlMu6nX+BkoI8T3W9j3yvq71Z7IiKgnnrF8Z9go4f5Uvbd3H7tpZgtdFtWEZH1T6EOuNFnADjefjXvfOVmj6sREXn5FOrAcP9RMi7CrW/ZTTCgXrqI1C+FOpAdf55Bt4G3X97jdSkiIiuiUAcis0MMs5ENuryuiNQ5hTrQlB0mGenWBKmI1D2FejFPa2mCTEITpCJS/xTqqUECOMrNvV5XIiKyYg0f6vmJfgCCHVs9rkREZOUaPtSnh48DEO/a5nElIiIr1/Chnh57HoD2Ht2HVETqX8OHemGyn0nXzOauDV6XIiKyYg0f6oHkKQbdBnraYl6XIiKyYg0f6rHMEKeDXURDQa9LERFZsYYP9bbcCDPRTV6XISJSE40d6rkUTW6GfJOOURcRf2joUHfTA5UXbVu8LUREpEYaOtSTIycAiHRe4G0hIiI10tChnqqGenO3Ql1E/KGhQz07fpKSMzo3K9RFxB8aOtTL0/2M0kHfhlavSxERqYmGDvXwzCDDbKQtHva6FBGRmmjoUG/KDjMd1s0xRMQ/GjfUnaO9MEo6rptjiIh/LCnUzewGM3vWzI6Y2WcX2WafmR0ws0Nm9o+1LXMVzI4ToUCpRceoi4h/hM63gZkFgTuB64AB4DEze8A5d3jONu3A14AbnHMnzax7tQquldzESaJAoF03xxAR/1hKT30vcMQ5d8w5lwfuB26at80Hge85504COOdGa1tm7U0MVW+OsVE3xxAR/1hKqPcC/XOWB6rr5roU6DCzn5jZ42b2oYW+yMxuM7P9ZrZ/bGzs5VVcI+nREwC0bdruaR0iIrW0lFBf6NAQN285BFwFvAt4B/CnZnbpSz7k3N3OuT3OuT1dXV3LLraWCpP95FyY7p4+T+sQEaml846pU+mZzx147gMGF9hm3Dk3C8ya2U+BK4HnalLlKrDpAQZdJ33tca9LERGpmaX01B8DLjGzHWYWAW4BHpi3zQ+AN5lZyMwSwOuAZ2pbam1F00OMB7sJBxv3qE4R8Z/z9tSdc0UzuwN4CAgC9zrnDpnZ7dX373LOPWNmfwccBMrAN51zT69m4SvVkhvheHS312WIiNTUUoZfcM49CDw4b91d85b/HPjz2pW2ikoF2ssTZJt0jLqI+EtDjj2UpwcJUsa1KtRFxF8aMtSnz94cQ8eoi4i/NGaoD1dOPGru2u5tISIiNdaQoZ4ZPwlAx+YdHlciIlJbDRnq5amTTLsEPd3engAlIlJrDRnqoZkhhunSzTFExHcaMtTjmWGmwuqli4j/NGSotxdGmI31eF2GiEjNNV6o52dpdSmKLfMvNCkiUv8aLtTT488DEGjT1RlFxH8aLtQnByvHqMc2XuBxJSIitddwoZ6q3hyjRTfHEBEfarhQL0z0U3ZG15btXpciIlJzDRfqTA8wRhvd7S1eVyIiUnMNF+qR9CDjgW5CujmGiPhQwyVbS3aYZKTb6zJERFZFY4W6c3SWxsgmdB11EfGnhgr10uxpYuQp6+YYIuJTDRXqE0PHAAh16OYYIuJPDRXqZ26O0dStE49ExJ8aKtTTY7o5hoj4W0OFemmyn5wLsWnzVq9LERFZFQ0V6sHUKUZtA82xiNeliIisioYK9XhmiImQjlEXEf9qqFBvy48wG9vkdRkiIqumcUK9VKTTTVBo0s0xRMS/GibUU6cHCFHG2hTqIuJfDRPqE9WbY0Q36Bh1EfGvhgn11EjlbNJm3RxDRHysYUI9N9EPQFfvRR5XIiKyehom1JkaIOXibNyw0etKRERWTcOEenh2kNFAF4GAeV2KiMiqaZhQb84Ok4zoGHUR8beGCfWO4hjZeI/XZYiIrKqGCPVidpYOkpRadYy6iPhbQ4T6+GDlcMZgu67OKCL+1hChPjV8AoBEl048EhF/a4hQT4+eAKCtRzfHEBF/a4hQL0xWTjzq7lWoi4i/LSnUzewGM3vWzI6Y2WfPsd1rzaxkZu+rXYkrF0idYpx2Eokmr0sREVlV5w11MwsCdwI3AruAW81s1yLb/VfgoVoXuVKx9BATwS6vyxARWXVL6anvBY4454455/LA/cBNC2z3h8B3gdEa1lcTbfkRZqI6Rl1E/G8pod4L9M9ZHqiuO8vMeoGbgbvO9UVmdpuZ7Tez/WNjY8ut9WVx5TIbS2Pkmresye+JiHhpKaG+0MVS3LzlLwOfcc6VzvVFzrm7nXN7nHN7urrWZjgkNTlOwnK6OYaINITQErYZAOaetdMHDM7bZg9wv5kBbATeaWZF59z3a1LlCowNHqMViHRu87oUEZFVt5RQfwy4xMx2AKeAW4APzt3AOXf2WEEz+wvgR+sh0AGSI5U7HjV3b/e2EBGRNXDeUHfOFc3sDipHtQSBe51zh8zs9ur75xxH91pu/CQAG7Zc6HElIiKrbyk9dZxzDwIPzlu3YJg75z6y8rJqpzw9QN4F6eju87oUEZFV5/szSsMzpzgd2EAgGPS6FBGRVef7UE9kh5kK6+YYItIYfB/qHYVRMro5hog0CF+Hej5foMtNUGzRMeoi0hh8HepjQycJW4lguyZJRaQx+DrUJ4Yqx6jHN273thARkTXi61CfHTsBQGvPdk/rEBFZK74O9eJE5TpkG3sv8rgSEZG14etQt+QAs8SINXd4XYqIyJrwdahH0kOcDnaDLXShSRER//F1qLfmhklFdeKRiDQO34Z6Mp1ha2mAQrvG00Wkcfg21I8dfoKE5Yhs2+N1KSIia8a3oT519JcAbN75eo8rERFZO74N9cDQE8wSo2PrLq9LERFZM74N9Y3JwwzEXgEB3zZRROQlfJl4ydk0F5WOM7vhlV6XIiKypnwZ6scPP07UCsQuuMrrUkRE1pQvQ33q6KOAJklFpPH4MtSDQwdIkaCj7zKvSxERWVO+DPWu1GEG4pfp8gAi0nB8F+rJmRl2lE6Q3qhJUhFpPL4L9eOHf0nESsS2aZJURBqP70I9efQxALbsusbjSkRE1p7vQj04fIApWujYcrHXpYiIrDnfhXp36jCnNEkqIg3KV6GeTCXZXjqpSVIRaVi+CvUThx4lZGXi21/rdSkiIp7wVagnq5fb7b1ck6Qi0ph8FeqhkSc5TTsdmy7wuhQREU/4KtQ3pZ7hVOIVmiQVkYblm1Cfnp5kW7mfbNeVXpciIuIZ34T6yUOPEjRHfLvuSSoijcs3oZ46Vpkk7duly+2KSOPyTaiHRp5klA10bNrmdSkiIp7xTahvmnmGwYSuny4ijc0XoT49NcEF7hTZ7ld5XYqIiKd8Eer9Tz8CQEKTpCLS4HwR6qnjlcvtbtWZpCLS4JYU6mZ2g5k9a2ZHzOyzC7z/O2Z2sPp4xMzW9GDx8OiTDNFFR9eWtfxZEZF157yhbmZB4E7gRmAXcKuZ7Zq32XHgLc65VwGfB+6udaHn0jPzDENNO9fyJ0VE1qWl9NT3Akecc8ecc3ngfuCmuRs45x5xzk1WF38B9NW2zMVNT4zR54bJaZJURGRJod4L9M9ZHqiuW8y/Av52oTfM7DYz229m+8fGxpZe5Tn0H6pMkjbt0OV2RUSWEuoLXR3LLbih2bVUQv0zC73vnLvbObfHObenq6tr6VWew8zx/QBs0ySpiMiSQn0A2DpnuQ8YnL+Rmb0K+CZwk3PudG3KO7/I6JMMWA/tG7rX6idFRNatpYT6Y8AlZrbDzCLALcADczcws23A94Dfc849V/syF7d59hmGNUkqIgIsIdSdc0XgDuAh4BngO865Q2Z2u5ndXt3sz4ANwNfM7ICZ7V+1iudIjg+z2Y1qklREpCq0lI2ccw8CD85bd9ec1x8DPlbb0s6v//AjXA40a5JURASo8zNKZ6tnkmqSVESkoq5DPTJ6kOetl47ODV6XIiKyLtR1qG9Ja5JURGSuug315OgA3e40+U26J6mIyBl1G+r9h/8ZgNYLNUkqInJG3YZ6+sRjlJyxbdfrvC5FRGTdqNtQj40d5PlAHx0dnV6XIiKybtRnqDvHltlfM9I8/wrAIiKNrS5DfXr0JBuYpKBJUhGRF6nLUD9Vvdxu60WaJBURmasuQz39/H6KLsAFOzVJKiIyV12GenzsIMcD2+hob/O6FBGRdaX+Qt05etO/ZrRFk6QiIvPVXahPDx+jnSRFTZKKiLxE3YX64JkzSS/a63ElIiLrT92Fer5nN/dt+DTbd+rIFxGR+ZZ0k4z15MrLr+DKy6/wugwRkXWp7nrqIiKyOIW6iIiPKNRFRHxEoS4i4iMKdRERH1Goi4j4iEJdRMRHFOoiIj5izjlvfthsDHj+ZX58IzBew3LWA7+1yW/tAf+1yW/tAf+1aaH2XOCc61rsA56F+kqY2X7n3B6v66glv7XJb+0B/7XJb+0B/7Xp5bRHwy8iIj6iUBcR8ZF6DfW7vS5gFfitTX5rD/ivTX5rD/ivTctuT12OqYuIyMLqtacuIiILUKiLiPhI3YW6md1gZs+a2REz+6zX9dSCmZ0ws6fM7ICZ7fe6nuUys3vNbNTMnp6zrtPMHjaz31SfO7yscbkWadPnzOxUdT8dMLN3elnjcpjZVjP7BzN7xswOmdmnquvrcj+doz31vI9iZvZLM3uy2qb/UF2/rH1UV2PqZhYEngOuAwaAx4BbnXOHPS1shczsBLDHOVeXJ02Y2ZuBGeA+59wV1XX/DZhwzv2X6n98O5xzn/GyzuVYpE2fA2acc1/wsraXw8w2A5udc78ysxbgceA9wEeow/10jvb8NvW7jwxocs7NmFkY+DnwKeC9LGMf1VtPfS9wxDl3zDmXB+4HbvK4pobnnPspMDFv9U3At6qvv0XlD65uLNKmuuWcG3LO/ar6OgU8A/RSp/vpHO2pW65iproYrj4cy9xH9RbqvUD/nOUB6nxHVjng783scTO7zetiamSTc24IKn+AQLfH9dTKHWZ2sDo8UxdDFfOZ2Xbg1cCj+GA/zWsP1PE+MrOgmR0ARoGHnXPL3kf1Fuq2wLr6GT9a3Bucc68BbgQ+Wf1ff1l//idwEbAbGAK+6G05y2dmzcB3gU8755Je17NSC7SnrveRc67knNsN9AF7zeyK5X5HvYX6ALB1znIfMOhRLTXjnBusPo8Cf0NlmKnejVTHPc+Mf456XM+KOedGqn90ZeAb1Nl+qo7Tfhf4K+fc96qr63Y/LdSeet9HZzjnpoCfADewzH1Ub6H+GHCJme0wswhwC/CAxzWtiJk1VSd6MLMm4Hrg6XN/qi48AHy4+vrDwA88rKUmzvxhVd1MHe2n6iTcPcAzzrn/PuetutxPi7WnzvdRl5m1V1/HgbcDv2aZ+6iujn4BqB6i9GUgCNzrnPtPHpe0ImZ2IZXeOUAI+Ha9tcnM/hewj8plQkeAfw98H/gOsA04CbzfOVc3E4+LtGkflf+td8AJ4PfPjHWud2b2RuBnwFNAubr6T6iMQ9fdfjpHe26lfvfRq6hMhAapdLi/45z7j2a2gWXso7oLdRERWVy9Db+IiMg5KNRFRHxEoS4i4iMKdRERH1Goi4j4iEJdRMRHFOoiIj7y/wEsFEFPzqAm5wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracyスコア\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch = 30\n",
    "plt.plot(np.arange(epoch), nn.train_score_list)\n",
    "plt.plot(np.arange(epoch), nn.val_score_list)\n",
    "\n",
    "#train_score_list =[]\n",
    "#val_score_list = []\n",
    "#train_loss_list = [\n",
    "#val_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe497fd73d0>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trainデータ\n",
    "epoch = 30\n",
    "\n",
    "plt.plot(np.arange(epoch), nn.train_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
