{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 1\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -102.35  -87.35  -87.35  -87.35   20.65   30.65\n",
      "    69.65  -79.35   60.65  149.65  141.65   21.65 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -75.35\n",
      "   -69.35  -11.35   48.65   64.65  147.65  147.65  147.65  147.65  147.65\n",
      "   119.65   66.65  147.65  136.65   89.65  -41.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -56.35  132.65\n",
      "   147.65  147.65  147.65  147.65  147.65  147.65  147.65  147.65  145.65\n",
      "   -12.35  -23.35  -23.35  -49.35  -66.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35  113.65\n",
      "   147.65  147.65  147.65  147.65  147.65   92.65   76.65  141.65  135.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -25.35\n",
      "    50.65    1.65  147.65  147.65   99.65  -94.35 -105.35  -62.35   48.65\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "   -91.35 -104.35   48.65  147.65  -15.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35   33.65  147.65   84.65 -103.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35  -94.35   84.65  147.65  -35.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -70.35  135.65  119.65   54.65    2.65 -104.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35  -24.35  134.65  147.65  147.65   13.65\n",
      "   -80.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -60.35   80.65  147.65  147.65\n",
      "    44.65  -78.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -89.35  -12.35  146.65\n",
      "   147.65   81.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  143.65\n",
      "   147.65  143.65  -41.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35  -59.35   24.65   77.65  147.65\n",
      "   147.65  101.65 -103.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35  -66.35   42.65  123.65  147.65  147.65  147.65\n",
      "   144.65   76.65 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35  -81.35    8.65  115.65  147.65  147.65  147.65  147.65   95.65\n",
      "   -27.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -82.35\n",
      "   -39.35  107.65  147.65  147.65  147.65  147.65   92.65  -24.35 -103.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35  -87.35   65.65  113.65\n",
      "   147.65  147.65  147.65  147.65   89.65  -25.35  -96.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35  -50.35   66.65  120.65  147.65  147.65\n",
      "   147.65  147.65  138.65   27.65  -94.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35   30.65  147.65  147.65  147.65  106.65\n",
      "    29.65   26.65  -89.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]\n",
      " [-105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35 -105.35\n",
      "  -105.35]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "image = image.astype(np.float) # float型に変換\n",
    "image -= 105.35 # 意図的に負の小数値を作り出してみる\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()\n",
    "print(image) # 値を確認\n",
    "\n",
    "# plt.imshowには自動的に0~255に変換してくれてる（そもそもuintなのでそのままだとエラー）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 何故？\n",
    "plt.imshow(image, 'gray', vmin = 0, vmax = 255)\n",
    "plt.show()\n",
    "\n",
    "# 元々マイナスの数字なので、範囲が-105~145だが\n",
    "#0~255にするので、色の情報を失っている可能性あり\n",
    "\n",
    "\n",
    "plt.imshow(image, 'gray', vmin = -105, vmax = 150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# 前処理\n",
    "# DLでは0~1しか扱わないので画像データmaxの255でデータを割る\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "# one-hot変換\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ３層のネットワークをここで作る\n",
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose = True):\n",
    "        self.verbose = verbose\n",
    "        pass\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        pass\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチ\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([4, 1, 6, 2, 6, 5, 2, 6, 9, 0, 8, 7, 5, 0, 5, 7, 9, 5, 6, 3],\n",
      "      dtype=uint8))\n"
     ]
    }
   ],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】重みの初期値を決めるコードの作成\n",
    "ニューラルネットワークの各層の重みの初期値を決めるコードを作成してください。\n",
    "\n",
    "\n",
    "重みの初期値は様々な方法が提案されていますが、今回はガウス分布による単純な初期化を行います。バイアスに関しても同様です。\n",
    "\n",
    "\n",
    "以下のコードを参考にしてください。標準偏差の値sigmaはハイパーパラメータです。発展的な重みの初期化方法については次のSprintで扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "sigma = 0.01 # ガウス分布の標準偏差\n",
    "\n",
    "# 重みの初期値\n",
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "# W1: (784, 400)\n",
    "\n",
    "n_nodes2 = 200 # 自由(理由なし)\n",
    "W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "# W2: (400, 200)\n",
    "\n",
    "# バイアス\n",
    "bias1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "# baias1：（784, 400）\n",
    "\n",
    "bias2 = sigma * np.random.randn(n_nodes1, n_nodes1)\n",
    "# baias2：（400, 200）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】フォワードプロパゲーションの実装\n",
    "三層のニューラルネットワークの フォワードプロパゲーション を作成してください。以下の説明ではノード数は1層目は400、2層目は200としますが、変更しても構いません。\n",
    "\n",
    "\n",
    "各層の数式を以下に示します。今回はそれぞれの記号が表す配列が、実装上どのようなndarrayのshapeになるかを併記してあります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ３層のネットワークをここで作る\n",
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, sigma, n_nodes1, n_nodes2,n_output,batch_size, epoch, verbose = False):\n",
    "        self.verbose = verbose\n",
    "        self.sigma = sigma # ガウス分布の標準偏差\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch = epoch\n",
    "        self.n_output = n_output\n",
    "        self.W1 = self.sigma * np.random.randn(n_features, self.n_nodes1)# W1: (784, 400)\n",
    "        self.W2 = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2) # (400, 200)\n",
    "        self.W3 =  self.sigma * np.random.randn(self.n_nodes2, self.n_output) #(200, 10)\n",
    "        self.bias1 = self.sigma * np.random.randn(self.n_nodes1) # baias1：（784,）\n",
    "        self.bias3 = self.sigma * np.random.randn(self.n_output) # (10,)\n",
    "        self.bias2 = self.sigma * np.random.randn(self.n_nodes2) # \n",
    "        self.train_score_list =[]\n",
    "        self.val_score_list = []\n",
    "        self.train_loss_list = []\n",
    "        self.val_loss_list = []\n",
    "    \n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        #n_features = X.shape[1] #(784)\n",
    "         \n",
    "                \n",
    "        # ワンホット（ブロードキャスト版）\n",
    "        y_one_hot = y.reshape(-1,1) == np.arange(10) # (48000, 10)\n",
    "        y_val_one_hot = y_val.reshape(-1,1) == np.arange(10) # (12000, 10)\n",
    "        \n",
    "        \n",
    "        # エポックで学習\n",
    "        for epoch in range(self.epoch):\n",
    "            train_loss = 0\n",
    "            get_mini_batch = GetMiniBatch(X, y_one_hot, batch_size=self.batch_size)\n",
    "            # イテレーション\n",
    "            for mini_X_train, mini_y_train in get_mini_batch: # バッチサイズ20なら2400回繰り返し\n",
    "                self.forward(mini_X_train)\n",
    "                train_loss += self.log_loss(mini_X_train, mini_y_train)\n",
    "                self.back_propagation(mini_X_train, mini_y_train, alpha=0.01)\n",
    "           \n",
    "            # 問題6 accuracyのスコア\n",
    "            train_score = len(self.predict(X)[self.predict(X) == y]) / len(y)\n",
    "            self.train_score_list.append(train_score)\n",
    "            train_loss = train_loss/ len(get_mini_batch)\n",
    "            self.train_loss_list.append(train_loss)\n",
    "            \n",
    "            if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "                print(\"train loss {}, train_score{}\".format(train_loss,train_score))\n",
    "\n",
    "            \n",
    "        if X_val is not None and y_val is not None:\n",
    "            for epoch in range(self.epoch):\n",
    "                val_loss = 0\n",
    "                get_mini_batch = GetMiniBatch(X_val, y_val_one_hot, batch_size=self.batch_size)\n",
    "                for mini_X_train, mini_y_train in get_mini_batch:\n",
    "                    self.forward(mini_X_train)\n",
    "                    val_loss += self.log_loss(mini_X_train, mini_y_train)\n",
    "                    self.back_propagation(mini_X_train, mini_y_train, alpha=0.01)\n",
    "            \n",
    "                val_score = len(self.predict(X_val)[self.predict(X_val) == y_val]) / len(y_val)\n",
    "                self.val_score_list.append(val_score)\n",
    "                val_loss = val_loss / len(get_mini_batch)\n",
    "                self.val_loss_list.append(val_loss)\n",
    "            \n",
    "                if self.verbose:\n",
    "                #verboseをTrueにした際は学習過程などを出力する\n",
    "                    print(\"val loss {}, val_score{}\".format(val_loss, val_score))\n",
    "            \n",
    "                \n",
    "    \n",
    "    # 問題5\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        return np.argmax(self.forward(X), axis=1)\n",
    "   \n",
    "\n",
    "    # 問題2 \n",
    "    def forward(self, X):\n",
    "        self.a1 = X@self.W1 + self.bias1 #((20, 784), (784, 400)) + (400, ) (20, 400)\n",
    "        self.Z1 =  self.sigmoid(self.a1) \n",
    "        self.a2 = self.Z1@self.W2 + self.bias2 # (20, 400) (400, 200) + (200,) (20,200)\n",
    "        self.Z2 = np.tanh(self.a2)    \n",
    "        self.a3 = self.Z2@self.W3 + self.bias3  #  (20,200) (200,10)  + (10,) (20,10)\n",
    "        self.Z3= self.soft_max(self.a3) # (20,10) \n",
    "        return self.Z3\n",
    "        \n",
    "    # シグモイド関数\n",
    "    def sigmoid(self, X):\n",
    "        return 1/(1 + np.exp(-X))\n",
    "    \n",
    "    # ソフトマックス関数\n",
    "    def soft_max(self, X):\n",
    "        # オーバーフロー対策 \n",
    "        X_max = np.max(X) # (20,10)\n",
    "        return np.exp(X - X_max)/ np.sum(np.exp(X - X_max), axis=1, keepdims=True)\n",
    "        \n",
    "   # 問題3\n",
    "    def log_loss(self, X, y):\n",
    "        #y = (20, ) \n",
    "        # output_layer = (20,10) \n",
    "        self.loss = -(1/self.batch_size) * np.sum(y*np.log(self.forward(X)))\n",
    "        return self.loss\n",
    "    \n",
    "    # 問題4 \n",
    "    def back_propagation(self, X, y, alpha):\n",
    "        # Z = sotmax(A) (20,10)\n",
    "        # A = zx+b (20,10)\n",
    "        # ３層\n",
    "        delta_A3 = (1/self.batch_size)*(self.Z3 - y) # (20,10) (20, 10)\n",
    "        self.bias3 -= alpha * np.sum(delta_A3, axis=0) # (10,)\n",
    "        self.W3 -= alpha * self.Z2.T@delta_A3 # (200,20) (20,10) (200,10)\n",
    "        delta_Z2 = delta_A3@self.W3.T # (20,10) (10,200) (20,200)\n",
    "        \n",
    "        # ２層 \n",
    "        delta_A2 = delta_Z2*(1 - (self.Z2**2)) #(20,200) (20,200)\n",
    "        self.bias2 -= alpha * np.sum(delta_A2, axis=0) # (200,)\n",
    "        self.W2 -= alpha * self.Z1.T@delta_A2 # (400,20) (20,200) (400,200) \n",
    "        delta_Z1 = delta_A2@self.W2.T # (20,200) (200, 400) (20,400)\n",
    "        \n",
    "        #1層\n",
    "        # シグモイドの微分\n",
    "        delta_A1 = delta_Z1 * (1-self.Z1)*self.Z1 # (20,400) \n",
    "        self.bias1 -= alpha * np.sum(delta_A1, axis=0) # (400,)\n",
    "        self.W1 -= alpha * X.T@delta_A1 # (784, 20) (20,400) (784, 400)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 2.2992312037627447, train_score0.23510416666666667\n",
      "train loss 2.223309200157625, train_score0.3470416666666667\n",
      "train loss 1.3215123453880833, train_score0.7014791666666667\n",
      "train loss 0.7798981645024985, train_score0.7930625\n",
      "train loss 0.6130914190257762, train_score0.8371666666666666\n",
      "train loss 0.5301040502480712, train_score0.8554791666666667\n",
      "train loss 0.47812802961289547, train_score0.8726041666666666\n",
      "train loss 0.4302968885247707, train_score0.8840833333333333\n",
      "train loss 0.3984892288462972, train_score0.8914166666666666\n",
      "train loss 0.37723641570344846, train_score0.8966875\n",
      "train loss 0.35992122753839106, train_score0.901125\n",
      "train loss 0.34548824897680624, train_score0.9043125\n",
      "train loss 0.3337522086729263, train_score0.90725\n",
      "train loss 0.3240272739646914, train_score0.9100208333333333\n",
      "train loss 0.31555005421184906, train_score0.9122916666666666\n",
      "train loss 0.30773946878823166, train_score0.9143958333333333\n",
      "train loss 0.30020103619270994, train_score0.91675\n",
      "train loss 0.29269375551296517, train_score0.918375\n",
      "train loss 0.285111699596359, train_score0.9201041666666666\n",
      "train loss 0.2774726368858426, train_score0.922125\n",
      "train loss 0.2698853871803316, train_score0.9241458333333333\n",
      "train loss 0.26248933818178044, train_score0.9258125\n",
      "train loss 0.2553958508836765, train_score0.9276875\n",
      "train loss 0.24866246797573335, train_score0.9293333333333333\n",
      "train loss 0.24229894501861768, train_score0.9308125\n",
      "train loss 0.23628433036667057, train_score0.9320833333333334\n",
      "train loss 0.2305821814640783, train_score0.9334375\n",
      "train loss 0.22515150646562718, train_score0.9348958333333334\n",
      "train loss 0.2199537920423118, train_score0.9360416666666667\n",
      "train loss 0.21495678199959362, train_score0.9375416666666667\n",
      "val loss 0.2182131028548824, val_score0.9365\n",
      "val loss 0.21133886197340368, val_score0.9383\n",
      "val loss 0.20649944566969597, val_score0.9392\n",
      "val loss 0.2024834038775738, val_score0.9398\n",
      "val loss 0.198940161821377, val_score0.9405\n",
      "val loss 0.1957144373004301, val_score0.9417\n",
      "val loss 0.19272143628581004, val_score0.9429\n",
      "val loss 0.1899092124544516, val_score0.9442\n",
      "val loss 0.18724333764317344, val_score0.9449\n",
      "val loss 0.18469961427491682, val_score0.9452\n",
      "val loss 0.1822602417057526, val_score0.9459\n",
      "val loss 0.17991164168403906, val_score0.9469\n",
      "val loss 0.1776431503557239, val_score0.9472\n",
      "val loss 0.17544619299815, val_score0.9482\n",
      "val loss 0.17331374141808303, val_score0.9482\n",
      "val loss 0.171239943833902, val_score0.949\n",
      "val loss 0.1692198640147889, val_score0.9497\n",
      "val loss 0.16724929210391146, val_score0.9504\n",
      "val loss 0.16532460402352803, val_score0.9508\n",
      "val loss 0.16344265475849357, val_score0.9521\n",
      "val loss 0.1616006958428249, val_score0.9529\n",
      "val loss 0.1597963104911043, val_score0.9534\n",
      "val loss 0.15802736182031132, val_score0.9542\n",
      "val loss 0.15629195093982826, val_score0.9544\n",
      "val loss 0.15458838259766078, val_score0.9547\n",
      "val loss 0.15291513670483842, val_score0.9553\n",
      "val loss 0.1512708445061092, val_score0.956\n",
      "val loss 0.14965426848019703, val_score0.9564\n",
      "val loss 0.14806428527553583, val_score0.9568\n",
      "val loss 0.14649987114501872, val_score0.9571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nn = ScratchSimpleNeuralNetrowkClassifier(sigma=0.01, n_nodes1=400, n_nodes2=200,n_output=10,batch_size=20, epoch=30, verbose=True)\n",
    "nn.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 4 5 6]\n",
      "0.9571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.predict(X_test)\n",
    "print(a)\n",
    "print(len(a[a == y_test]) / len(X_test))\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([4, 1, 6, 2, 6, 5, 2, 6, 9, 0, 8, 7, 5, 0, 5, 7, 9, 5, 6, 3],\n",
      "      dtype=uint8))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20, 784), (784, 400))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    pass\n",
    "\n",
    "# バッチサイズの20個を60000件の中から１個取り出している(max3000個)\n",
    "get_mini_batch[0][0].shape, W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(get_mini_batch[0][0]@W1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias1 = np.zeros((n_nodes1))\n",
    "#get_mini_batch[0][0]@bias1\n",
    "get_mini_batch[0][0].shape, bias1.shape\n",
    "\n",
    "(get_mini_batch[0][0]).shape\n",
    "((get_mini_batch[0][0]@W1) + bias1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 400)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = (get_mini_batch[0][0]@W1) + bias1\n",
    "np.tanh(nn).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(10):\n",
    "    np.exp(X_train[:, k])/ np.sum(np.exp(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(X_train[:, 1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(X_train).shape\n",
    "#20,10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45474167.09579028"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.exp(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.19905072e-08, 2.19905072e-08, 2.19905072e-08, ...,\n",
       "        2.19905072e-08, 2.19905072e-08, 2.19905072e-08],\n",
       "       [2.19905072e-08, 2.19905072e-08, 2.19905072e-08, ...,\n",
       "        2.19905072e-08, 2.19905072e-08, 2.19905072e-08],\n",
       "       [2.19905072e-08, 2.19905072e-08, 2.19905072e-08, ...,\n",
       "        2.19905072e-08, 2.19905072e-08, 2.19905072e-08],\n",
       "       ...,\n",
       "       [2.19905072e-08, 2.19905072e-08, 2.19905072e-08, ...,\n",
       "        2.19905072e-08, 2.19905072e-08, 2.19905072e-08],\n",
       "       [2.19905072e-08, 2.19905072e-08, 2.19905072e-08, ...,\n",
       "        2.19905072e-08, 2.19905072e-08, 2.19905072e-08],\n",
       "       [2.19905072e-08, 2.19905072e-08, 2.19905072e-08, ...,\n",
       "        2.19905072e-08, 2.19905072e-08, 2.19905072e-08]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.exp(X_train)/np.sum(np.exp(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.exp(X_train)/np.sum(np.exp(X_train), axis=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 784)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(np.exp(X_train)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 784), (10000, 784))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平滑化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ...,  True, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(-1,1) == np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.79254585, -0.14509158, -1.28713287, ..., -2.81962169,\n",
       "        -1.14406001,  1.47568564],\n",
       "       [-1.32275668,  1.60840454,  1.18336099, ...,  0.67863041,\n",
       "         1.51854652, -0.70275234],\n",
       "       [ 0.44494317, -1.38090756,  0.34876935, ..., -0.4658047 ,\n",
       "         0.50559737,  0.89300135],\n",
       "       ...,\n",
       "       [-0.43481017, -0.22796111,  1.54043006, ...,  1.46430167,\n",
       "         1.25701103,  1.86759362],\n",
       "       [-0.14210812, -3.07987899, -0.32067736, ..., -0.53407238,\n",
       "         0.28473852, -1.91870176],\n",
       "       [-0.4993296 ,  0.47490048,  0.56264197, ..., -0.02634771,\n",
       "         0.22502908,  0.98097986]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((20, 10))\n",
    "log = np.zeros((20,10))\n",
    "np.random.randn(200, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-718076a99941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mX_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "np.exp(X - X_max)/ np.sum(np.exp(X - X_max), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.zeros((20,10))/20).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-46-8d51c995a679>:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  np.sum((2 / np.zeros((20,10))), axis=0).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((2 / np.zeros((20,10))), axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([355,  97, 406, ..., 711, 464,  75])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(X_test, axis=1)\n",
    "\n",
    "#np.argmax(self.foward(X), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】交差エントロピー誤差の実装\n",
    "目的関数（損失関数）を作成します。\n",
    "\n",
    "\n",
    "多クラス分類の目的関数である交差エントロピー誤差 \n",
    "L\n",
    " は次の数式です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 問題3\n",
    "def log_loss(self, X, y):\n",
    "    #y = (20, ) \n",
    "    # output_layer = (20,10) \n",
    "    self.loss = -(1/self.batch_size) * np.sum(y*np.log(self.forward(X)))\n",
    "    return self.loss\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】バックプロパゲーションの実装\n",
    "三層のニューラルネットワークのバックプロパゲーションを作成してください。確率的勾配降下法を行う部分です。\n",
    "\n",
    "\n",
    "数式を以下に示します。\n",
    "\n",
    "\n",
    "まず、i層目の重みとバイアスの更新式です。 \n",
    "W\n",
    "i\n",
    " と \n",
    "B\n",
    "i\n",
    " に対し、更新後の \n",
    "W\n",
    "′\n",
    "i\n",
    " と \n",
    "B\n",
    "′\n",
    "i\n",
    " は次の数式で求められます。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 問題4 \n",
    "def back_propagation(self, X, y, alpha):\n",
    "    # Z = sotmax(A) (20,10)\n",
    "    # A = zx+b (20,10)\n",
    "    # ３層\n",
    "    delta_A3 = (1/self.batch_size)*(self.Z3 - y) # (20,10) (20, 10)\n",
    "    self.bias3 -= alpha * np.sum(delta_A3, axis=0) # (10,)\n",
    "    self.W3 -= alpha * self.Z2.T@delta_A3 # (200,20) (20,10) (200,10)\n",
    "    delta_Z2 = delta_A3@self.W3.T # (20,10) (10,200) (20,200)\n",
    "        \n",
    "    # ２層 \n",
    "    delta_A2 = delta_Z2*(1 - (self.Z2**2)) #(20,200) (20,200)\n",
    "    self.bias2 -= alpha * np.sum(delta_A2, axis=0) # (200,)\n",
    "    self.W2 -= alpha * self.Z1.T@delta_A2 # (400,20) (20,200) (400,200) \n",
    "    delta_Z1 = delta_A2@self.W2.T # (20,200) (200, 400) (20,400)\n",
    "        \n",
    "    #1層\n",
    "    # シグモイドの微分\n",
    "    delta_A1 = delta_Z1 * (1-self.Z1)*self.Z1 # (20,400) \n",
    "    self.bias1 -= alpha * np.sum(delta_A1, axis=0) # (400,)\n",
    "    self.W1 -= alpha * X.T@delta_A1 # (784, 20) (20,400) (784, 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】推定\n",
    "推定を行うメソッドを作成してください。\n",
    "\n",
    "\n",
    "フォワードプロパゲーションによって出力された10個の確率の中で、最も高いものはどれかを判定します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        return np.argmax(self.forward(X), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】学習と推定\n",
    "MNISTのデータを学習・推定し、Accuracyを計算してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 2.299240577180339, train_score0.10391666666666667\n",
      "train loss 2.200932481321529, train_score0.3679791666666667\n",
      "train loss 1.3155192218453537, train_score0.6859375\n",
      "train loss 0.8033320589912045, train_score0.7790833333333333\n",
      "train loss 0.6321418364639254, train_score0.8339166666666666\n",
      "train loss 0.5328054276589469, train_score0.8575625\n",
      "train loss 0.46709195747024085, train_score0.8765208333333333\n",
      "train loss 0.41952215012561617, train_score0.8861041666666667\n",
      "train loss 0.39047992167144374, train_score0.8932083333333334\n",
      "train loss 0.36961050261507084, train_score0.8988541666666666\n",
      "train loss 0.3535688376887054, train_score0.9023125\n",
      "train loss 0.3411305453047734, train_score0.9052708333333334\n",
      "train loss 0.3310593724481137, train_score0.9083125\n",
      "train loss 0.3224257241641212, train_score0.9104375\n",
      "train loss 0.31461689833536705, train_score0.912125\n",
      "train loss 0.3072217651969324, train_score0.9143125\n",
      "train loss 0.299969660236312, train_score0.9163125\n",
      "train loss 0.292702030733571, train_score0.9183958333333333\n",
      "train loss 0.2853592508648166, train_score0.9200833333333334\n",
      "train loss 0.2779684529977094, train_score0.9220416666666666\n",
      "train loss 0.2706190373463062, train_score0.9236041666666667\n",
      "train loss 0.26342438975473925, train_score0.9255625\n",
      "train loss 0.25648322284615066, train_score0.927375\n",
      "train loss 0.24985715923619903, train_score0.92925\n",
      "train loss 0.24356830871278135, train_score0.93075\n",
      "train loss 0.2376083160224855, train_score0.9320208333333333\n",
      "train loss 0.23194994509248665, train_score0.9333541666666667\n",
      "train loss 0.2265570051479153, train_score0.9348958333333334\n",
      "train loss 0.22139155720969542, train_score0.9361041666666666\n",
      "train loss 0.21641856386019853, train_score0.9377291666666666\n",
      "val loss 0.21991364839211988, val_score0.9374\n",
      "val loss 0.21273156880584995, val_score0.9382\n",
      "val loss 0.20788355922932136, val_score0.9397\n",
      "val loss 0.203887912277865, val_score0.9406\n",
      "val loss 0.20036000358201933, val_score0.9413\n",
      "val loss 0.19714296120151534, val_score0.9422\n",
      "val loss 0.19415424237663764, val_score0.9427\n",
      "val loss 0.191343689420203, val_score0.9433\n",
      "val loss 0.18867801703358486, val_score0.9442\n",
      "val loss 0.18613375374191793, val_score0.9448\n",
      "val loss 0.18369356697886619, val_score0.9453\n",
      "val loss 0.18134417692955773, val_score0.9458\n",
      "val loss 0.17907509862208523, val_score0.9465\n",
      "val loss 0.17687784719884547, val_score0.947\n",
      "val loss 0.1747454159991008, val_score0.9475\n",
      "val loss 0.17267192214278038, val_score0.9484\n",
      "val loss 0.170652358583639, val_score0.9491\n",
      "val loss 0.16868241587346894, val_score0.9495\n",
      "val loss 0.1667583507778188, val_score0.9503\n",
      "val loss 0.16487688714093318, val_score0.9509\n",
      "val loss 0.16303513945492523, val_score0.9518\n",
      "val loss 0.16123055276317352, val_score0.9526\n",
      "val loss 0.15946085456227763, val_score0.9531\n",
      "val loss 0.157724015693942, val_score0.954\n",
      "val loss 0.1560182180985061, val_score0.9547\n",
      "val loss 0.1543418278959385, val_score0.9553\n",
      "val loss 0.15269337266824293, val_score0.9554\n",
      "val loss 0.1510715221028211, val_score0.9557\n",
      "val loss 0.14947507135999313, val_score0.9563\n",
      "val loss 0.14790292667572988, val_score0.9567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "nn = ScratchSimpleNeuralNetrowkClassifier(sigma=0.01, n_nodes1=400, n_nodes2=200,n_output=10,batch_size=20, epoch=30, verbose=True)\n",
    "nn.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】学習曲線のプロット\n",
    "学習曲線をプロットしてください。\n",
    "\n",
    "\n",
    "ニューラルネットワークは過学習が発生しやすいため、学習曲線の確認が重要です。訓練データと検証データに対するエポックごとの損失（交差エントロピー誤差）を記録できるようにする必要があります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdd4e23bf10>]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbfklEQVR4nO3de5hcd33f8fd3bnuVrJV2JdvSSivLso242AZhTAnBEAKGlpjQhNoQIJTEIQEe8k8fnPRpoOXpLS40JYY4juOCWxqXFANuauJwLZSLsQzG8oWVZElrrS6r3ZVWWs1e5vbtH3Nmd3Y0K81Ks54953xezzPPnNuc+R6dZz767W9+c465OyIiEg2JVhcgIiLNo1AXEYkQhbqISIQo1EVEIkShLiISIalWvXFvb68PDAy06u1FRELp8ccfH3P3vsXWtyzUBwYG2LVrV6veXkQklMxs6Fzr1f0iIhIhCnURkQhRqIuIRIhCXUQkQhTqIiIRolAXEYkQhbqISIS0bJy6iMii3KFUhFJh/uGlYDpY7sVguhhMF8qvw+f3Mb/DmmVennYv77fyoHq+avqs9y1VTQfr5rYtLtynl8rbVe9v842w7Q3L8k+nUBdZ6RaEW7F+mFWCpLJdMQfFApTyUMwHz5X5qnWlQrC+sp/KskLVfHHhe1cHV3U9c3UV6rxnvs7y6kdtgBdb/a++vF7zhwp1ibhSqeZDXh1g1R/8OiGyoIVUva5UE0LF+mF0VvgsFkaLBFC9+QUttNpWm58dwme9R9U8LbqRjSUhkap6JIJlSbDKdPWy4DmRgmQaEunyc6qtaj41v3zBvlPzrz1rWdVyS8wvn6uv6v0t6FE2qz6QmmWV+UTwsJrnRHmbyrK59w3eb+59E1XzVcdvNl9L9WPu3626tuZTqL9Q3KsCo7bVkq/TCqoKpdp1ta2is1puxbPDoZg7RwsqX/P62pZfndZhI3XWC1ovnb19qUjLgutcLHl2GC0aQMmzg8jSdT7QNUGSqNpvMjU/Xz29YP/VwVITKtWhl8zMB+dZgVpZl6wfsMn0/P4ldMIX6qUiFGYba+GUCuVtCzPzj/zMIvOzQfCd70/GJbTYqvezUv6ctMTCD3LlA1+v5VHb+rKqsFrQWktWBVcDLbkFQVcbhrXT1a20xd6rsqzeewUtp9pl1fs517+HSBO4O7OFErP5EtP5Ih3pJJd0ppflvcIX6s98Df7X+5u7z1R7+U/Eyoe7+k/H2j8ZU+01LZtztNgqLb26f3rW+VP0rLBL1gnGxYI3tXB9dR3JoHWWSCuoJLYKxRK5YjlYZwslZvLFueeZfJGZQonZ4HkmX2Q2WF955IslcoX5R75YYrZm2UyhyHRu4X6ng/1Uf2/7+zdt42M3X7Msxxm+UN/wEnjjJxb/M7V2PpWBVEc5tNPBc6q96tG27H1cIgLFkjOdLzKVKzCdKzKTLzFbOP9zJYRzhRK5YnE+RIOAzhWr1hfKr1mwLnguli6uiy+TTJBOGplUYv6RTJBJJcmkErQlE3S3pejtbqM9naQ9laAjk5ybbksH0+kEL7n8kib9q54tfKHed1X5ISJNlS+WmJotMpUvMJUrtzincuUQrrQ4p3Ol4LmwYH6mEtb50ty6yj4q07lC6YJrSyeNtiA8y0GaWDDdlkqwqj1FWyoxt11ban5d7bJMKkF7aj5kK89tqernJG3p4DXJBBaSxl/4Ql0kZir9sdO5IlNBoE7liguCNxu0fstBW2QmaOFWugDmuwPKXQQz+XJXQyW0p/NF8sWltWSTCaMznaQ9k6QjnaQzk6QtnaQznWTDqjQdVcvbM0k60yk6Mgk6Mik60uV1banEXHi2p+o/Z5IJEolwBOpKoFAXaYJcELrZucCdf87OFhesy84WqsK0FHRFzPe/VsJ3umqZL7HnoNIqnWuJVrVKu9tSrOsqT3dmknRmUnRkymHcEcx3ZirT5UdHOjU33x4EcjppoWm9xolCXWKj0uKtDs3pIFzPzM4Hbna2QLYqfMvz8+E8lS+UuymqwruwhP7aVMLmwrQSku3pcv/rJR1p2jNJ2lPJcqt2rh+2KmAzKTrTyargXRjC7amkWrYxplCXFWsmX+TUdJ6JqTynpvOcns6f1drN5soBu+A56JZY2PotdzsspcWbShhdbSm6Mkk6g+eOTJINq9rpWJdcEMxzYRtMd2VSdLaV11e/vjOTIpPSCCRZPgp1WTbu5dEOp6YroVyoms7XnT41nWcieG7ki7W2VIKutlRNkCbp6cyURx5Uj0CotIjT810I7eny68vhXd5Pd1t5P2H6ckykQqEuDTs9k2dscpaTUzlOZPOcnMpxMpvj5FSek9kcJ6ZyTEzlOJHNMTGV5/RM/rxfvq1qS7G6I80lHWnWdKa5cn03lwTzl3Sm56c70qxuT9PdnpoP73SSVFKtXpFqCnWZc2o6z+GT0wyfnGL45HTwmJp7Pj1TqPu6TDLBms40a7sy9HRmuPrSVazpzCwI47npjtTc9Kr2NEn1/Yo0lUI9ZqZyBfaPZnlu9AzPBc/7R7MMn5xisia0OzNJNvV0sKmnk50DPWxc08GG1e30dGXo6UzT05mhpytDVyapbgqRFUKhHlEnsjkGj00G4R0E+PEzHJ6YntsmYbB5bSdbe7u4YaCHTT2dcyG+qaeDNZ1phbVIyCjUI2A6V+SpI6f4+aEJnjg0wc+HJzh0Yj68OzNJtvV188qBHm7t6+fK9d1sW9/NlnWdtKWSLaxcRJpNoR4yxZKz9/hkEOCneOLQBHtGJueua7FxTQfX9a/hPTdu4UWXrebK9d1curpdLW6RmFCoh8Tu4VPc/6ODPLz7KNlc+TK+q9tTXNu/hje+aBvX9a/hZZvW0LeqrbWFikhLKdRXsNlCkYd3H+X+Hw3xs+cn6Egn+bVrL+fGbWu5rr+HgXWdaoGLyAIK9RXo8MQ0X/zxEP/zsUOMZ3Nc0dvFx9+2g3/6ik2sbl+eC+uLSDQo1FcId+cH+8b5wo8O8q1nRwD4lRdt4L2v3sJrtvXqWh4i0hCFeovNFop8adcw//UHB9g/mmVtV4YPvm4b73rVZjb1dLa6PBEJGYV6ixSKJR782WH+yzf3cnhimmv71/Dpd17LW196Ge1pDTMUkQujUH+BlUrO1586xqe+Mcj+0Swv3XgJ//4dL+W123v1paeIXDSF+gvE3fnu4Ch3PjLIM0dPs319N3f/1st584svVZiLSNMo1F8Aj+4f585HBtk1dJL+tR18+p3Xcst1G3UxKxFpOoX6MnpyeII7Hxnk+3vHWL+qjU++/SX8s539ukmCiCwbhfoy+eKjQ/zLrzzFms40f/zWa3jPjQN0ZPQFqIgsL4X6Mvjhc2P8ydee5nVX9XHXu65nlX4wJCIvEPUDNNnQeJY/+OJP2drbxZ8r0EXkBaZQb6LJmTwf+MIu3OHe9+7UT/pF5AWn7pcmKZacjz7wBAfGsvy3f34DA71drS5JRGKooZa6md1sZoNmts/M7qiz/hIz+99m9nMze9rM3t/8Ule2P/37X/DtXxznE2/bwT+6srfV5YhITJ031M0sCXwWeAuwA7jNzHbUbPYh4Bl3vxa4CfiUmWWaXOuK9eXHh/nL7+3nt27czHtePdDqckQkxhppqd8A7HP3/e6eAx4AbqnZxoFVVv5pZDdwAqh/6/mI+enzJ/mjB3fz6ivW8fG3vbjV5YhIzDUS6huBQ1Xzw8GyancBLwKOALuBj7p7qSkVrmBHJqa5/f7HufSSdj737peTTup7ZxFprUZSqN5v2b1m/s3AE8DlwHXAXWa2+qwdmd1uZrvMbNfo6OiSi11JpnIFfvf+Xczki9z7vp30dMWmt0lEVrBGQn0Y6K+a30S5RV7t/cCDXrYPOABcU7sjd7/H3Xe6+86+vr4Lrbnl3J1/8bdP8szR03zmtuu4asOqVpckIgI0FuqPAdvNbGvw5eetwEM12zwP/AqAmW0Argb2N7PQleQz39rH/9l9lDtuvoY3XLOh1eWIiMw57zh1dy+Y2YeBR4AkcJ+7P21mHwzW3w18Evi8me2m3F3zMXcfW8a6W+bru4/yn7+5h3dcv5Hbf/mKVpcjIrJAQz8+cveHgYdrlt1dNX0EeFNzS1t5zswW+KOv7Oba/jX8u3e8VNdBF5EVR78oXYL//uMhJqbyfP79L9Yt50RkRdIYvAZN54rc+/39vHZ7L9f1r2l1OSIidSnUG/Q3P3mesTM5PvKG7a0uRURkUQr1BswWivzl957jVVvXcsPWta0uR0RkUQr1BvztrmFGTs+qlS4iK55C/TzyxRJ/8d3nuH7zGl5z5bpWlyMick4K9fP46s8Oc3himo+84UoNYRSRFU+hfg7FkvO57z7Hiy9fzeuvXt/qckREzkuhfg5/9+QRDoxl1UoXkdBQqC+iVHI++519XLWhmzftuLTV5YiINEShvoh/eOYYe0bO8KHXX0kioVa6iISDQr0Od+fPv72Prb1d/JOXXd7qckREGqZQr+M7g8d5+shp/uCmbSTVSheREFGo13B3PvOtfWzq6eDt19fetU9EZGVTqNf4wb5xnjg0we/ftE33HBWR0FFq1fjMt/dy6ep2fuMVm1pdiojIkinUqzy6f5yfHDjB773uCtpSul66iISPQr3KXd/ZR293hltfubnVpYiIXBCFeuCJQxN8f+8Yv/vaK+jIqJUuIuGkUA/c9e29rOlM8+4bt7S6FBGRC6ZQB35x7DTffPY4H3jNVrrbdNtWEQkvhTrw6P4TALzzlf0trkRE5OIo1IGD41m6MknWr2prdSkiIhdFoQ4cHMuyZV2XLq8rIqGnUAeGxqfY2tvV6jJERC5a7EO9UCzx/IkptqzrbHUpIiIXLfahfmRihkLJGVinlrqIhF/sQ/3geBaAAXW/iEgEKNQroa7uFxGJAIX62BSdmSR9Gs4oIhGgUB/XcEYRiQ6F+niWrb3qehGRaIh1qBeKJQ6dmGKLRr6ISETEOtSPnpohX3S2KtRFJCJiHeoHxsojX/TDIxGJiliH+pDGqItIxMQ61A+MTdGR1tUZRSQ6Yh3qQ+NZtqzr1HBGEYmMhkLdzG42s0Ez22dmdyyyzU1m9oSZPW1m/7e5ZS6PA+NZXZ1RRCLlvKFuZkngs8BbgB3AbWa2o2abNcDngF9z9xcDv7kMtTZVseQazigikdNIS/0GYJ+773f3HPAAcEvNNu8CHnT35wHc/Xhzy2y+IxPT5eGM+uGRiERII6G+EThUNT8cLKt2FdBjZt81s8fN7L31dmRmt5vZLjPbNTo6emEVN0nlQl5qqYtIlDQS6vW+RfSa+RTwCuAfA28G/pWZXXXWi9zvcfed7r6zr69vycU208HxKQD1qYtIpKQa2GYY6K+a3wQcqbPNmLtngayZfQ+4FtjTlCqXwcGxLO3phIYzikikNNJSfwzYbmZbzSwD3Ao8VLPN14DXmlnKzDqBVwHPNrfU5hoazzKgqzOKSMSct6Xu7gUz+zDwCJAE7nP3p83sg8H6u939WTP7e+BJoATc6+5PLWfhF+vAWJbt61e1ugwRkaZqpPsFd38YeLhm2d0183cCdzavtOVTHs44zRt3bGh1KSIiTRXLX5QemZgmVyzp6owiEjmxDPWhYOSLhjOKSNTEMtQPBGPUNZxRRKImlqE+pOGMIhJRsQz1g+NZtqztIpHQcEYRiZaYhvoUA7rmi4hEUOxCvVhynh+fYkBfkopIBMUu1I+eKg9n1C3sRCSKYhfq88MZ1f0iItETu1A/MKbhjCISXbEL9aHxLG2pBBtWtbe6FBGRpotdqB8YK39JquGMIhJFsQv1ofGs+tNFJLJiFeqlkjN0YkojX0QksmIV6kdPz5ArlDRGXUQiK1ahfjAY+TKg7hcRiah4hXpwdUZ1v4hIVMUr1MfKwxkvXa3hjCISTfEK9fEptqzr1HBGEYmsWIV6eTijul5EJLpiE+qlkjM0PqXLA4hIpMUm1I+dnmG2UNIPj0Qk0mIT6vPDGdVSF5Hoik+oB5fc1XBGEYmyGIV6lkwqwWUazigiERafUB/LsmWthjOKSLTFJ9Q1nFFEYiAWoT4/nFEjX0Qk2mIR6vPDGdVSF5Foi0WoVy7kpR8eiUjUxSPUx8rDGfXDIxGJuliE+tB4lkwywWWXdLS6FBGRZRWLUD8wlmXzuk6SGs4oIhEXi1AfGp/S3Y5EJBYiH+rlm01ndc0XEYmFyIf6yOQMM/kSWzTyRURiIPKhXhn5slUtdRGJgYZC3cxuNrNBM9tnZnecY7tXmlnRzH6jeSVenMoYdQ1nFJE4OG+om1kS+CzwFmAHcJuZ7Vhku/8IPNLsIi/GwWA44+VrNJxRRKKvkZb6DcA+d9/v7jngAeCWOtt9BPgycLyJ9V20g2NZ+td2aDijiMRCI6G+EThUNT8cLJtjZhuBXwfuPteOzOx2M9tlZrtGR0eXWusFKQ9nVH+6iMRDI6Fer4nrNfN/BnzM3Yvn2pG73+PuO919Z19fX6M1XrBSyTk4ntXdjkQkNlINbDMM9FfNbwKO1GyzE3jAzAB6gbeaWcHdv9qUKi/Q8clZZvIl/fBIRGKjkVB/DNhuZluBw8CtwLuqN3D3rZVpM/s88HetDnQoXx4AdF9SEYmP84a6uxfM7MOUR7Ukgfvc/Wkz+2Cw/pz96K00FAxnVJ+6iMRFIy113P1h4OGaZXXD3N1/++LLao4D41nSSdNwRhGJjUj/onRobIr+tbo6o4jER6RD/eC4LuQlIvES2VAvFEvsH82yfX13q0sREXnBRDbUD45PkSuWuGrDqlaXIiLygolsqO8ZmQTg6ksV6iISH5EN9cFjk5jBlep+EZEYiWyo7xmZZGBdF+3pZKtLERF5wUQ21AdHJrlqg1rpIhIvkQz1mXyRg2NZrtaXpCISM5EM9edGz1By2K5QF5GYiWSoa+SLiMRVJEN98NgZ0knTr0lFJHYiGep7Rya5orebTCqShycisqhIpt7gyCRXqetFRGIocqF+ZrbA8MlprtZwRhGJociF+t7gS1Jd80VE4ihyoa6RLyISZ5EL9cFjZ2hPJ+jv0c2mRSR+Ihfqe0YmuWrDKhK625GIxFDkQn1wZJLt69X1IiLxFKlQP5HNMTo5y9WXauSLiMRTpEJ9j0a+iEjMRSrU92rki4jEXKRCfXBkklXtKS5d3d7qUkREWiJSob7n2Bmu3rAKM418EZF4ikyou7uu+SIisReZUD8+Ocup6bzudiQisRaZUB88ppEvIiKRCfX54Ywaoy4i8RWZUB88Nklvd4Z13W2tLkVEpGUiE+qVa76IiMRZJEK9VHL2jJxRqItI7EUi1A9PTDOdL+qXpCISe5EIdY18EREpi0aoa+SLiAgQkVDfMzLJxjUdrGpPt7oUEZGWikSoDx6bVCtdRIQGQ93MbjazQTPbZ2Z31Fn/bjN7Mnj80MyubX6p9eWLJfaPZnXNFxERGgh1M0sCnwXeAuwAbjOzHTWbHQBe5+4vAz4J3NPsQhczNJ4lVyzpmi8iIjTWUr8B2Ofu+909BzwA3FK9gbv/0N1PBrM/BjY1t8zFDR47A2jki4gINBbqG4FDVfPDwbLFfAD4+sUUtRSDI5OYwZXr1acuIpJqYJt6d5zwuhuavZ5yqP/SIutvB24H2Lx5c4MlntueY5MMrOuiPZ1syv5ERMKskZb6MNBfNb8JOFK7kZm9DLgXuMXdx+vtyN3vcfed7r6zr6/vQuo9y57jGvkiIlLRSKg/Bmw3s61mlgFuBR6q3sDMNgMPAu9x9z3NL7O+mXyRg2NZfUkqIhI4b/eLuxfM7MPAI0ASuM/dnzazDwbr7wb+BFgHfC64P2jB3XcuX9llz42eoeRoOKOISKCRPnXc/WHg4Zpld1dN/w7wO80t7fwqN8ZQS11EpCzUvygdPHaGdNIY6O1qdSkiIitCqEN9z8gk2/q6SSdDfRgiIk0T6jQsX/NFXS8iIhWhDfXJmTyHJ6Y1nFFEpEpoQ33vcV0eQESkVmhDfU9wtyPdwk5EZF54Q33kDO3pBP09na0uRURkxQhxqJe/JE0k6l2aRkQknkIb6oMjGvkiIlIrlKF+IptjdHJWvyQVEakRylCvXB5A13wREVko1KGulrqIyEKhDPXBY5Osbk+xYXVbq0sREVlRQhnqlZEvwWV+RUQkELpQd/fyNV/Uny4icpbQhfrI6VlOzxTUny4iUkfoQn1u5ItCXUTkLKEL9c5Mkl/dsUHXfBERqaOh29mtJDsH1rJzYG2ryxARWZFC11IXEZHFKdRFRCJEoS4iEiEKdRGRCFGoi4hEiEJdRCRCFOoiIhGiUBcRiRBz99a8sdkoMHSBL+8FxppYzkoQtWOK2vFA9I4pascD0Tumesezxd37FntBy0L9YpjZLnff2eo6milqxxS144HoHVPUjgeid0wXcjzqfhERiRCFuohIhIQ11O9pdQHLIGrHFLXjgegdU9SOB6J3TEs+nlD2qYuISH1hbamLiEgdCnURkQgJXaib2c1mNmhm+8zsjlbX0wxmdtDMdpvZE2a2q9X1LJWZ3Wdmx83sqapla83sG2a2N3juaWWNS7XIMX3CzA4H5+kJM3trK2tcCjPrN7PvmNmzZva0mX00WB7K83SO4wnzOWo3s5+Y2c+DY/rXwfIlnaNQ9ambWRLYA/wqMAw8Btzm7s+0tLCLZGYHgZ3uHsofTZjZLwNngPvd/SXBsj8FTrj7fwj+8+1x94+1ss6lWOSYPgGccff/1MraLoSZXQZc5u4/NbNVwOPA24HfJoTn6RzH807Ce44M6HL3M2aWBv4f8FHgHSzhHIWtpX4DsM/d97t7DngAuKXFNcWeu38POFGz+BbgC8H0Fyh/4EJjkWMKLXc/6u4/DaYngWeBjYT0PJ3jeELLy84Es+ng4SzxHIUt1DcCh6rmhwn5iQw48A9m9riZ3d7qYppkg7sfhfIHEFjf4nqa5cNm9mTQPROKropaZjYAXA88SgTOU83xQIjPkZklzewJ4DjwDXdf8jkKW6hbnWXh6T9a3Gvc/eXAW4APBX/6y8rzF8A24DrgKPCp1pazdGbWDXwZ+EN3P93qei5WneMJ9Tly96K7XwdsAm4ws5csdR9hC/VhoL9qfhNwpEW1NI27HwmejwNfodzNFHYjQb9npf/zeIvruWjuPhJ86ErAXxGy8xT0034Z+KK7PxgsDu15qnc8YT9HFe4+AXwXuJklnqOwhfpjwHYz22pmGeBW4KEW13RRzKwr+KIHM+sC3gQ8de5XhcJDwPuC6fcBX2thLU1R+WAFfp0QnafgS7i/Bp51909XrQrleVrseEJ+jvrMbE0w3QG8EfgFSzxHoRr9AhAMUfozIAnc5+7/tsUlXRQzu4Jy6xwgBfyPsB2Tmf0NcBPly4SOAB8Hvgp8CdgMPA/8pruH5ovHRY7pJsp/1jtwEPi9Sl/nSmdmvwR8H9gNlILFf0y5Hzp05+kcx3Mb4T1HL6P8RWiScoP7S+7+b8xsHUs4R6ELdRERWVzYul9EROQcFOoiIhGiUBcRiRCFuohIhCjURUQiRKEuIhIhCnURkQj5/xyxBUEceQz/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracyスコア\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epoch = 30\n",
    "plt.plot(np.arange(epoch), nn.train_score_list)\n",
    "plt.plot(np.arange(epoch), nn.val_score_list)\n",
    "\n",
    "#train_score_list =[]\n",
    "#val_score_list = []\n",
    "#train_loss_list = [\n",
    "#val_loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdd4ec592b0>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD4CAYAAAATpHZ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcVklEQVR4nO3deZCcd33n8fe3r+nuOXs0I+uakSxksMEga1CMZWBxNoGyXaG4ic0GWGqJAUOtU5BUWJaKk1RRyxJgKQy217vxAhXugMHZggQ2mAA2tpGMfNtYGEsz1jU65j76mN/+0U+3elo9d8888zz9eVV19XN1z/dxW5/f07/n9zxtzjlERCQcIn4XICIi9aNQFxEJEYW6iEiIKNRFREJEoS4iEiIxv/5wV1eX27Fjh19/XkQkkA4cOHDKOdc913rfQn3Hjh3s37/frz8vIhJIZnZ4vvXqfhERCRGFuohIiCjURURCRKEuIhIiCnURkRBRqIuIhIhCXUQkRAIX6mfGs/zNPz3OVK7gdykiIutO4EL93kOn+NJ9z3HdHfdzamza73JERNaVwIX663dv4bb/8HKeOj7CG794L4dOjvpdkojIuhG4UAe4+tJNfPOGfUzlZnjTrfdx36FTfpckIrIuBDLUAXb3dHDXjVeyqS3Ju+58kG/v7/e7JBER3wU21AF6OtP84weu5IqdG/iLf3yEz/zoafSbqyLSyAId6gDtqTj/5z2/xx/v7eGWnxzipm8c1MgYEWlYvt16t57i0QiffMtL2d6V5lP//DTHhif5n+/cS2dzwu/SRETWVOCP1EvMjBuv2sUX3rGHhweGefOt9/K7U+N+lyUisqZCE+olf/SyLXz9T69gZCrPm269l4P9Q36XJCKyZkIX6gAv357hrhuvJBaJ8IWfHPK7HBGRNRPKUAfYvqGZPb0dHDmjLhgRaRyhDXWAnkya/jOTGuYoIg0j3KHemWIyV+D0eNbvUkRE1kS4Qz2TBqD/zITPlYiIrI1wh3qnF+pnJ32uRERkbYQ61LdlUoCO1EWkcYQ61JubYmxoTjBwVqEuIo0h1KEOsK2zOAJGRKQRhD7UezIp+nWkLiINIvyh3pnm6NAkhRmNVReR8At/qGfS5AqO4yNTfpciIrLqwh/qnRoBIyKNI/yhrguQRKSBhD7Ut3SkMNMFSCLSGEIf6olYhM1tSQZ0pC4iDWDBUDezHjO7x8yeNLPHzeymGtuYmX3ezA6Z2SNm1rc65S7Pts60hjWKSENYzJF6HviIc+4S4Argg2b24qptrgEu8h43ALfVtcoVKt2CV0Qk7BYMdefcMefcQ970KPAksLVqszcAX3FF9wMdZra57tUuU09nihOjU0znC36XIiKyqpbUp25mO4A9wANVq7YC/RXzA5wf/JjZDWa238z2Dw4OLq3SFejJpHEOntfJUhEJuUWHupm1AN8B/sw5N1K9usZLzruE0zl3h3Nur3Nub3d399IqXQHdgldEGsWiQt3M4hQD/avOue/W2GQA6KmY3wYcXXl59aELkESkUSxm9IsBfw886Zz77Byb3Q28yxsFcwUw7Jw7Vsc6V+SC1iSJaEQjYEQk9GKL2OaVwDuBR83soLfsY0AvgHPuduAHwLXAIWACeE/9S12+SMTYmkkxoBEwIhJyC4a6c+4X1O4zr9zGAR+sV1GrYZtuwSsiDSD0V5SW9HSm1acuIqHXOKGeSXN2IsfYdN7vUkREVk3jhLpGwIhIA2icUNcteEWkATROqOsCJBFpAA0T6pl0nOZEVEfqIhJqDRPqZkZPZ5oBDWsUkRBrmFCHYhfMER2pi0iINVaoe/dVL14rJSISPo0V6p0pJnMFTo9n/S5FRGRVNFaoa1ijiIRcY4W6hjWKSMg1VKhvy+iqUhEJt4YK9eamGBuaExrWKCKh1VChDrCtszgCRkQkjBou1Ht0X3URCbHGC/XONEeHJinMaKy6iIRP44V6Jk2u4Dg+MuV3KSIiddd4oa77qotIiDVeqOsCJBEJsYYL9S0dKcx0AZKIhFPDhXoiFmFzW5IBHamLSAg1XKiDN1ZdwxpFJIQaMtRLt+AVEQmbxgz1zhQnRqeYzhf8LkVEpK4aM9QzaZyD53WyVERCpjFDXbfgFZGQatBQ1wVIIhJODRnqF7QmSUQjGgEjIqHTkKEeiRhbMykGNAJGREKmIUMdir+CpCN1EQmbhg31ns60+tRFJHQaN9Qzac5O5BibzvtdiohI3TRuqGsEjIiEUOOGum7BKyIh1LihrguQRCSEGjbUM+k4zYmojtRFJFQWDHUzu9PMTprZY3Osv8rMhs3soPf4q/qXWX9mRk9nmgENaxSREIktYpsvAV8AvjLPNj93zv1RXSpaQ9syGtYoIuGy4JG6c+5nwJk1qGXN9XQWL0ByzvldiohIXdSrT32fmT1sZj80s5fMtZGZ3WBm+81s/+DgYJ3+9PL1ZNJMZAucHs/6XYqISF3UI9QfArY753YDtwDfm2tD59wdzrm9zrm93d3ddfjTK1MeAaMuGBEJiRWHunNuxDk35k3/AIibWdeKK1sD5QuQNKxRREJixaFuZpvMzLzpy733PL3S910LugBJRMJmwdEvZvZ14Cqgy8wGgJuBOIBz7nbgrcAHzCwPTALXuYCceWxuitHZnNCwRhEJjQVD3Tl3/QLrv0BxyGMg9WRS9Ou+6iISEg17RWnJts607qsuIqHR8KHek0lzdGiSwkwgeoxEROalUO9MkSs4jo9M+V2KiMiKKdQ1AkZEQkShrguQRCREGj7Ut3QkMdMFSCISDg0f6k2xKJvakgzoSF1EQqDhQx2K/eoa1igiYaBQB7Z16gIkEQkHhTrQ25nmxOgU0/mC36WIiKyIQp1iqDunETAiEnwKdeAlW9oBONg/7HMlIiIro1AHLtrYQmtTjIeOnPW7FBGRFVGoA5GIcVlvBw8dVqiLSLAp1D19vRl+c2KUsem836WIiCybQt3Ttz3DjIOH+4f8LkVEZNkU6p7LejoA1AUjIoGmUPe0p+JctLGFAzpZKiIBplCv0Neb4ddHhpjRD2aISEAp1Cv0be9geDLHs6fG/S5FRGRZFOoV+nozABqvLiKBpVCv8ILuFtqSMX6tUBeRgFKoVyhehJThocMa1igiwaRQr/Ly3gy/OTnKyFTO71JERJZMoV6lb3sHThchiUhAKdSrXNbTgRnqghGRQFKoV2lNxnnhxlaNgBGRQFKo19C3vYNfHzmri5BEJHAU6jXs6c0wMpXn2VNjfpciIrIkCvUaShchHdDNvUQkYBTqNezsaqY9FdfJUhEJHIV6DZGIsae3QydLRSRwFOpz6OvN8MzJMYYndRGSiASHQn0OpX71g7oISUQCRKE+h9097URMv4QkIsGiUJ9DazLOCy/QRUgiEiwLhrqZ3WlmJ83ssTnWm5l93swOmdkjZtZX/zL90bc9w8F+/RKSiATHYo7UvwRcPc/6a4CLvMcNwG0rL2t96OvNMDqV59CgLkISkWBYMNSdcz8DzsyzyRuAr7ii+4EOM9tcrwL91NfbAahfXUSCox596luB/or5AW9Z4F3Y1UwmHVe/uogERj1C3Wosq9kJbWY3mNl+M9s/ODhYhz+9usyMPb0Z3S5ARAKjHqE+APRUzG8Djtba0Dl3h3Nur3Nub3d3dx3+9Orr6+3gt4PjDE1k/S5FRGRB9Qj1u4F3eaNgrgCGnXPH6vC+60LpIqRf6yIkEQmA2EIbmNnXgauALjMbAG4G4gDOuduBHwDXAoeACeA9q1WsH3b3dBAx+PXhs/z+izb6XY6IyLwWDHXn3PULrHfAB+tW0TrT3BTj4k1tPHRER+oisv7pitJF6NvewcH+IQq6CElE1jmF+iL09WYYm87zzMlRv0sREZmXQn0RSidL9aMZIrLeKdQXYfuGNJ3NCV2EJCLrnkJ9EcyMPv0SkogEgEJ9kfb0ZnhWFyGJyDqnUF+k8kVIGtooIuuYQn2Rdve0E42Y7gMjIuuaQn2R0okYF2/SLyGJyPqmUF+Cvt4MD+siJBFZxxTqS/Dy7RnGswWePq6LkERkfVKoL0H5IiR1wYjIOqVQX4KezhRdLU38vydPULyPmYjI+qJQXwIz472vvpCfPj3IPz0SmlvGi0iIKNSX6E9fvZPLejq4+fuPMTg67Xc5IiKzKNSXKBoxPv22lzGeLfDx7z2qbhgRWVcU6suwa2MrH37tC/mXx0+oG0ZE1hWF+jKpG0ZE1iOF+jIVu2F2qxtGRNYVhfoK7NrYwke8bpi7Hz7qdzkiIgr1lXrvq3eyp7eDm+9+nJOjU36XIyINTqG+QtGI8Xdv3c1EtsDH73pM3TAi4iuFeh2UumF+9IS6YUTEXwr1OlE3jIisBwr1OlE3jIisBwr1Otq1sYU/f526YUTEPwr1OvtPr1I3jIj4R6FeZ5XdMP9V3TAissYU6qtg18YW/uJ1L+LHT5zgL7/zCLnCjN8liUiDiPldQFi999UXMjqV4/M/OcTRoSlu/ZM+2pJxv8sSkZDTkfoqMTM+/LoX8am3voz7nz3N22//JUeHJv0uS0RCTqG+yt6+t4cvvedynj87yZtuvZfHjw77XZKIhJhCfQ286qIuvv2BfUTMePvtv+Sep0/6XZKIhJRCfY1cvKmN733wlWzf0Mx7v7yfrz1wxO+SRCSEFOpr6IK2JN96/z5efVEXH7vrUf77Pz/FzIyGPIpI/SjU11hLU4z//a69vOMVvdz2099y0zcPMpUr+F2WiISEhjT6IBaN8Ik3XkpvZ5pP/vApjg9Pcsc795JpTvhdmogE3KKO1M3sajN72swOmdlHa6y/ysyGzeyg9/ir+pcaLmbG+1/zAm65fg8P9w/z2v/xb3zjwSMU1B0jIiuwYKibWRT4InAN8GLgejN7cY1Nf+6cu8x7/G2d6wyt1+/ewndvvJILu5r56Hcf5fW3/IIHnj3td1kiElCLOVK/HDjknHvWOZcFvgG8YXXLaiyXbm3nW+/bxy3X72F4Mscf33E/N371AP1nJvwuTUQCZjGhvhXor5gf8JZV22dmD5vZD83sJXWproGYGa/fvYV//chr+PBrX8g9Tw3yB5/9N/7uX55ifDrvd3kiEhCLCXWrsay64/chYLtzbjdwC/C9mm9kdoOZ7Tez/YODg0urtEEk41H+8x9cxE/+/DVce+kmvnjPb/n9T/+U7xwY0PBHEVnQYkJ9AOipmN8GzPoFCOfciHNuzJv+ARA3s67qN3LO3eGc2+uc29vd3b2CssNvc3uKz123h+/eeCWbO1J85NsP86bb7uPA4bN+lyYi69hiQv1XwEVmdqGZJYDrgLsrNzCzTWZm3vTl3vvqbF8d9PVmuOsDV/KZt+3m2NAkb7ntPt562318/+DzZPO6pa+IzGaL+REHM7sW+BwQBe50zn3CzN4P4Jy73cw+BHwAyAOTwIedc/fN95579+51+/fvX2n9DWV8Os/XHjjCPzxwmMOnJ+hqSXDd7/Xyjlf0sqUj5Xd5IrIGzOyAc27vnOv9+mUehfryzcw4fvbMIP9w/2H+9amTGPCHl1zAu/bt4JW7NuB9aRKREFoo1HVFaQBFIsZVL9rIVS/aSP+ZCb724BG++at+fvTECXZ2N/Mnr9jOW16+jfaUfpRDpNHoSD0kpnIFfvDoMb7yy8Mc7B8iFY/y7y/ZyL6dG9j3gg3s7GrWEbxICKj7pQE9OjDM1x48zD1PDXJ8ZAqAja1N7HvBhnLI93amFfIiAaTulwb00m3t/LdtL8M5x3OnJ/jlb0/zy2dPc++h03z/YHE06pb2JFd4IX/Fzg1sy6QU8iIhoCP1BuKc47eDY+WQv//ZM5wZzwLQnopz8aZWLtncxiWbi88vvKCVZDzqc9UiUklH6lJmZuza2Mquja28c98OZmYcvzk5yq+eO8uTx0Z48tgI39rfz0S2eH/3iMHO7pZy2L94cxu7NrawpSNFNKKjepH1SKHewCIR4+JNbVy8qa28bGbGceTMRDnknzg2ysH+If7vI8fK28SjRk8mzfYNabZvaGbHhjTbu5rZsaGZbZkU8ah+e0XELwp1mSUSMXZ0NbOjq5lrXrq5vHxkKsdTx0b53akxnjs9weHT4zx3aoIHf3eG8ey5X26KRoytHSl6O9Nsbk+yuT3JpvaU91ycb0/F1X8vskoU6rIobck4l1/YyeUXds5a7pzj1Fi2GPKlsD89wZEzEzzzzCAnR6epPm2TjEfY1FYK+RQbW5vY0JKgq6WJrpbidHdLE53NCWI66hdZEoW6rIiZ0d3aRHdrE3t3dJ63PleYYXB0mmPDUxwfnuLY8CQnRqbK8w/+7gyDo9NkC7XvY5NJx8tB39XSRCadIJOOk2lOkEkn6EjH6fSmM80JmhNRfQuQhqZQl1UVj0bY0pGa9940zjlGp/OcGp3m9HiWU6PTnCo9j01zeizLqbFpHj86wtmJLMOTufOO/s/9PaPDC/72VJz2VIL2VJwOb76jvLw0n6AtGaMtFde5AAkFhbr4zsxoS8ZpS8bZuYg7MhdmHMOTOc5OZBmayHJmfPb00ESWoYkcw5M5nh+a5ImjwwxP5mb1/deSTkRpTxXraE/FaUsVw/7cvPecrFieLs63NMX0DUHWBYW6BE40YnQ2J+hsTizpddn8DCNTuXLgD08Wj/qHJ3KMTOUZnswxMllal+P5oSmePDbKyGSO0QV+fSpilIO+LRU71xB486VGYdZ88lxD0RSLqFGQulCoS8NIxCLlk7FLlS/MMDadZ2Qyz8hUrtwAjEzlyssqG4TRqTyHTo6V10/m5v+WkIhGiqFfEfjtNefjs+bbU3FakjFdNyBlCnWRRYhFI3SkE3Skl/btoKT0LaHYEOQrwr/UQHjfFLxthiaKI4pK2xbm+SlDM2hpis3bELQlY15XUXzWt4b2VJxkXN8SwkShLrIGVvItwTnHeLZQ/iZQfq7qMjq3PMdzpybK0xMLnEuIR63cFVQ+X1DVlVRe5y1r9c6BtCZjpDXiaF1RqIusc2ZGS1PxZOxyfuEqm585941gKn9eN1Fl11Fp/fNDk8VupcncnMNNS6IRo9UL/NZkzHvEy8tammYvK023JWO0eCeZmxMxIupCqguFukjIJWIRNrQ0sWEZ3xKgeK/+0rmB0ali8I/OmvcaB6+RGJ3K039mwpvOMTadZ57eo7JSw1UK+lID0JyoCP/SNudNR8vbpOKN/c1BoS4i80rGoyTjUTa2Lu/1pe6jsanZjcLYdJ6xqTxj08WGoHJ+xFt/fHiquNx7LOamsmbQnCgGffG5ejpGcyJaXp5OVDwnYqS9bdOJaLGRSEQDNTopeKF+6hD85oeQbK94dMyej+h2sSLrRWX30ab25LLfxznHZK5QDv/x6UI57Men84xO55nwpsemC0xkz60bzxY4PjJVnh6fzi94rqFSNGKk41HSXvinE1HvEat6jpI6b12UlDedihfnN7Q0rdrPTQYv1I8dhB99fP5tEq3nAr6pBeJpSDR7z+nic3m6uWJZCmLJ4iOehFjq/OdYU/FQQETWlJl5QRlb9reGSjMzxUZiPJtnYtp7rgj8ca9BmMgVyusnswXGswUms8VGZWgiy9GhQnF77/XZ/PznIADe95qd/JdrLln5TtQQvFB/yZvhotfB1PAiHkMwPQrZMRg7CblxyE5AbgKy48ByfiDEvOBvqvFcY1m0CWKJqudkjWVNEE14z/HZy6KJqu289dEERHRpu8hyRCJW7o6hDo1ESb4ww2SuwGS2GPYT2QKTuWIjUJre1V3HP1gleKEeiUCyrfigZ/nv4xzkp88FfG4CcpOQn1r4OT/tPaZqP0+cOTdfyBanC9OQzxaXLasxmYNFK0K/1iNe9TzfdMxrKOJVr4t7yyrmowmIxObfpvQ+ldtFYvqmI6EWi0ZojUZoTa5O98qCf9+Xv7oemBW7VOJJSJ9/d8FV4xzM5L2grwr88nN29rJCtsb6LBRy59YXchXblV6Xn71tbnj2toUczOSKNcxUbOsW/vq4IpHKxiNWFf7xquWJubeJxOZ5feV8bOHXzdq29PdrTceL52wile+vcziyfjRuqPvF7NyR7Ho1UzgX/DNVDUN5ea5qPj/HNnnvOVsxXfmaXNV2uXPLS9vkszAzPntd5Wtm8lWvz63xfzA7vwGpDPxSg1BuTCoaidL68msrGozSfLRqvnr9ea+v8f7lmmKz56vX11xWYxt921q3FOpyvki0+Igvf6SCr5wrNkyVjURlY1BqtMrr59q2+nX5itfmq96r1ny+9vtVzuenKpbP8dpyo1XxcIsfubEqLLLEhiBa7Cqcd/uqZTX/RsU2VjkfXeBvLfC6ud6rXEOtZZWvXz+NnEJdwsfMOz8QK45oCqPKhqu6UXCFisaqRgNR2VC46m1qzJfec75tKhsrN7Pwe5a6IKuXlf9O9Wsq3rO0zbpiczQSc8z3vRuu/NCqVKJQFwmiyoarETnnNR5V4T+rQSks0GBULl/EslnvX7GuusGr3qb8XhXzLRtX7T9Ng/4fISKBZnbu6Jfl3TkzrDTIWUQkRBTqIiIholAXEQkRhbqISIgo1EVEQkShLiISIgp1EZEQUaiLiISIucX8PtRq/GGzQeDwMl/eBZyqYznrQdj2KWz7A+Hbp7DtD4Rvn2rtz3bnXPdcL/At1FfCzPY75/b6XUc9hW2fwrY/EL59Ctv+QPj2aTn7o+4XEZEQUaiLiIRIUEP9Dr8LWAVh26ew7Q+Eb5/Ctj8Qvn1a8v4Esk9dRERqC+qRuoiI1KBQFxEJkcCFupldbWZPm9khM/uo3/XUg5k9Z2aPmtlBM9vvdz1LZWZ3mtlJM3usYlmnmf3YzJ7xnjN+1rhUc+zTX5vZ897ndNDMrvWzxqUwsx4zu8fMnjSzx83sJm95ID+nefYnyJ9R0sweNLOHvX36G2/5kj6jQPWpm1kU+A3wWmAA+BVwvXPuCV8LWyEzew7Y65wL5EUTZvbvgDHgK865S71lnwLOOOc+6TW+GefcX/pZ51LMsU9/DYw55z7tZ23LYWabgc3OuYfMrBU4ALwR+I8E8HOaZ3/eTnA/IwOanXNjZhYHfgHcBLyZJXxGQTtSvxw45Jx71jmXBb4BvMHnmhqec+5nwJmqxW8AvuxNf5niP7jAmGOfAss5d8w595A3PQo8CWwloJ/TPPsTWK5ozJuNew/HEj+joIX6VqC/Yn6AgH+QHgf8yMwOmNkNfhdTJxc4545B8R8gsHq/tLu2PmRmj3jdM4HoqqhmZjuAPcADhOBzqtofCPBnZGZRMzsInAR+7Jxb8mcUtFC3GsuC0380t1c65/qAa4APel/9Zf25DXgBcBlwDPiMv+UsnZm1AN8B/sw5N+J3PStVY38C/Rk55wrOucuAbcDlZnbpUt8jaKE+APRUzG8DjvpUS9045456zyeBuyh2MwXdCa/fs9T/edLnelbMOXfC+0c3A/wvAvY5ef203wG+6pz7rrc4sJ9Trf0J+mdU4pwbAn4KXM0SP6OghfqvgIvM7EIzSwDXAXf7XNOKmFmzd6IHM2sGXgc8Nv+rAuFu4N3e9LuB7/tYS12U/mF53kSAPifvJNzfA0865z5bsSqQn9Nc+xPwz6jbzDq86RTwh8BTLPEzCtToFwBviNLngChwp3PuEz6XtCJmtpPi0TlADPha0PbJzL4OXEXxNqEngJuB7wHfAnqBI8DbnHOBOfE4xz5dRfFrvQOeA95X6utc78zsVcDPgUeBGW/xxyj2Qwfuc5pnf64nuJ/RyyieCI1SPOD+lnPub81sA0v4jAIX6iIiMregdb+IiMg8FOoiIiGiUBcRCRGFuohIiCjURURCRKEuIhIiCnURkRD5/9MSQfZt7upwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trainデータ\n",
    "epoch = 30\n",
    "\n",
    "plt.plot(np.arange(epoch), nn.train_loss_list)\n",
    "plt.plot(np.arange(epoch), nn.val_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 考察\n",
    "# valでもepochを回しているので、スタートからlossは低い状態\n",
    "# 最近ではvalで最適化することもあるため、今回はそちらを採用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
