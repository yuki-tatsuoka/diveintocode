{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "dir_path = \"/Users/yuki.tatsuoka/Downloads/home-credit-default-risk (1)/\"\n",
    "\n",
    "app_train = pd.read_csv(dir_path + \"application_train.csv\")\n",
    "app_test = pd.read_csv(dir_path + \"application_test.csv\")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "np.set_printoptions(threshold=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0      100001         Cash loans           F            N               Y   \n",
       "1      100005         Cash loans           M            N               Y   \n",
       "2      100013         Cash loans           M            Y               Y   \n",
       "3      100028         Cash loans           F            N               Y   \n",
       "4      100038         Cash loans           M            Y               N   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          135000.0    568800.0      20560.5         450000.0   \n",
       "1             0           99000.0    222768.0      17370.0         180000.0   \n",
       "2             0          202500.0    663264.0      69777.0         630000.0   \n",
       "3             2          315000.0   1575000.0      49018.5        1575000.0   \n",
       "4             1          180000.0    625500.0      32067.0         625500.0   \n",
       "\n",
       "   ... FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                0                0                0                0   \n",
       "1  ...                0                0                0                0   \n",
       "2  ...                0                0                0                0   \n",
       "3  ...                0                0                0                0   \n",
       "4  ...                0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR  AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "2                        0.0                        0.0   \n",
       "3                        0.0                        0.0   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         0.0                        0.0   \n",
       "4                         NaN                        NaN   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         0.0  \n",
       "1                        0.0                         3.0  \n",
       "2                        1.0                         4.0  \n",
       "3                        0.0                         3.0  \n",
       "4                        NaN                         NaN  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロスバリデーションまでいきたいのでEDA割愛\n",
    "# train,testデータのカラムが異なるので整える\n",
    "y = app_train[\"TARGET\"]\n",
    "\n",
    "# TARGETを削除\n",
    "app_train = app_train.drop(\"TARGET\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 121)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train,testデータを統合する\n",
    "df = pd.concat([app_train, app_test], axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AMT_ANNUITY                         36\n",
       "AMT_GOODS_PRICE                    278\n",
       "NAME_TYPE_SUITE                   2203\n",
       "OWN_CAR_AGE                     235241\n",
       "OCCUPATION_TYPE                 111996\n",
       "CNT_FAM_MEMBERS                      2\n",
       "EXT_SOURCE_1                    193910\n",
       "EXT_SOURCE_2                       668\n",
       "EXT_SOURCE_3                     69633\n",
       "APARTMENTS_AVG                  179948\n",
       "BASEMENTAREA_AVG                207584\n",
       "YEARS_BEGINEXPLUATATION_AVG     172863\n",
       "YEARS_BUILD_AVG                 236306\n",
       "COMMONAREA_AVG                  248360\n",
       "ELEVATORS_AVG                   189080\n",
       "ENTRANCES_AVG                   178407\n",
       "FLOORSMAX_AVG                   176341\n",
       "FLOORSMIN_AVG                   241108\n",
       "LANDAREA_AVG                    210844\n",
       "LIVINGAPARTMENTS_AVG            242979\n",
       "LIVINGAREA_AVG                  177902\n",
       "NONLIVINGAPARTMENTS_AVG         246861\n",
       "NONLIVINGAREA_AVG               195766\n",
       "APARTMENTS_MODE                 179948\n",
       "BASEMENTAREA_MODE               207584\n",
       "YEARS_BEGINEXPLUATATION_MODE    172863\n",
       "YEARS_BUILD_MODE                236306\n",
       "COMMONAREA_MODE                 248360\n",
       "ELEVATORS_MODE                  189080\n",
       "ENTRANCES_MODE                  178407\n",
       "FLOORSMAX_MODE                  176341\n",
       "FLOORSMIN_MODE                  241108\n",
       "LANDAREA_MODE                   210844\n",
       "LIVINGAPARTMENTS_MODE           242979\n",
       "LIVINGAREA_MODE                 177902\n",
       "NONLIVINGAPARTMENTS_MODE        246861\n",
       "NONLIVINGAREA_MODE              195766\n",
       "APARTMENTS_MEDI                 179948\n",
       "BASEMENTAREA_MEDI               207584\n",
       "YEARS_BEGINEXPLUATATION_MEDI    172863\n",
       "YEARS_BUILD_MEDI                236306\n",
       "COMMONAREA_MEDI                 248360\n",
       "ELEVATORS_MEDI                  189080\n",
       "ENTRANCES_MEDI                  178407\n",
       "FLOORSMAX_MEDI                  176341\n",
       "FLOORSMIN_MEDI                  241108\n",
       "LANDAREA_MEDI                   210844\n",
       "LIVINGAPARTMENTS_MEDI           242979\n",
       "LIVINGAREA_MEDI                 177902\n",
       "NONLIVINGAPARTMENTS_MEDI        246861\n",
       "NONLIVINGAREA_MEDI              195766\n",
       "FONDKAPREMONT_MODE              243092\n",
       "HOUSETYPE_MODE                  177916\n",
       "TOTALAREA_MODE                  171055\n",
       "WALLSMATERIAL_MODE              180234\n",
       "EMERGENCYSTATE_MODE             167964\n",
       "OBS_30_CNT_SOCIAL_CIRCLE          1050\n",
       "DEF_30_CNT_SOCIAL_CIRCLE          1050\n",
       "OBS_60_CNT_SOCIAL_CIRCLE          1050\n",
       "DEF_60_CNT_SOCIAL_CIRCLE          1050\n",
       "DAYS_LAST_PHONE_CHANGE               1\n",
       "AMT_REQ_CREDIT_BUREAU_HOUR       47568\n",
       "AMT_REQ_CREDIT_BUREAU_DAY        47568\n",
       "AMT_REQ_CREDIT_BUREAU_WEEK       47568\n",
       "AMT_REQ_CREDIT_BUREAU_MON        47568\n",
       "AMT_REQ_CREDIT_BUREAU_QRT        47568\n",
       "AMT_REQ_CREDIT_BUREAU_YEAR       47568\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数値データと、object型のデータの欠損値を確認する\n",
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数値型とオブジェクトを分断する\n",
    "quantitve = [x for x in df.columns if df.dtypes[x] != object]\n",
    "objective = [x for x in df.columns if df.dtypes[x] == object]\n",
    "\n",
    "# 数値型には平均値、object型には最頻値\n",
    "for i in quantitve:\n",
    "    df[i].fillna(0, inplace=True)\n",
    "\n",
    "# modeのみSeriesとDataFrameでは挙動が異なるので, ilocで指定してndarray型に変換する\n",
    "for i in objective:\n",
    "    df[i].fillna('NA', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 251)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_dummiesでobject型をワンホットで埋める\n",
    "df = pd.get_dummies(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "結合前のサイズ(307511, 121), (48744, 121)\n",
      "結合後のサイズ(307511, 251), (48744, 251)\n"
     ]
    }
   ],
   "source": [
    "# trainデータとテストデータに分割する\n",
    "new_app_train = df.iloc[:app_train.shape[0], :]\n",
    "new_app_test = df.iloc[app_train.shape[0]:, :]\n",
    "\n",
    "# \n",
    "print(\"結合前のサイズ{}, {}\".format(app_train.shape, app_test.shape))\n",
    "print(\"結合後のサイズ{}, {}\".format(new_app_train.shape, new_app_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】クロスバリデーション\n",
    "事前学習期間では検証データをはじめに分割しておき、それに対して指標値を計算することで検証を行っていました。（ホールドアウト法）しかし、分割の仕方により精度は変化します。実践的には クロスバリデーション（交差検証） を行います。分割を複数回行い、それぞれに対して学習と検証を行う方法です。複数回の分割のためにscikit-learnにはKFoldクラスが用意されています。\n",
    "\n",
    "\n",
    "事前学習期間の課題で作成したベースラインモデルに対してKFoldクラスによるクロスバリデーションを行うコードを作成し実行してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     4      5      6 ... 307507 307508 307509]\n",
      "[     0      1      2 ... 307490 307506 307510]\n",
      "(246008,)\n",
      "(61503,)\n",
      "--------------------------------------------------\n",
      "[     0      1      2 ... 307508 307509 307510]\n",
      "[     5      6     11 ... 307494 307497 307505]\n",
      "(246009,)\n",
      "(61502,)\n",
      "--------------------------------------------------\n",
      "[     0      1      2 ... 307508 307509 307510]\n",
      "[     9     10     18 ... 307488 307498 307500]\n",
      "(246009,)\n",
      "(61502,)\n",
      "--------------------------------------------------\n",
      "[     0      1      2 ... 307505 307506 307510]\n",
      "[     7     21     22 ... 307507 307508 307509]\n",
      "(246009,)\n",
      "(61502,)\n",
      "--------------------------------------------------\n",
      "[     0      1      2 ... 307508 307509 307510]\n",
      "[     4      8     19 ... 307495 307496 307502]\n",
      "(246009,)\n",
      "(61502,)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# クロスバリデーションを使う\n",
    "# kfoldを使ってみる\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for train_index, test_index in kf.split(new_app_train, y):\n",
    "    print(train_index)\n",
    "    print(test_index)\n",
    "    print(train_index.shape)\n",
    "    print(test_index.shape)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,testデータに分ける\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for train_index, test_index in kf.split(new_app_train, y):\n",
    "    X_train1, X_test1 = new_app_train.iloc[train_index], new_app_train.iloc[test_index]\n",
    "    y_train1, y_test1 = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6211080475382352\n",
      "0.6120328983203771\n",
      "0.620333952473957\n"
     ]
    }
   ],
   "source": [
    "# stratifiedKFoldも実施してみる\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=22)\n",
    "\n",
    "model_LR = LogisticRegression()\n",
    "\n",
    "for train_index, test_index in skf.split(new_app_train, y):\n",
    "    X_train2 = new_app_train.iloc[train_index, :]\n",
    "    X_test2 = new_app_train.iloc[test_index, :]\n",
    "    y_train2 = y.iloc[train_index]\n",
    "    y_test2 = y.iloc[test_index]\n",
    "    \n",
    "    # 学習\n",
    "    model_LR.fit(X_train2, y_train2)\n",
    "    pred = model_LR.predict_proba(X_test2)[:, 1]\n",
    "    print(roc_auc_score(y_test2,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX_train = {}\\nX_test = {}\\n\\nfor i, (train_index, test_index) in enumerate(skf.split(new_app_train, y)):\\n    X_train[i] = new_app_train.loc[train_index]\\n    X_test[i] = new_app_train.iloc[test_index]\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_train = {}\n",
    "X_test = {}\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(new_app_train, y)):\n",
    "    X_train[i] = new_app_train.loc[train_index]\n",
    "    X_test[i] = new_app_train.iloc[test_index]\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分割した各スコア[0.62171145 0.61912683 0.62096088 0.61749134 0.62347683]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6217114516675628"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross_val_scoreでもスコアリング \n",
    "scores = cross_val_score(model_LR, X=new_app_train, y=y, cv=5, scoring='roc_auc')\n",
    "\n",
    "print(\"分割した各スコア{}\".format(scores))\n",
    "scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6205534681377224"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平均化 \n",
    "score_mean = scores.mean()\n",
    "score_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  【問題2】グリッドサーチ\n",
    "これまで分類器のパラメータには触れず、デフォルトの設定を使用していました。パラメータの詳細は今後のSprintで学んでいくことになります。機械学習の前提として、パラメータは状況に応じて最適なものを選ぶ必要があります。最適なパラメータを探していくことを パラメータチューニング と呼びます。パラメータチューニングをある程度自動化する単純な方法としては グリッドサーチ があります。\n",
    "\n",
    "\n",
    "scikit-learnのGridSearchCVを使い、グリッドサーチを行うコードを作成してください。そして、ベースラインモデルに対して何らかしらのパラメータチューニングを行なってください。どのパラメータをチューニングするかは、使用した手法の公式ドキュメントを参考にしてください。\n",
    "\n",
    "\n",
    "sklearn.model_selection.GridSearchCV — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "GridSearchCVクラスには引数としてモデル、探索範囲、さらにクロスバリデーションを何分割で行うかを与えます。クロスバリデーションの機能も含まれているため、これを使用する場合はKFoldクラスを利用する必要はありません\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter{'C': 1.0, 'penalty': 'l2'}\n",
      "best parameter0.6178975899180583\n"
     ]
    }
   ],
   "source": [
    "# ロジスティック回帰\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "model_LR = LogisticRegression()\n",
    "\n",
    "params = {\"C\":[0.01, 0.1, 1.0, 5, 10], \"penalty\":[\"l1\", \"l2\"]}\n",
    "\n",
    "grid = GridSearchCV(model_LR, params,  scoring='roc_auc')\n",
    "grid.fit(X_train2, y_train2)\n",
    "\n",
    "print('best parameter{}'.format(grid.best_params_))\n",
    "print('best parameter{}'.format(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.621355624638684\n",
      "0.613304807767437\n",
      "0.6197293470988348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4596345401508278"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR = LogisticRegression(penalty='l2', C=10)\n",
    "\n",
    "for train_index, test_index in skf.split(new_app_train, y):\n",
    "    X_train3 = new_app_train.iloc[train_index]\n",
    "    X_test3 = new_app_train.iloc[test_index]\n",
    "    y_train3 = y.iloc[train_index]\n",
    "    y_test3 = y.iloc[test_index]\n",
    "    \n",
    "    # 学習\n",
    "    model_LR.fit(X_train3, y_train3)\n",
    "    pred = model_LR.predict_proba(X_test3)[:, 1]\n",
    "    print(roc_auc_score(y_test3, pred))\n",
    "    \n",
    "# ROC曲線 結果\n",
    "# グリッドサーチ前:\n",
    "0.6211080475382352\n",
    "0.6120328983203771\n",
    "0.620333952473957\n",
    "\n",
    "# グリッドサーチ後:\n",
    "0.621355624638684\n",
    "0.613304807767437\n",
    "0.6197293470988348\n",
    "\n",
    "'''\n",
    "考察\n",
    "最後以外は微妙なれどグリッドサーチによって改善されている\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'n_estimators': 500}\n",
      "0.9194616783906214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# JSONエラーが出たので追加\n",
    "# https://www.kaggle.com/c/data-science-bowl-2019/discussion/122021\n",
    "X_train3.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_train3.columns]\n",
    "X_test3.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_test3.columns]\n",
    "\n",
    "# モデル選定 \n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "# 学習データの用意\n",
    "train = lgb.Dataset(X_train3, y_train3) \n",
    "test = lgb.Dataset(X_test3, y_test3, reference=train)\n",
    "\n",
    "params = {'learning_rate': [0.01, 0.05, 0.1, 1], 'n_estimators': [100,200,500]}\n",
    "grid = GridSearchCV(model, params, cv=5)\n",
    "grid.fit(X_train3, y_train3)\n",
    "\n",
    "# 評価\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n",
    "\n",
    "# gridserchの評価\n",
    "# ロジスティック回帰：0.9195598535620721\n",
    "# lightgbm：             0.9192549866669385\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205008, 251) (102503, 251)\n",
      "(205008,) (102503,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train3.shape, X_test3.shape)\n",
    "print(y_train3.shape, y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16550, number of negative: 188458\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11734\n",
      "[LightGBM] [Info] Number of data points in the train set: 205008, number of used features: 240\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.080729 -> initscore=-2.432489\n",
      "[LightGBM] [Info] Start training from score -2.432489\n",
      "[1]\tvalid_0's auc: 0.705878\n",
      "[2]\tvalid_0's auc: 0.708714\n",
      "[3]\tvalid_0's auc: 0.71015\n",
      "[4]\tvalid_0's auc: 0.711542\n",
      "[5]\tvalid_0's auc: 0.712361\n",
      "[6]\tvalid_0's auc: 0.712901\n",
      "[7]\tvalid_0's auc: 0.712995\n",
      "[8]\tvalid_0's auc: 0.713271\n",
      "[9]\tvalid_0's auc: 0.713314\n",
      "[10]\tvalid_0's auc: 0.714633\n",
      "[11]\tvalid_0's auc: 0.714808\n",
      "[12]\tvalid_0's auc: 0.715216\n",
      "[13]\tvalid_0's auc: 0.716489\n",
      "[14]\tvalid_0's auc: 0.716874\n",
      "[15]\tvalid_0's auc: 0.717212\n",
      "[16]\tvalid_0's auc: 0.717526\n",
      "[17]\tvalid_0's auc: 0.717781\n",
      "[18]\tvalid_0's auc: 0.718328\n",
      "[19]\tvalid_0's auc: 0.719031\n",
      "[20]\tvalid_0's auc: 0.719188\n",
      "[21]\tvalid_0's auc: 0.719495\n",
      "[22]\tvalid_0's auc: 0.719828\n",
      "[23]\tvalid_0's auc: 0.72032\n",
      "[24]\tvalid_0's auc: 0.720314\n",
      "[25]\tvalid_0's auc: 0.72091\n",
      "[26]\tvalid_0's auc: 0.721158\n",
      "[27]\tvalid_0's auc: 0.721249\n",
      "[28]\tvalid_0's auc: 0.721634\n",
      "[29]\tvalid_0's auc: 0.721922\n",
      "[30]\tvalid_0's auc: 0.722233\n",
      "[31]\tvalid_0's auc: 0.722445\n",
      "[32]\tvalid_0's auc: 0.722639\n",
      "[33]\tvalid_0's auc: 0.72289\n",
      "[34]\tvalid_0's auc: 0.723073\n",
      "[35]\tvalid_0's auc: 0.723201\n",
      "[36]\tvalid_0's auc: 0.723571\n",
      "[37]\tvalid_0's auc: 0.723672\n",
      "[38]\tvalid_0's auc: 0.723986\n",
      "[39]\tvalid_0's auc: 0.724132\n",
      "[40]\tvalid_0's auc: 0.724233\n",
      "[41]\tvalid_0's auc: 0.724683\n",
      "[42]\tvalid_0's auc: 0.724913\n",
      "[43]\tvalid_0's auc: 0.725231\n",
      "[44]\tvalid_0's auc: 0.725593\n",
      "[45]\tvalid_0's auc: 0.725934\n",
      "[46]\tvalid_0's auc: 0.726132\n",
      "[47]\tvalid_0's auc: 0.726422\n",
      "[48]\tvalid_0's auc: 0.726559\n",
      "[49]\tvalid_0's auc: 0.726766\n",
      "[50]\tvalid_0's auc: 0.726965\n",
      "[51]\tvalid_0's auc: 0.727092\n",
      "[52]\tvalid_0's auc: 0.727243\n",
      "[53]\tvalid_0's auc: 0.727437\n",
      "[54]\tvalid_0's auc: 0.727601\n",
      "[55]\tvalid_0's auc: 0.727692\n",
      "[56]\tvalid_0's auc: 0.727869\n",
      "[57]\tvalid_0's auc: 0.728017\n",
      "[58]\tvalid_0's auc: 0.72817\n",
      "[59]\tvalid_0's auc: 0.728341\n",
      "[60]\tvalid_0's auc: 0.728481\n",
      "[61]\tvalid_0's auc: 0.728747\n",
      "[62]\tvalid_0's auc: 0.728926\n",
      "[63]\tvalid_0's auc: 0.729193\n",
      "[64]\tvalid_0's auc: 0.729491\n",
      "[65]\tvalid_0's auc: 0.72956\n",
      "[66]\tvalid_0's auc: 0.729798\n",
      "[67]\tvalid_0's auc: 0.729858\n",
      "[68]\tvalid_0's auc: 0.730112\n",
      "[69]\tvalid_0's auc: 0.730181\n",
      "[70]\tvalid_0's auc: 0.730367\n",
      "[71]\tvalid_0's auc: 0.730487\n",
      "[72]\tvalid_0's auc: 0.730727\n",
      "[73]\tvalid_0's auc: 0.730886\n",
      "[74]\tvalid_0's auc: 0.731083\n",
      "[75]\tvalid_0's auc: 0.731181\n",
      "[76]\tvalid_0's auc: 0.731357\n",
      "[77]\tvalid_0's auc: 0.731444\n",
      "[78]\tvalid_0's auc: 0.731648\n",
      "[79]\tvalid_0's auc: 0.731707\n",
      "[80]\tvalid_0's auc: 0.731907\n",
      "[81]\tvalid_0's auc: 0.73196\n",
      "[82]\tvalid_0's auc: 0.732113\n",
      "[83]\tvalid_0's auc: 0.732192\n",
      "[84]\tvalid_0's auc: 0.7324\n",
      "[85]\tvalid_0's auc: 0.732502\n",
      "[86]\tvalid_0's auc: 0.732602\n",
      "[87]\tvalid_0's auc: 0.73278\n",
      "[88]\tvalid_0's auc: 0.732968\n",
      "[89]\tvalid_0's auc: 0.733027\n",
      "[90]\tvalid_0's auc: 0.733149\n",
      "[91]\tvalid_0's auc: 0.733296\n",
      "[92]\tvalid_0's auc: 0.733448\n",
      "[93]\tvalid_0's auc: 0.733479\n",
      "[94]\tvalid_0's auc: 0.733538\n",
      "[95]\tvalid_0's auc: 0.73372\n",
      "[96]\tvalid_0's auc: 0.733832\n",
      "[97]\tvalid_0's auc: 0.733977\n",
      "[98]\tvalid_0's auc: 0.73409\n",
      "[99]\tvalid_0's auc: 0.734236\n",
      "[100]\tvalid_0's auc: 0.734385\n",
      "[101]\tvalid_0's auc: 0.734503\n",
      "[102]\tvalid_0's auc: 0.734601\n",
      "[103]\tvalid_0's auc: 0.734682\n",
      "[104]\tvalid_0's auc: 0.734833\n",
      "[105]\tvalid_0's auc: 0.73497\n",
      "[106]\tvalid_0's auc: 0.73512\n",
      "[107]\tvalid_0's auc: 0.735279\n",
      "[108]\tvalid_0's auc: 0.735397\n",
      "[109]\tvalid_0's auc: 0.735521\n",
      "[110]\tvalid_0's auc: 0.735569\n",
      "[111]\tvalid_0's auc: 0.735661\n",
      "[112]\tvalid_0's auc: 0.735726\n",
      "[113]\tvalid_0's auc: 0.735866\n",
      "[114]\tvalid_0's auc: 0.736015\n",
      "[115]\tvalid_0's auc: 0.736111\n",
      "[116]\tvalid_0's auc: 0.736223\n",
      "[117]\tvalid_0's auc: 0.736331\n",
      "[118]\tvalid_0's auc: 0.736452\n",
      "[119]\tvalid_0's auc: 0.736546\n",
      "[120]\tvalid_0's auc: 0.736665\n",
      "[121]\tvalid_0's auc: 0.736828\n",
      "[122]\tvalid_0's auc: 0.736891\n",
      "[123]\tvalid_0's auc: 0.73701\n",
      "[124]\tvalid_0's auc: 0.737142\n",
      "[125]\tvalid_0's auc: 0.737265\n",
      "[126]\tvalid_0's auc: 0.73738\n",
      "[127]\tvalid_0's auc: 0.737543\n",
      "[128]\tvalid_0's auc: 0.737611\n",
      "[129]\tvalid_0's auc: 0.737753\n",
      "[130]\tvalid_0's auc: 0.737865\n",
      "[131]\tvalid_0's auc: 0.738015\n",
      "[132]\tvalid_0's auc: 0.738122\n",
      "[133]\tvalid_0's auc: 0.738246\n",
      "[134]\tvalid_0's auc: 0.738316\n",
      "[135]\tvalid_0's auc: 0.738435\n",
      "[136]\tvalid_0's auc: 0.73853\n",
      "[137]\tvalid_0's auc: 0.7386\n",
      "[138]\tvalid_0's auc: 0.738718\n",
      "[139]\tvalid_0's auc: 0.738784\n",
      "[140]\tvalid_0's auc: 0.738905\n",
      "[141]\tvalid_0's auc: 0.738995\n",
      "[142]\tvalid_0's auc: 0.739116\n",
      "[143]\tvalid_0's auc: 0.739201\n",
      "[144]\tvalid_0's auc: 0.739318\n",
      "[145]\tvalid_0's auc: 0.739412\n",
      "[146]\tvalid_0's auc: 0.739528\n",
      "[147]\tvalid_0's auc: 0.739629\n",
      "[148]\tvalid_0's auc: 0.739714\n",
      "[149]\tvalid_0's auc: 0.739819\n",
      "[150]\tvalid_0's auc: 0.7399\n",
      "[151]\tvalid_0's auc: 0.739987\n",
      "[152]\tvalid_0's auc: 0.740081\n",
      "[153]\tvalid_0's auc: 0.740173\n",
      "[154]\tvalid_0's auc: 0.740236\n",
      "[155]\tvalid_0's auc: 0.740307\n",
      "[156]\tvalid_0's auc: 0.740428\n",
      "[157]\tvalid_0's auc: 0.740507\n",
      "[158]\tvalid_0's auc: 0.740603\n",
      "[159]\tvalid_0's auc: 0.740693\n",
      "[160]\tvalid_0's auc: 0.740787\n",
      "[161]\tvalid_0's auc: 0.740854\n",
      "[162]\tvalid_0's auc: 0.740922\n",
      "[163]\tvalid_0's auc: 0.74099\n",
      "[164]\tvalid_0's auc: 0.741075\n",
      "[165]\tvalid_0's auc: 0.74113\n",
      "[166]\tvalid_0's auc: 0.741209\n",
      "[167]\tvalid_0's auc: 0.741267\n",
      "[168]\tvalid_0's auc: 0.741398\n",
      "[169]\tvalid_0's auc: 0.741461\n",
      "[170]\tvalid_0's auc: 0.741564\n",
      "[171]\tvalid_0's auc: 0.741624\n",
      "[172]\tvalid_0's auc: 0.74181\n",
      "[173]\tvalid_0's auc: 0.741924\n",
      "[174]\tvalid_0's auc: 0.741974\n",
      "[175]\tvalid_0's auc: 0.742071\n",
      "[176]\tvalid_0's auc: 0.74218\n",
      "[177]\tvalid_0's auc: 0.742217\n",
      "[178]\tvalid_0's auc: 0.742312\n",
      "[179]\tvalid_0's auc: 0.742453\n",
      "[180]\tvalid_0's auc: 0.742602\n",
      "[181]\tvalid_0's auc: 0.742738\n",
      "[182]\tvalid_0's auc: 0.742843\n",
      "[183]\tvalid_0's auc: 0.742974\n",
      "[184]\tvalid_0's auc: 0.743135\n",
      "[185]\tvalid_0's auc: 0.743284\n",
      "[186]\tvalid_0's auc: 0.743405\n",
      "[187]\tvalid_0's auc: 0.743549\n",
      "[188]\tvalid_0's auc: 0.743659\n",
      "[189]\tvalid_0's auc: 0.743754\n",
      "[190]\tvalid_0's auc: 0.743863\n",
      "[191]\tvalid_0's auc: 0.743987\n",
      "[192]\tvalid_0's auc: 0.744091\n",
      "[193]\tvalid_0's auc: 0.744165\n",
      "[194]\tvalid_0's auc: 0.74425\n",
      "[195]\tvalid_0's auc: 0.744397\n",
      "[196]\tvalid_0's auc: 0.744545\n",
      "[197]\tvalid_0's auc: 0.744694\n",
      "[198]\tvalid_0's auc: 0.744807\n",
      "[199]\tvalid_0's auc: 0.744879\n",
      "[200]\tvalid_0's auc: 0.744956\n",
      "[201]\tvalid_0's auc: 0.745093\n",
      "[202]\tvalid_0's auc: 0.745153\n",
      "[203]\tvalid_0's auc: 0.745245\n",
      "[204]\tvalid_0's auc: 0.745377\n",
      "[205]\tvalid_0's auc: 0.745425\n",
      "[206]\tvalid_0's auc: 0.745492\n",
      "[207]\tvalid_0's auc: 0.745616\n",
      "[208]\tvalid_0's auc: 0.745731\n",
      "[209]\tvalid_0's auc: 0.745853\n",
      "[210]\tvalid_0's auc: 0.745945\n",
      "[211]\tvalid_0's auc: 0.745981\n",
      "[212]\tvalid_0's auc: 0.746061\n",
      "[213]\tvalid_0's auc: 0.746118\n",
      "[214]\tvalid_0's auc: 0.746188\n",
      "[215]\tvalid_0's auc: 0.746246\n",
      "[216]\tvalid_0's auc: 0.746318\n",
      "[217]\tvalid_0's auc: 0.746391\n",
      "[218]\tvalid_0's auc: 0.746485\n",
      "[219]\tvalid_0's auc: 0.746534\n",
      "[220]\tvalid_0's auc: 0.746629\n",
      "[221]\tvalid_0's auc: 0.746719\n",
      "[222]\tvalid_0's auc: 0.7468\n",
      "[223]\tvalid_0's auc: 0.746884\n",
      "[224]\tvalid_0's auc: 0.746933\n",
      "[225]\tvalid_0's auc: 0.747034\n",
      "[226]\tvalid_0's auc: 0.747176\n",
      "[227]\tvalid_0's auc: 0.747251\n",
      "[228]\tvalid_0's auc: 0.747323\n",
      "[229]\tvalid_0's auc: 0.747366\n",
      "[230]\tvalid_0's auc: 0.747418\n",
      "[231]\tvalid_0's auc: 0.747522\n",
      "[232]\tvalid_0's auc: 0.747645\n",
      "[233]\tvalid_0's auc: 0.747725\n",
      "[234]\tvalid_0's auc: 0.747812\n",
      "[235]\tvalid_0's auc: 0.747853\n",
      "[236]\tvalid_0's auc: 0.747915\n",
      "[237]\tvalid_0's auc: 0.747976\n",
      "[238]\tvalid_0's auc: 0.748058\n",
      "[239]\tvalid_0's auc: 0.748126\n",
      "[240]\tvalid_0's auc: 0.748191\n",
      "[241]\tvalid_0's auc: 0.74825\n",
      "[242]\tvalid_0's auc: 0.748305\n",
      "[243]\tvalid_0's auc: 0.748401\n",
      "[244]\tvalid_0's auc: 0.748462\n",
      "[245]\tvalid_0's auc: 0.748527\n",
      "[246]\tvalid_0's auc: 0.748584\n",
      "[247]\tvalid_0's auc: 0.748629\n",
      "[248]\tvalid_0's auc: 0.748671\n",
      "[249]\tvalid_0's auc: 0.748787\n",
      "[250]\tvalid_0's auc: 0.748863\n",
      "[251]\tvalid_0's auc: 0.748958\n",
      "[252]\tvalid_0's auc: 0.748988\n",
      "[253]\tvalid_0's auc: 0.749053\n",
      "[254]\tvalid_0's auc: 0.749132\n",
      "[255]\tvalid_0's auc: 0.749219\n",
      "[256]\tvalid_0's auc: 0.749295\n",
      "[257]\tvalid_0's auc: 0.749316\n",
      "[258]\tvalid_0's auc: 0.749383\n",
      "[259]\tvalid_0's auc: 0.749478\n",
      "[260]\tvalid_0's auc: 0.749575\n",
      "[261]\tvalid_0's auc: 0.749638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[262]\tvalid_0's auc: 0.749677\n",
      "[263]\tvalid_0's auc: 0.749756\n",
      "[264]\tvalid_0's auc: 0.749848\n",
      "[265]\tvalid_0's auc: 0.749877\n",
      "[266]\tvalid_0's auc: 0.749966\n",
      "[267]\tvalid_0's auc: 0.75\n",
      "[268]\tvalid_0's auc: 0.750032\n",
      "[269]\tvalid_0's auc: 0.750088\n",
      "[270]\tvalid_0's auc: 0.750178\n",
      "[271]\tvalid_0's auc: 0.750233\n",
      "[272]\tvalid_0's auc: 0.750316\n",
      "[273]\tvalid_0's auc: 0.750366\n",
      "[274]\tvalid_0's auc: 0.750391\n",
      "[275]\tvalid_0's auc: 0.750468\n",
      "[276]\tvalid_0's auc: 0.750549\n",
      "[277]\tvalid_0's auc: 0.750593\n",
      "[278]\tvalid_0's auc: 0.750638\n",
      "[279]\tvalid_0's auc: 0.750715\n",
      "[280]\tvalid_0's auc: 0.750769\n",
      "[281]\tvalid_0's auc: 0.750808\n",
      "[282]\tvalid_0's auc: 0.750832\n",
      "[283]\tvalid_0's auc: 0.75085\n",
      "[284]\tvalid_0's auc: 0.750921\n",
      "[285]\tvalid_0's auc: 0.750991\n",
      "[286]\tvalid_0's auc: 0.751066\n",
      "[287]\tvalid_0's auc: 0.751109\n",
      "[288]\tvalid_0's auc: 0.751149\n",
      "[289]\tvalid_0's auc: 0.751243\n",
      "[290]\tvalid_0's auc: 0.751261\n",
      "[291]\tvalid_0's auc: 0.751327\n",
      "[292]\tvalid_0's auc: 0.751353\n",
      "[293]\tvalid_0's auc: 0.751428\n",
      "[294]\tvalid_0's auc: 0.751535\n",
      "[295]\tvalid_0's auc: 0.751559\n",
      "[296]\tvalid_0's auc: 0.751592\n",
      "[297]\tvalid_0's auc: 0.751613\n",
      "[298]\tvalid_0's auc: 0.751719\n",
      "[299]\tvalid_0's auc: 0.751771\n",
      "[300]\tvalid_0's auc: 0.751829\n",
      "[301]\tvalid_0's auc: 0.751864\n",
      "[302]\tvalid_0's auc: 0.751926\n",
      "[303]\tvalid_0's auc: 0.751995\n",
      "[304]\tvalid_0's auc: 0.752026\n",
      "[305]\tvalid_0's auc: 0.752076\n",
      "[306]\tvalid_0's auc: 0.752133\n",
      "[307]\tvalid_0's auc: 0.752187\n",
      "[308]\tvalid_0's auc: 0.752281\n",
      "[309]\tvalid_0's auc: 0.752342\n",
      "[310]\tvalid_0's auc: 0.752429\n",
      "[311]\tvalid_0's auc: 0.752457\n",
      "[312]\tvalid_0's auc: 0.752525\n",
      "[313]\tvalid_0's auc: 0.752577\n",
      "[314]\tvalid_0's auc: 0.752666\n",
      "[315]\tvalid_0's auc: 0.752699\n",
      "[316]\tvalid_0's auc: 0.752715\n",
      "[317]\tvalid_0's auc: 0.752799\n",
      "[318]\tvalid_0's auc: 0.752848\n",
      "[319]\tvalid_0's auc: 0.752905\n",
      "[320]\tvalid_0's auc: 0.75299\n",
      "[321]\tvalid_0's auc: 0.753017\n",
      "[322]\tvalid_0's auc: 0.753069\n",
      "[323]\tvalid_0's auc: 0.753116\n",
      "[324]\tvalid_0's auc: 0.753165\n",
      "[325]\tvalid_0's auc: 0.753215\n",
      "[326]\tvalid_0's auc: 0.753282\n",
      "[327]\tvalid_0's auc: 0.753357\n",
      "[328]\tvalid_0's auc: 0.753398\n",
      "[329]\tvalid_0's auc: 0.753445\n",
      "[330]\tvalid_0's auc: 0.753471\n",
      "[331]\tvalid_0's auc: 0.75354\n",
      "[332]\tvalid_0's auc: 0.753577\n",
      "[333]\tvalid_0's auc: 0.753619\n",
      "[334]\tvalid_0's auc: 0.753684\n",
      "[335]\tvalid_0's auc: 0.753729\n",
      "[336]\tvalid_0's auc: 0.753793\n",
      "[337]\tvalid_0's auc: 0.753817\n",
      "[338]\tvalid_0's auc: 0.753848\n",
      "[339]\tvalid_0's auc: 0.753889\n",
      "[340]\tvalid_0's auc: 0.753968\n",
      "[341]\tvalid_0's auc: 0.75401\n",
      "[342]\tvalid_0's auc: 0.75404\n",
      "[343]\tvalid_0's auc: 0.754092\n",
      "[344]\tvalid_0's auc: 0.754155\n",
      "[345]\tvalid_0's auc: 0.75417\n",
      "[346]\tvalid_0's auc: 0.754219\n",
      "[347]\tvalid_0's auc: 0.754242\n",
      "[348]\tvalid_0's auc: 0.754259\n",
      "[349]\tvalid_0's auc: 0.754283\n",
      "[350]\tvalid_0's auc: 0.754343\n",
      "[351]\tvalid_0's auc: 0.754382\n",
      "[352]\tvalid_0's auc: 0.754408\n",
      "[353]\tvalid_0's auc: 0.754427\n",
      "[354]\tvalid_0's auc: 0.754472\n",
      "[355]\tvalid_0's auc: 0.754523\n",
      "[356]\tvalid_0's auc: 0.754561\n",
      "[357]\tvalid_0's auc: 0.754614\n",
      "[358]\tvalid_0's auc: 0.754658\n",
      "[359]\tvalid_0's auc: 0.754685\n",
      "[360]\tvalid_0's auc: 0.754755\n",
      "[361]\tvalid_0's auc: 0.754781\n",
      "[362]\tvalid_0's auc: 0.754815\n",
      "[363]\tvalid_0's auc: 0.754864\n",
      "[364]\tvalid_0's auc: 0.754879\n",
      "[365]\tvalid_0's auc: 0.754915\n",
      "[366]\tvalid_0's auc: 0.754961\n",
      "[367]\tvalid_0's auc: 0.754971\n",
      "[368]\tvalid_0's auc: 0.754988\n",
      "[369]\tvalid_0's auc: 0.755013\n",
      "[370]\tvalid_0's auc: 0.755028\n",
      "[371]\tvalid_0's auc: 0.75509\n",
      "[372]\tvalid_0's auc: 0.755137\n",
      "[373]\tvalid_0's auc: 0.75519\n",
      "[374]\tvalid_0's auc: 0.755226\n",
      "[375]\tvalid_0's auc: 0.75525\n",
      "[376]\tvalid_0's auc: 0.755266\n",
      "[377]\tvalid_0's auc: 0.755294\n",
      "[378]\tvalid_0's auc: 0.755345\n",
      "[379]\tvalid_0's auc: 0.755376\n",
      "[380]\tvalid_0's auc: 0.755421\n",
      "[381]\tvalid_0's auc: 0.755429\n",
      "[382]\tvalid_0's auc: 0.755462\n",
      "[383]\tvalid_0's auc: 0.755514\n",
      "[384]\tvalid_0's auc: 0.755542\n",
      "[385]\tvalid_0's auc: 0.755565\n",
      "[386]\tvalid_0's auc: 0.755598\n",
      "[387]\tvalid_0's auc: 0.755635\n",
      "[388]\tvalid_0's auc: 0.755654\n",
      "[389]\tvalid_0's auc: 0.755681\n",
      "[390]\tvalid_0's auc: 0.755707\n",
      "[391]\tvalid_0's auc: 0.755753\n",
      "[392]\tvalid_0's auc: 0.755765\n",
      "[393]\tvalid_0's auc: 0.755776\n",
      "[394]\tvalid_0's auc: 0.755789\n",
      "[395]\tvalid_0's auc: 0.75582\n",
      "[396]\tvalid_0's auc: 0.755832\n",
      "[397]\tvalid_0's auc: 0.755865\n",
      "[398]\tvalid_0's auc: 0.755917\n",
      "[399]\tvalid_0's auc: 0.755931\n",
      "[400]\tvalid_0's auc: 0.755958\n",
      "[401]\tvalid_0's auc: 0.755995\n",
      "[402]\tvalid_0's auc: 0.755999\n",
      "[403]\tvalid_0's auc: 0.756021\n",
      "[404]\tvalid_0's auc: 0.756046\n",
      "[405]\tvalid_0's auc: 0.756069\n",
      "[406]\tvalid_0's auc: 0.756099\n",
      "[407]\tvalid_0's auc: 0.756151\n",
      "[408]\tvalid_0's auc: 0.75617\n",
      "[409]\tvalid_0's auc: 0.756195\n",
      "[410]\tvalid_0's auc: 0.756241\n",
      "[411]\tvalid_0's auc: 0.756269\n",
      "[412]\tvalid_0's auc: 0.756282\n",
      "[413]\tvalid_0's auc: 0.756297\n",
      "[414]\tvalid_0's auc: 0.756323\n",
      "[415]\tvalid_0's auc: 0.756377\n",
      "[416]\tvalid_0's auc: 0.7564\n",
      "[417]\tvalid_0's auc: 0.756458\n",
      "[418]\tvalid_0's auc: 0.756505\n",
      "[419]\tvalid_0's auc: 0.75653\n",
      "[420]\tvalid_0's auc: 0.756546\n",
      "[421]\tvalid_0's auc: 0.756571\n",
      "[422]\tvalid_0's auc: 0.756609\n",
      "[423]\tvalid_0's auc: 0.756638\n",
      "[424]\tvalid_0's auc: 0.756699\n",
      "[425]\tvalid_0's auc: 0.756718\n",
      "[426]\tvalid_0's auc: 0.756749\n",
      "[427]\tvalid_0's auc: 0.756761\n",
      "[428]\tvalid_0's auc: 0.756783\n",
      "[429]\tvalid_0's auc: 0.756803\n",
      "[430]\tvalid_0's auc: 0.756853\n",
      "[431]\tvalid_0's auc: 0.756893\n",
      "[432]\tvalid_0's auc: 0.756905\n",
      "[433]\tvalid_0's auc: 0.756919\n",
      "[434]\tvalid_0's auc: 0.756942\n",
      "[435]\tvalid_0's auc: 0.756955\n",
      "[436]\tvalid_0's auc: 0.757008\n",
      "[437]\tvalid_0's auc: 0.757046\n",
      "[438]\tvalid_0's auc: 0.757068\n",
      "[439]\tvalid_0's auc: 0.757102\n",
      "[440]\tvalid_0's auc: 0.757138\n",
      "[441]\tvalid_0's auc: 0.757182\n",
      "[442]\tvalid_0's auc: 0.757196\n",
      "[443]\tvalid_0's auc: 0.757243\n",
      "[444]\tvalid_0's auc: 0.757283\n",
      "[445]\tvalid_0's auc: 0.75729\n",
      "[446]\tvalid_0's auc: 0.757318\n",
      "[447]\tvalid_0's auc: 0.757345\n",
      "[448]\tvalid_0's auc: 0.757402\n",
      "[449]\tvalid_0's auc: 0.757412\n",
      "[450]\tvalid_0's auc: 0.757446\n",
      "[451]\tvalid_0's auc: 0.757472\n",
      "[452]\tvalid_0's auc: 0.757487\n",
      "[453]\tvalid_0's auc: 0.757531\n",
      "[454]\tvalid_0's auc: 0.757546\n",
      "[455]\tvalid_0's auc: 0.757565\n",
      "[456]\tvalid_0's auc: 0.757601\n",
      "[457]\tvalid_0's auc: 0.757628\n",
      "[458]\tvalid_0's auc: 0.757646\n",
      "[459]\tvalid_0's auc: 0.757662\n",
      "[460]\tvalid_0's auc: 0.757706\n",
      "[461]\tvalid_0's auc: 0.757711\n",
      "[462]\tvalid_0's auc: 0.757737\n",
      "[463]\tvalid_0's auc: 0.757757\n",
      "[464]\tvalid_0's auc: 0.757763\n",
      "[465]\tvalid_0's auc: 0.757786\n",
      "[466]\tvalid_0's auc: 0.757835\n",
      "[467]\tvalid_0's auc: 0.757874\n",
      "[468]\tvalid_0's auc: 0.757892\n",
      "[469]\tvalid_0's auc: 0.757903\n",
      "[470]\tvalid_0's auc: 0.757941\n",
      "[471]\tvalid_0's auc: 0.757995\n",
      "[472]\tvalid_0's auc: 0.758018\n",
      "[473]\tvalid_0's auc: 0.758064\n",
      "[474]\tvalid_0's auc: 0.758096\n",
      "[475]\tvalid_0's auc: 0.758109\n",
      "[476]\tvalid_0's auc: 0.758124\n",
      "[477]\tvalid_0's auc: 0.758143\n",
      "[478]\tvalid_0's auc: 0.758186\n",
      "[479]\tvalid_0's auc: 0.758195\n",
      "[480]\tvalid_0's auc: 0.75823\n",
      "[481]\tvalid_0's auc: 0.758262\n",
      "[482]\tvalid_0's auc: 0.758279\n",
      "[483]\tvalid_0's auc: 0.758285\n",
      "[484]\tvalid_0's auc: 0.758318\n",
      "[485]\tvalid_0's auc: 0.758328\n",
      "[486]\tvalid_0's auc: 0.75836\n",
      "[487]\tvalid_0's auc: 0.758405\n",
      "[488]\tvalid_0's auc: 0.758415\n",
      "[489]\tvalid_0's auc: 0.758418\n",
      "[490]\tvalid_0's auc: 0.758448\n",
      "[491]\tvalid_0's auc: 0.758484\n",
      "[492]\tvalid_0's auc: 0.758526\n",
      "[493]\tvalid_0's auc: 0.758528\n",
      "[494]\tvalid_0's auc: 0.758546\n",
      "[495]\tvalid_0's auc: 0.758562\n",
      "[496]\tvalid_0's auc: 0.758586\n",
      "[497]\tvalid_0's auc: 0.758595\n",
      "[498]\tvalid_0's auc: 0.758621\n",
      "[499]\tvalid_0's auc: 0.758639\n",
      "[500]\tvalid_0's auc: 0.758641\n"
     ]
    }
   ],
   "source": [
    "# パラーメータの調整\n",
    "params_algo = {\n",
    "                'task': 'train',\n",
    "                'boosting_type': 'gbdt',\n",
    "                'objective': 'binary',\n",
    "                'metric':'auc',\n",
    "                'learning_rate':0.01,\n",
    "                'n_estimators':500,\n",
    "            }\n",
    "\n",
    "# 学習と推定 \n",
    "model = lgb.train(params_algo, train, valid_sets=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】Kaggle Notebooksからの調査\n",
    "KaggleのNotebooksから様々なアイデアを見つけ出して、列挙してください。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クロスバリデーション種類\n",
    "•k分割交差検定<br>\n",
    "•層化k分割交差検定<br>\n",
    "•ホールドアウトベースの検証<br>\n",
    "•リーブワンアウト交差検定→データの中から1つのみ抽出<br>\n",
    "•グループk分割交差検定→グループに選びたいものだけ抽出する？<br>\n",
    "\n",
    " ### for使い繰り返し処理でクロスバリデーションを行なっている\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df['outliers'])):\n",
    "        train_x,  = train_df[feats].iloc[train_idx], \n",
    "        train_y = train_df['target'].iloc[train_idx]\n",
    "        valid_x = train_df[feats].iloc[valid_idx]\n",
    "        valid_y = train_df['target'].iloc[valid_idx]\n",
    "\n",
    "        # set data structure\n",
    "        lgb_train = lgb.Dataset(train_x,label=train_y,free_raw_data=False)\n",
    "        lgb_test = lgb.Dataset(valid_x,label=valid_y,free_raw_data=False)\n",
    "\n",
    "        # params optimized by optuna\n",
    "        params ={\n",
    "                        'task': 'train',\n",
    "                        'boosting': 'goss',\n",
    "                        'objective': 'regression',\n",
    "                        'metric': 'rmse',\n",
    "                        'learning_rate': 0.005,\n",
    "                        'subsample': 0.9855232997390695,\n",
    "                        'max_depth': 8,\n",
    "                        'top_rate': 0.9064148448434349,\n",
    "                        'num_leaves': 87,\n",
    "                        'min_child_weight': 41.9612869171337,\n",
    "                        'other_rate': 0.0721768246018207,\n",
    "                        'reg_alpha': 9.677537745007898,\n",
    "                        'colsample_bytree': 0.5665320670155495,\n",
    "                        'min_split_gain': 9.820197773625843,\n",
    "                        'reg_lambda': 8.2532317400459,\n",
    "                        'min_data_in_leaf': 21,\n",
    "                        'verbose': -1,\n",
    "                        'seed':int(2**n_fold),\n",
    "                        'bagging_seed':int(2**n_fold),\n",
    "                        'drop_seed':int(2**n_fold)\n",
    "                        }\n",
    "\n",
    "        reg = lgb.train(\n",
    "                        params,\n",
    "                        lgb_train,\n",
    "                        valid_sets=[lgb_train, lgb_test],\n",
    "                        valid_names=['train', 'test'],\n",
    "                        num_boost_round=10000,\n",
    "                        early_stopping_rounds= 200,\n",
    "                        verbose_eval=100\n",
    "                        )\n",
    "\n",
    "        oof_preds[valid_idx] = reg.predict(valid_x, num_iteration=reg.best_iteration)\n",
    "        sub_preds += reg.predict(test_df[feats], num_iteration=reg.best_iteration) / folds.n_splits\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feats\n",
    "        fold_importance_df[\"importance\"] = np.log1p(reg.feature_importance(importance_type='gain', iteration=reg.best_iteration))\n",
    "        fold_importance_df[\"fold\"] = n_fold + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        print('Fold %2d RMSE : %.6f' % (n_fold + 1, rmse(valid_y, oof_preds[valid_idx])))\n",
    "        del reg, train_x, train_y, valid_x, valid_y\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### グリッドサーチ\n",
    "%%time\n",
    "parameters = {\n",
    "    'max_depth': [3, 5, 7, 9], \n",
    "    'n_estimators': [5, 10, 15, 20, 25, 50, 100],\n",
    "    'learning_rate': [0.01, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(\n",
    "    random_state=SEED,\n",
    ")\n",
    "\n",
    "model_xgb = GridSearchCV(\n",
    "    model_xgb, \n",
    "    parameters, \n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    ")\n",
    "\n",
    "model_xgb.fit(X_train, y_train)\n",
    "\n",
    "print('-----')\n",
    "print(f'Best parameters {model_xgb.best_params_}')\n",
    "print(\n",
    "    f'Mean cross-validated accuracy score of the best_estimator: ' + \n",
    "    f'{model_xgb.best_score_:.3f}'\n",
    ")\n",
    "cross_valid_scores['xgboost'] = model_xgb.best_score_\n",
    "print('-----')\n",
    "-----\n",
    "Best parameters {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 50}\n",
    "Mean cross-validated accuracy score of the best_estimator: 0.848\n",
    "-----\n",
    "CPU times: user 16.1 s, sys: 217 ms, total: 16.3 s\n",
    "Wall time: 16.3 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】高い汎化性能のモデル作成\n",
    "問題3で見つけたアイデアと、独自のアイデアを組み合わせ高い汎化性能のモデル作りを進めてください。\n",
    "\n",
    "\n",
    "その過程として、何を行うことで、クロスバリデーションの結果がどの程度変化したかを表にまとめてください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:37:50] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:37:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7447646898536284\n"
     ]
    }
   ],
   "source": [
    "# XGBMでクロスバリデーションなしのスコアを確認する\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_app_train, y, random_state=22)\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "score_list1 = []\n",
    "\n",
    "#train、testデータ作成〜予測\n",
    "model = xgb.XGBClassifier(silent=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred = model.predict_proba(X_test)[:, 1]\n",
    "scores = roc_auc_score(y_test, pred)\n",
    "\n",
    "score_list1.append(scores)\n",
    "print(scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230633, 251)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:39:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:39:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7474700365975426\n",
      "[23:40:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:40:24] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7423615342952354\n",
      "[23:41:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:41:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7514631708370274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nlightgbmの処理\\n    \\n    train = lgb.Dataset(X_train4, label=y_train4, free_raw_data=False)\\n    test = lgb.Dataset(y_train4, label=y_test4, reference=train, free_raw_data=False)\\n    \\n    params = {'task': 'train',\\n             'boosting_type': 'gbdt',\\n              'objective': 'binary',\\n              'metric':'auc',\\n              'learning_rate':0.05,\\n              'n_estimators':100,\\n    }\\n    \\n    model = lgb.train(params, train, \\n                      valid_sets=test, \\n                      num_boost_round=5000, \\n                      early_stopping_rounds= 200,\\n                      verbose_eval=100)\\n\\n    model.predict(X_test4,num_iteration=model.best_iteration)\\n    \\n \""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lightGBMをfor文で学習の予定だったが、エラー修正が不可だったので\n",
    "# ひとまずXGBoostに変更する\n",
    "# 今回はそのままクロスバリデーションで学習する\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=22)\n",
    "score_list2 = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(new_app_train, y)):\n",
    "    X_train4 = new_app_train.loc[train_index]\n",
    "    y_train4 = y.iloc[train_index]\n",
    "    X_test4 = new_app_train.iloc[test_index]\n",
    "    y_test4 = y.iloc[test_index]\n",
    "    \n",
    "    #train、testデータ作成〜予測\n",
    "    model = xgb.XGBClassifier(silent=1)\n",
    "    model.fit(X_train4, y_train4)\n",
    "    pred = model.predict_proba(X_test4)[:, 1]\n",
    "    scores = roc_auc_score( y_test4, pred)\n",
    "    score_list2.append(scores)\n",
    "    print(scores)\n",
    "\n",
    "\n",
    "'''\n",
    "lightgbmの処理\n",
    "    \n",
    "    train = lgb.Dataset(X_train4, label=y_train4, free_raw_data=False)\n",
    "    test = lgb.Dataset(y_train4, label=y_test4, reference=train, free_raw_data=False)\n",
    "    \n",
    "    params = {'task': 'train',\n",
    "             'boosting_type': 'gbdt',\n",
    "              'objective': 'binary',\n",
    "              'metric':'auc',\n",
    "              'learning_rate':0.05,\n",
    "              'n_estimators':100,\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(params, train, \n",
    "                      valid_sets=test, \n",
    "                      num_boost_round=5000, \n",
    "                      early_stopping_rounds= 200,\n",
    "                      verbose_eval=100)\n",
    "\n",
    "    model.predict(X_test4,num_iteration=model.best_iteration)\n",
    "    \n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:16:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:17:23] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:18:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:20:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:21:39] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:23:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:24:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:26:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:28:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:30:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:31:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:33:00] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:34:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:35:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:36:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:38:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:39:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:41:34] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:43:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:45:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:47:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:48:43] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:50:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:51:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:52:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:54:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:56:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[21:58:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:00:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:01:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:03:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:05:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:06:35] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:07:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:09:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:10:40] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:12:26] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:14:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:15:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[22:17:31] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 63.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:19:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, eta=0.5, gamma=0.01,\n",
       "                                     gpu_id=-1, importance_type='gain',\n",
       "                                     interaction_constraints='',\n",
       "                                     learning_rate=0.5, max_delta_step=0,\n",
       "                                     max_depth=6, min_child_weight=1,\n",
       "                                     missing=nan, monotone_constraints='()',\n",
       "                                     n_estimators=100, n_jobs=8,\n",
       "                                     num_parallel_tree=1, random_state=0,\n",
       "                                     reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, subsample=1,\n",
       "                                     tree_method='exact', validate_parameters=1,\n",
       "                                     verbosity=None),\n",
       "             param_grid={'eta': [0.1, 0.5], 'gamma': [0.01, 0.001],\n",
       "                         'max_depth': [9, 12]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBMでグリッドサーチを行う\n",
    "# params = {'eta':[0.1,0.5], 'gamma':[0.01, 0.001], 'max_depth':[9, 12]}\n",
    "\n",
    "# grid = GridSearchCV(model, params, verbose=1)\n",
    "# grid.fit(X_train4, y_train4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eta': 0.1, 'gamma': 0.001, 'max_depth': 12}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# グリッドサーチの指標\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.897028413629427"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ベストスコア\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:42:47] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7462778968213293\n",
      "[23:45:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7398851605295693\n",
      "[23:47:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.7480723300570565\n"
     ]
    }
   ],
   "source": [
    "# グリッドサーチで評価した指標を投入する\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=22)\n",
    "\n",
    "score_list3 = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(new_app_train, y)):\n",
    "    X_train4 = new_app_train.loc[train_index]\n",
    "    y_train4 = y.iloc[train_index]\n",
    "    X_test4 = new_app_train.iloc[test_index]\n",
    "    y_test4 = y.iloc[test_index]\n",
    "    \n",
    "    #Jsonエラー修正\n",
    "    X_train4.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_train4.columns]\n",
    "    X_test4.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in X_test4.columns]\n",
    "\n",
    "    #train、testデータ作成〜予測\n",
    "    model = xgb.XGBClassifier(eta=0.1, gamma=0.001, max_depth=12)\n",
    "    model.fit(X_train4, y_train4)\n",
    "    pred = model.predict_proba(X_test4)[:, 1]\n",
    "    scores = roc_auc_score( y_test4, pred)\n",
    "    score_list3.append(scores)\n",
    "    print(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロスバリデーションなし　グリッドサーチなし \n",
    "# クロスバリデーションあり　グリッドサーチなし\n",
    "# クロスバリデーションあり　グリッドサーチあり　にて指標をまとめてみる\n",
    "\n",
    "score_list1 = np.array(score_list1)\n",
    "score_list2 = np.array(score_list2).reshape(-1,1)\n",
    "score_list3 = np.array(score_list3).reshape(-1,1)\n",
    "\n",
    "# 配列が正しくないので整理\n",
    "zero = np.zeros(2)\n",
    "score_list1_merge = np.concatenate([score_list1, zero], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配列を２次元に変更する\n",
    "score_list1_merge = score_list1_merge.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74476469, 0.74747004, 0.7462779 ],\n",
       "       [0.        , 0.74236153, 0.73988516],\n",
       "       [0.        , 0.75146317, 0.74807233]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 整えてマージする\n",
    "total_score =np.concatenate([score_list1_merge, score_list2, score_list3], axis=1)\n",
    "total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross, grid None</th>\n",
       "      <th>cross only</th>\n",
       "      <th>cross + grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.744765</td>\n",
       "      <td>0.747470</td>\n",
       "      <td>0.746278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.742362</td>\n",
       "      <td>0.739885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.751463</td>\n",
       "      <td>0.748072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cross, grid None  cross only  cross + grid\n",
       "0          0.744765    0.747470      0.746278\n",
       "1          0.000000    0.742362      0.739885\n",
       "2          0.000000    0.751463      0.748072"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # カラム名で、左から順に\n",
    "# クロスバリデーションなし　グリッドサーチなし \n",
    "# クロスバリデーションあり　グリッドサーチなし\n",
    "# クロスバリデーションあり　グリッドサーチあり\n",
    "total_score_pd = pd.DataFrame(total_score, columns = [\"cross, grid None\", \"cross only\", \"cross + grid\"])\n",
    "total_score_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "考察\n",
    "左と真ん中で、クロスバリデーションだけで微妙だけど上昇したことがわかる\n",
    "真ん中と右で、グリッドサーチで実施した内容は全部スコアが低いので、再度パラメータのチューニングを実施した方が良い状況\n",
    "Γで少しスコアが悪くなっている可能性がある。\n",
    "XGBoostでは再度検証をすべきだが、検証時間の兼ね合いでここでは割愛する。\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】最終的なモデルの選定\n",
    "最終的にこれは良いというモデルを選び、推定した結果をKaggleに提出してスコアを確認してください。どういったアイデアを取り入れ、どの程度のスコアになったかを記載してください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クロスバリデーションのpredを提出する\n",
    "\n",
    "pred = model.predict_proba(new_app_test)[:, 1]\n",
    "submission_id = new_app_test['SK_ID_CURR']\n",
    "\n",
    "submission = pd.DataFrame(pred, columns=['TARGET']).reset_index(drop=True)\n",
    "submission = pd.concat([submission_id, submission], axis=1).reset_index(drop=True)\n",
    "submission.to_csv(dir_path + \"submission_gbm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証結果\n",
    "# 前：0.74238\n",
    "# 今：0.72855\n",
    "'''\n",
    "以前はlightGBMを利用し提出を行った\n",
    "この際は、通常のホールアウト法を利用してグリッドサーチは利用せず出力されたスコア。\n",
    "今回は、グリッドサーチの結果があまり良くなかったため、XGBoostが好ましくないとは言い切れないが\n",
    "lightGBMもグリッドサーチを行っていないので、lightGBMに軍ぱいがあると言える。\n",
    "とはいえlightGBMだけ実施すれば良い物でもないのでアルゴリズムを求める場合両方追求する必要性がある。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
