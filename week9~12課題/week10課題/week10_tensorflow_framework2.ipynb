{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】公式チュートリアルモデルを分担して実行\n",
    "TensorFLowの公式チュートリアルモデルを分担して実行してください。\n",
    "\n",
    "\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。\n",
    "\n",
    "\n",
    "models/tutorials at master · tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dot, Embedding, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nseason = ['Spring', 'Summer', 'Fall', 'Winter']\\niter_season = iter(season)\\n\\nprint(type(iter_season)) # 型を表示して確認\\n\\nprint(next(iter_season)) # 1番目のイテレータを表示後、次のイテレータに進む\\nnext(iter_season) # 次のイテレータに進む\\n\\n# イテレータを１つずつ取り出して表示\\nfor i in iter_season:\\n    print(i)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "season = ['Spring', 'Summer', 'Fall', 'Winter']\n",
    "iter_season = iter(season)\n",
    "\n",
    "print(type(iter_season)) # 型を表示して確認\n",
    "\n",
    "print(next(iter_season)) # 1番目のイテレータを表示後、次のイテレータに進む\n",
    "next(iter_season) # 次のイテレータに進む\n",
    "\n",
    "# イテレータを１つずつ取り出して表示\n",
    "for i in iter_season:\n",
    "    print(i)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 \n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The wide road shimmered in the hot sun\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'the': 1, 'wide': 2, 'road': 3, 'shimmered': 4, 'in': 5, 'hot': 6, 'sun': 7}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# トークンから整数インデックスへのマッピングを保存するための語彙を作成\n",
    "\n",
    "vocab, index = {}, 1 # start indexing from 1\n",
    "vocab['<pad>'] = 0 # add a padding token \n",
    "\n",
    "for token in tokens:\n",
    "    if token not in vocab: \n",
    "        vocab[token] = index\n",
    "        index += 1\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'the', 2: 'wide', 3: 'road', 4: 'shimmered', 5: 'in', 6: 'hot', 7: 'sun'}\n"
     ]
    }
   ],
   "source": [
    "# dictの順番を入れ替える\n",
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "print(inverse_vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 1, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 文章をベクトル化\n",
    "example_sequence = [vocab[word] for word in tokens]\n",
    "print(example_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[2, 1],\n",
       " [6, 1],\n",
       " [3, 2],\n",
       " [5, 4],\n",
       " [1, 3],\n",
       " [3, 1],\n",
       " [1, 2],\n",
       " [4, 5],\n",
       " [2, 4],\n",
       " [6, 5],\n",
       " [7, 6],\n",
       " [7, 1],\n",
       " [4, 1],\n",
       " [1, 7],\n",
       " [3, 4],\n",
       " [5, 6],\n",
       " [1, 5],\n",
       " [2, 3],\n",
       " [1, 6],\n",
       " [1, 4],\n",
       " [5, 1],\n",
       " [3, 5],\n",
       " [6, 7],\n",
       " [4, 3],\n",
       " [4, 2],\n",
       " [5, 3]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スキップグラムを生成する\n",
    "# Word2Vecのデータ準備を簡素化する便利な関数を提供します。\n",
    "# スキップぐらむは全てのベクトルの組み合わせを出力している\n",
    "\n",
    "window_size = 2\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      example_sequence, \n",
    "      vocabulary_size=vocab_size, # 文章のトータルの長さ\n",
    "      window_size=window_size, # 前後のコンテキストの数\n",
    "      negative_samples=0, # ネガティブサンプリングの数\n",
    "    shuffle=True) # ドロップアウト\n",
    "print(len(positive_skip_grams))\n",
    "\n",
    "positive_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1): (wide, the)\n",
      "(6, 1): (hot, the)\n",
      "(3, 2): (road, wide)\n",
      "(5, 4): (in, shimmered)\n",
      "(1, 3): (the, road)\n"
     ]
    }
   ],
   "source": [
    "# 例(さっきの奴を表示している)\n",
    "for target, context in positive_skip_grams[:5]:\n",
    "    print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 1 4 3], shape=(4,), dtype=int64)\n",
      "['wide', 'the', 'shimmered', 'road']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[1]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スキップぐらむからtarget、contex-wordを抽出\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "# ネガティブサンプリングの数\n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class, # ポジティブクラス全体\n",
    "    num_true=1, # ポジティブクラスの数？\n",
    "    num_sampled=num_ns, # ネガティブサンプリングの数\n",
    "    unique=True, # all the negative samples should be unique\n",
    "    range_max=vocab_size, # 持ってくる特徴量の範囲\n",
    "    seed=SEED, \n",
    "    name=\"negative_sampling\" \n",
    ")\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])\n",
    "\n",
    "#tf.constant(context_word, dtype=\"int64\")\n",
    "#tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "context_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# トレーニング例\n",
    "# 次元を増やす\n",
    "negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
    "\n",
    "# ポジティブワードとネガティブワードを合体させる\n",
    "context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "# ラベルの作成\n",
    "label = tf.constant([1] + [0]*num_ns, dtype=\"int64\") \n",
    "\n",
    "# 次元を潰す\n",
    "target = tf.squeeze(target_word)\n",
    "context = tf.squeeze(context)\n",
    "label =  tf.squeeze(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_index    : 2\n",
      "target_word     : wide\n",
      "context_indices : [1 2 1 4 3]\n",
      "context_words   : ['the', 'wide', 'the', 'shimmered', 'road']\n",
      "label           : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# labelの確認\n",
    "print(f\"target_index    : {target}\")\n",
    "print(f\"target_word     : {inverse_vocab[target_word]}\")\n",
    "print(f\"context_indices : {context}\")\n",
    "print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n",
    "print(f\"label           : {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  : tf.Tensor(2, shape=(), dtype=int32)\n",
      "context : tf.Tensor([1 2 1 4 3], shape=(5,), dtype=int64)\n",
      "label   : tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# スキップグラムネガティブサンプリングWord2Vecモデルをトレーニングする\n",
    "print(f\"target  :\", target)\n",
    "print(f\"context :\", context )\n",
    "print(f\"label   :\", label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
      " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
     ]
    }
   ],
   "source": [
    "# 単語頻度ランクベースの確率的サンプリングテーブルを生成\n",
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
    "print(sampling_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータを生成する\n",
    "\n",
    "# スキップグラムとネガティブサンプリングのペアをシーケンスに与える\n",
    "# ウィンドウズサイズは負のサンプルに基づく\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "    targets, contexts, labels = [], [], []\n",
    "    # vocab_sizeトークンのサンプリングテーブルを作成\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "    \n",
    "    # データセット内のすべてのシーケンス(文)に反復\n",
    "    for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    # シーケンス(文)の正のスキップグラムペアを生成します。.\n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "            sequence, \n",
    "            vocabulary_size=vocab_size,\n",
    "            sampling_table=sampling_table,\n",
    "            window_size=window_size,\n",
    "            negative_samples=0)\n",
    "\n",
    "    # トレーニング例を作成するために、各ポジティブスキップグラムペアを反復します。 \n",
    "    # 正のコンテキストワードと負のサンプル。.\n",
    "        for target_word, context_word in positive_skip_grams:\n",
    "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                true_classes=context_class,\n",
    "                num_true=1,\n",
    "                num_sampled=num_ns, \n",
    "                unique=True, \n",
    "                range_max=vocab_size, \n",
    "                seed=SEED, \n",
    "                name=\"negative_sampling\")\n",
    "\n",
    "      # コンテキストを作成し、ベクトルにラベルを付けます(1つのターゲットワード)\n",
    "            negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
    "\n",
    "            context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "            label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "      # トレーニングの例からグローバルリストに各要素を追加します。.\n",
    "            targets.append(target_word)\n",
    "            contexts.append(context)\n",
    "            labels.append(label)\n",
    "    return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コーパスのDL\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n"
     ]
    }
   ],
   "source": [
    "# コーパスの文章\n",
    "with open(path_to_file) as f: \n",
    "    lines = f.read().splitlines()\n",
    "for line in lines[:20]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FilterDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ベクトル化のためにDatasetへ変換\n",
    "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))\n",
    "text_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コーパスから文をベクトル化する\n",
    "# カスタム標準化機能を作成して、テキストを下げます。 \n",
    "# 句読点の削除\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "# サイズと単語数を順番に定義します。.\n",
    "vocab_size = 4096\n",
    "sequence_length = 10\n",
    "\n",
    "# テキストベクトル化レイヤーを使用して、文字列を正規化、分割、およびマップします。\n",
    "#整数、output_sequence_length lengthを設定して、すべてのサンプルを同じ長さにパッドします。.\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization, # 正規化\n",
    "    max_tokens=vocab_size, # 語彙の最大値\n",
    "    output_mode='int', \n",
    "    output_sequence_length=sequence_length) # 出力する文章の長さ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストデータセットでadaptを呼び出して、語彙を作成します。\n",
    "vectorize_layer.adapt(text_ds.batch(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a', 'that', 'in', 'is', 'not', 'for', 'with', 'me', 'it', 'be', 'your']\n"
     ]
    }
   ],
   "source": [
    "# 語彙にアクセス\n",
    "# 参照用に作成したボキャブラリーを保存します。.\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトル生成\n",
    "def vectorize_text(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return tf.squeeze(vectorize_layer(text))\n",
    "\n",
    "# text_dsでデータを修正します。.\n",
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([138,  36, 982, 144, 673, 125,  16, 106,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([106, 106,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   7,   41,   34, 1286,  344,    4,  200,   64,    4, 3690]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([1286, 1286,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  89,    7,   93, 1187,  225,   12, 2442,  592,    4,    2]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  36, 2655,   36, 2655,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  72,   79,  506,   27,    3,   56,   24, 1390,   57,   40]),\n",
       " array([644,   9,   1,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  32,   54, 2863,  885,   72,   17,   18,  163,  146,  146]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 74, 218,  46, 595,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,   41,    1,  172,  595,    2, 1780,   46,    0,    0]),\n",
       " array([  29, 1323,    1,   47,   58,    1,   79,   39,   60,    0]),\n",
       " array([ 58, 573,  79,  22,   2,   1, 334,  17,  76,   0]),\n",
       " array([1870,   36,  258, 1026,   60,    1,   79,    1,    0,    0]),\n",
       " array([ 22,  60, 131,  36,  41, 100, 267,   2,   1,  10]),\n",
       " array([   1,   79,    2, 2346,    6,   40, 1540,   12,   25,   88]),\n",
       " array([ 1,  4,  1, 65,  1, 40,  0,  0,  0,  0]),\n",
       " array([2871,   12,    9, 1375,    4,   66,   72,   79,  625,   21]),\n",
       " array([ 40,   1, 251,  36, 662,   1,  14,   2, 260,  93]),\n",
       " array([ 106,   21,   11,    1,   14, 2461,   13,   11, 3329,   14]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  58,    7,  982, 3696,  170, 1187,  225,    0,    0,    0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 170,   27,   89,  339,    9,  157, 1033,    4,    2,    1]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1834,    7,   29, 1519,   23,  320,  163,   14,   20,  659]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([157,  56,   3, 231,  18, 496,   4, 102,  27,  46]),\n",
       " array([ 556, 1169,   22,   10,   23, 3500,  245,   15,  145,  450]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([181,  22, 106,  13,   1,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  71, 214,   7,  29,  23,  70, 163,   1,  23]),\n",
       " array([ 17,   4,  10, 384, 171,   1, 153, 115,  18,   0]),\n",
       " array([496,   4,  71,  17,  59,  14,  20, 659,  23,  95]),\n",
       " array([ 303,   20,  223,    3,    4,   18, 1781,  450,   53,   23]),\n",
       " array([ 12, 196, 184,   2,   1,   6,  20, 638,   0,   0]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  29,   23,  142,  309,   11,   20,  408,    7, 1199,    9]),\n",
       " array([1206,   11,   27,    7,   86,   11,   32,  177,   71,   23]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  39,    5,   86,   13,    5,  451,   13,   18, 2022,    6]),\n",
       " array([  23,   70,  742,   15,    1,    4, 3322,   11, 3431,    0]),\n",
       " array([  29, 4083,   41,  104,    2,  205,  649,   48,    2,  445]),\n",
       " array([  12,    1,   90,  188,   36, 2956,   62,    4,    2, 1319]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([49, 49,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([752, 103, 194,  62,   0,   0,   0,   0,   0,   0]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 446,  154,    1,   74,   10,   70, 1196,  712,    0,    0]),\n",
       " array([  2, 307,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([339,  74, 605, 394,  58,  34,   2, 257,  76,  28]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  29,    1,    8, 2208,   11,  158,   97,   75,    7,    0]),\n",
       " array([ 15,   1,   3,   1,   2, 390, 106,   5, 160,   7]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  40,  388,   12,   13, 1504,    4,    2, 1520,   60,   24]),\n",
       " array([  92,    1,   21,    1,   29,   36, 1368,    4,   42,    0]),\n",
       " array([ 53,  44,  56, 315, 847,  11, 780,  60,  71, 172]),\n",
       " array([2089,   24,  751,    1,   60,   37,   93,   36,    0,    0]),\n",
       " array([ 24, 751, 395, 100,   0,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  90,  628,    8,   46,  208,  109,  605, 1942,    0,    0]),\n",
       " array([  31,    7, 2840,  969,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,  142,   51,   36,   41, 1268,  702,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5, 117,   7, 208, 120,   1, 497,   0,   0,   0]),\n",
       " array([  24,    2, 1780,    6,    7,   14,   19, 1610,    0,    0]),\n",
       " array([  19, 2870,   11,   21, 3136,    7,   78,   25,   56,    0]),\n",
       " array([ 537,   57,    2,  182,   15,   19,    1,   25, 1954,   66]),\n",
       " array([170,   2, 820, 329, 202, 690,  31,  47,   0,   0]),\n",
       " array([   2,  177,   17, 1623, 3150,  610,  352,    1,    0,    0]),\n",
       " array([  6,  54, 751,   1,   1,  64, 115, 195,   0,   0]),\n",
       " array([ 787,   11,   19, 3612,   14,    2, 3136,    0,    0,    0]),\n",
       " array([   2,  260,   13,    2, 1780,   80,   17,    3,    0,    0]),\n",
       " array([ 19, 987,   4,  66,  13, 395,  86, 309, 833,   0]),\n",
       " array([   7,   41, 3314,   33, 3193,    0,    0,    0,    0,    0]),\n",
       " array([ 770,   97,   54,    1,    7,    3,    7, 1346,    0,    0]),\n",
       " array([  2,   1,  48,   2, 329, 103, 497,  14,   7,  84]),\n",
       " array([ 73,   7, 699,  66,  25, 658,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([497,  14,  79, 139, 310,  60, 439,   1,  14,  79]),\n",
       " array([  82, 1052,   79,    4, 3690,    3,   65,    1,    0,    0]),\n",
       " array([   1,   15, 2402,   80,    1,   14,    1,    4,    0,    0]),\n",
       " array([3347,    1, 3432, 1830,  144, 1870,  968,    0,    0,    0]),\n",
       " array([   1,  170,    2,  683,    3, 2322,   54,    0,    0,    0]),\n",
       " array([2336, 2883, 1830,    4,    1,  111,    3,    1,    0,    0]),\n",
       " array([   2,  172,   39,    2,  664, 1126,   79,   13,  111,   60]),\n",
       " array([413,  34,   2,  77,  60, 203,  79,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([478,   7,  86,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 691,  969, 1729,    1,    0,    0,    0,    0,    0,    0]),\n",
       " array([  52,   18, 1861,    6, 1696,    5,   37,  117,    7,    0]),\n",
       " array([  9, 798, 639,  17,  78,  18,   7,  24, 311,  17]),\n",
       " array([  22,  228,   17, 1636,    8,  502,    5,   31, 2834,    0]),\n",
       " array([   4, 2279,  818,    9,  234,   54,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 56,  67, 125,  17,  51,  82,   7,  86,  13, 131]),\n",
       " array([   1,  219,   40, 1991,   15,    9,  639,   22,   88,  818]),\n",
       " array([  7, 959,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  85,   59,    9,  118,   73,   34,    2, 1842, 2636,    0]),\n",
       " array([   1,  170,    2, 1490,  141, 1861,   17,    0,    0,    0]),\n",
       " array([  10,  337,   84,    9, 3643,   17,   95, 1016,    0,    0]),\n",
       " array([   5,    2, 3002,   48,    2,  407, 1119,    3,    1,    0]),\n",
       " array([ 227,    1,    2,    1,  134, 1597,    0,    0,    0,    0]),\n",
       " array([  84, 1072,   15,    2,  257,   97,    2,  205, 1681,    0]),\n",
       " array([  95,   98,    3,  125, 1384, 1683, 1007,  808,    0,    0]),\n",
       " array([   3,    1,    1,   95, 1670,    0,    0,    0,    0,    0]),\n",
       " array([ 214,    2, 2031,    3, 1198,  572,    0,    0,    0,    0]),\n",
       " array([   6,    2, 1329,  407,    2, 1490, 2481,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  56,   51,   29,  351,  128,    2, 1490,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  51,    5,   37,  117,    7,   15,    9,  409,    6, 1058]),\n",
       " array([  53,  439,  285,   50,    2, 3566,   22,  196,  141,    0]),\n",
       " array([  14,  155,    7,    5,   78,   80,    2, 1490, 1058,    0]),\n",
       " array([  25,   56,   25,    1,    1, 3430,    0,    0,    0,    0]),\n",
       " array([   4,    2, 2722, 2636,    2, 2628, 1363,    0,    0,    0]),\n",
       " array([ 10,   1,  20,   1, 196,  28, 120,   1,   0,   0]),\n",
       " array([  25,    7,    1,   40, 1281,   14,   10,    0,    0,    0]),\n",
       " array([ 60,  41,  13, 110,  25,   7,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 19,   1, 351,  29,   0,   0,   0,   0,   0,   0]),\n",
       " array([  2,   1, 210,   2,   1, 349,   0,   0,   0,   0]),\n",
       " array([   2, 3154,  133,    2,  596,   40,  733,    0,    0,    0]),\n",
       " array([  40, 2881,    2, 3036,    2,  266,   40,    1,    0,    0]),\n",
       " array([  15,  205,    1,    3, 2611, 2675,    0,    0,    0,    0]),\n",
       " array([11, 21, 40,  1, 39, 10, 60,  0,  0,  0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([29, 55,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([1814,   16,   21,  383,  910,   29,   55,   29,   55,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  87,   33,    2,    1, 1490,   18,    1,    0,    0,    0]),\n",
       " array([ 103,   12,    2, 1631,   48,    2,  407,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([56, 29, 55,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2, 1306,    1,   39,   60,   95, 2004,    0,    0,    0]),\n",
       " array([  29,  231,    2, 1490,  351,    0,    0,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  31, 117,   7,   0,   0,   0,   0,   0,   0]),\n",
       " array([  39,  585, 3820,    9,    1,   29,    7,   24,  234,    0]),\n",
       " array([601, 850, 585, 125,   2,   1, 351,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([3258,  244,  301,   17,    0,    0,    0,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([887,  16,  21,  46, 328,   0,   0,   0,   0,   0]),\n",
       " array([  19,  120,  392, 1490,   59,    1,    0,    0,    0,    0]),\n",
       " array([  13, 1920,   84,   20,    1,    3,  141, 2481,    0,    0]),\n",
       " array([ 139,   12,   17,    8,    1,  208, 1017,   23,    0,    0]),\n",
       " array([  10,    5, 1218,    2,  580, 1978,   57,   89,    0,    0]),\n",
       " array([ 53,   7,  42, 189,  81,   3, 741,  17,  12,   0]),\n",
       " array([ 471,    5,   69,    2,    1,    3,    2, 2561,    0,    0]),\n",
       " array([   6,    2, 1329,  407,   22,   39,    7,   42,  532,    0]),\n",
       " array([  5, 415,  17, 473,   2, 531,   6,  19, 147,   0]),\n",
       " array([196,   4,   2, 675,   2, 133,   4,   2, 979,  48]),\n",
       " array([   3,  473,    2,    1,    3, 2343,    6,   94,    0,    0]),\n",
       " array([   2,    1,    1,    3,  882, 3604, 1736,    0,    0,    0]),\n",
       " array([  50,   16, 1218,   10, 1538,    1,    0,    0,    0,    0]),\n",
       " array([3891,   60,  189,    3,  171,   10,   34,   57,  240,    0]),\n",
       " array([   7,    8,   46,    1,  500,    2, 1490,  543,   16,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([137,  51,  56,  56,   0,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([171,  34,  57, 240, 142,   0,   0,   0,   0,   0]),\n",
       " array([ 98,  29,   5,  42, 959, 112,   4, 524,   0,   0]),\n",
       " array([ 82,   5, 115,  80,   8,   1, 111,  10,  34,   0]),\n",
       " array([  50,   16,   42,  300, 1218,    2,    1,    6,   34,    0]),\n",
       " array([  3, 168,  16,  22,   2,   1,  29,  71,   7, 817]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  17,   59,   88,  351,   61, 3845,    7,   21,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2, 1281,    6,  302,   41,   21,   46, 1490,    0,    0]),\n",
       " array([   3,    7,    2, 2628, 2636,   14,    1,    0,    0,    0]),\n",
       " array([  65, 2742,    3,   65, 1318, 3723,  389,    1,    0,    0]),\n",
       " array([2525,    2, 3279,   48,    2,  572,    7,   37,  281,    0]),\n",
       " array([  32, 2118, 1396,   53,    7, 1218,    0,    0,    0,    0]),\n",
       " array([ 22,  17,   1,  52, 194,  50,  66,   4,   7,   0]),\n",
       " array([  3,  32, 177,  50, 969,  29,  42,   7, 131,   0]),\n",
       " array([   7,    2,  169, 3320,    6,   21,    1,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,    2,  169, 3320,   90,    2,  169, 3320,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 14,  10, 145,  74,  48,   2,   1,   1,   1,   0]),\n",
       " array([   6,   21,  120,  790, 2115,   26, 3649,    1,    0,    0]),\n",
       " array([  26, 1921,   10,  129,  852,   11,  147,    4,  682,    0]),\n",
       " array([   1,   89,    4,  766,   99, 1331,    0,    0,    0,    0]),\n",
       " array([  22,   80,    7,  501,   19, 2879,    1,    3,    1,    0]),\n",
       " array([ 302,    3,   38, 3447,   41,   57,    2,  626,    6,  786]),\n",
       " array([  2,  74, 649,  86,  24,   1,   0,   0,   0,   0]),\n",
       " array([1454,  152,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([527, 327,   2, 390,   7,   1,   1,   0,   0,   0]),\n",
       " array([  10,    1,    2,  172,    1,    6,   19, 1440,    0,    0]),\n",
       " array([ 80, 969,   1,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 36,  24, 195,  19,  46, 218,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,   10,   31,  102,   46,  248,    4,   43,   31, 1124]),\n",
       " array([ 1,  1, 29, 58,  7, 24,  7,  1,  0,  0]),\n",
       " array([ 10,  84, 123, 212, 123, 373,   2,  74,   1,   7]),\n",
       " array([  2, 205, 308,   7, 450,  23,  10,   1,   4,   7]),\n",
       " array([  97,   23,   87,  281,    7, 3027, 1697,    7,    1,    0]),\n",
       " array([97,  1,  1,  7, 41, 32,  1, 32,  0,  0]),\n",
       " array([  64,   12,    2,    1,    6,  477,   81,    2, 2669,    0]),\n",
       " array([ 52,   1,  11,   2, 374,  19, 638,  12,   0,   0]),\n",
       " array([  4,  80,  27, 446, 202, 886,   1,  27,   0,   0]),\n",
       " array([  3, 699,  10, 466,  95,  17,   0,   0,   0,   0]),\n",
       " array([ 103, 1472, 2174,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([1472,   19,  391,    3,   19, 1722,   41,    0,    0,    0]),\n",
       " array([   9, 1013,  775, 2031,  103, 1703,  120,   10,    0,    0]),\n",
       " array([  53,   58, 1962,   20, 1175,   23,   10,    1,    0,    0]),\n",
       " array([  81,   19, 2414,    1,   15,    1,    6,  951,    0,    0]),\n",
       " array([   3,    1,  174,    1,   15, 2922,  829,  563,  599,  563]),\n",
       " array([  15,  282, 2358,    7,   42,  661,    9,  319,    0,    0]),\n",
       " array([  3, 185,  27, 152,  10,  59,  44,  19, 391,   0]),\n",
       " array([  27, 1138,   10,   59,   19, 2176,  327,    2,  390,    0]),\n",
       " array([  10,   11,  104, 1423, 2124,    6,    2,  445,    0,    0]),\n",
       " array([   7,  535,  170,    2,  152, 1520,  103,    0,    0,    0]),\n",
       " array([480,   2, 260, 273,   7,  11,   1,  53, 252,   0]),\n",
       " array([  58, 1817,   47,   74,  356,  327,   65, 2568,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  14, 1390,   57,   65,  161,    1, 1203,   60,   71,    0]),\n",
       " array([  2, 445,  12,  56,   1,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([829, 847,  60,  71,   0,   0,   0,   0,   0,   0]),\n",
       " array([1745,  458,   33,    2,  477,    3, 2604,    4,   93,    0]),\n",
       " array([ 327,  163,    5,    2, 1319, 1202,   84,    4,  981,    0]),\n",
       " array([103,   1,   3, 103,   1, 649,   1,   0,   0,   0]),\n",
       " array([  3, 102, 112,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,    1, 1069, 2617,  751,    0,    0,    0,    0,    0]),\n",
       " array([   3,    1,  110,   25,  190,   13,   11,   65, 2372,    0]),\n",
       " array([1717,   65,    1, 2562,   60,   71,  413,    0,    0,    0]),\n",
       " array([2402,  394,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  58,    2, 2347,  362,  934,   65,    1,    0,    0,    0]),\n",
       " array([  3,  72,  16, 364,   8, 465,  67,  80,   9,   1]),\n",
       " array([  15, 2853,    6,  104,    1, 1760,   25,  467,    0,    0]),\n",
       " array([  25,    5,  231,    1,    8, 3580,    0,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([181, 104,  41, 788,   1,   1,   0,   0,   0,   0]),\n",
       " array([  14,  171,    1,   60, 1071,    1,    0,    0,    0,    0]),\n",
       " array([  82,   41,   60, 1362, 2739,   22,    5,  369,    7,    0]),\n",
       " array([  29,  500,    2,  205, 2520,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 60,  41,   1, 829, 847,   0,   0,   0,   0,   0]),\n",
       " array([  60,  279,   60,   76,    1, 3388,  284,    1,    0,    0]),\n",
       " array([  10,    1,  963, 1146, 1098,   10, 1827,   86, 1126,    0]),\n",
       " array([  10, 1160,   59,  128,   14, 1945,   10,    2,  260,  530]),\n",
       " array([1390,   14,    2,  683,  153,  337,   15,  104,    1,    0]),\n",
       " array([  60,    1,   65,    1,   53,  145, 2481,    0,    0,    0]),\n",
       " array([   3,    9, 2612, 1687,   66,    9,  517,   74,    0,    0]),\n",
       " array([  4, 488,   2, 133,   6,   1,   0,   0,   0,   0]),\n",
       " array([   3,   80,  719,  264,  155,    1, 2852,   65, 2450,    0]),\n",
       " array([ 25,  60,  58, 829,  66,  47,   2,   1,  48,   2]),\n",
       " array([ 1, 65,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  29,   12, 1687,   66,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 831,  692,    4,  927,   65, 3913,    1,    0,    0,    0]),\n",
       " array([   6,   65,  161, 1247, 1221,    1,  293,    0,    0,    0]),\n",
       " array([232,   1,   3,   5,  93,   1,   0,   0,   0,   0]),\n",
       " array([  2,   1,  87,  24,  89,   1,   2, 445,   0,   0]),\n",
       " array([ 251,   28, 2330,   15,   16,   17,   31,   11,  118,    0]),\n",
       " array([766,  81, 264,   3, 769, 284, 865,   1,   0,   0]),\n",
       " array([14,  1,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 21,  12, 517,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 75, 410,   7, 287,   7,   1,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 972, 1187,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 62, 327,   2, 390,   0,   0,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  229,   12,   51,    2, 1099,   41,   11,  395,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  69, 991,  47, 818,  55,  36,  37, 590, 433]),\n",
       " array([  40, 3530,    1,   98,   40,  262,    1,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 225,   96,  139,   10,    7,   24, 2378,  448,   79,    0]),\n",
       " array([   2, 1099,   41,   11,  395,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([60, 24,  9,  1,  0,  0,  0,  0,  0,  0]),\n",
       " array([2067,  342,   10,   31,  239,    7,    4,  818,    0,    0]),\n",
       " array([   5,  565,   11,    1,   20, 2347,    0,    0,    0,    0]),\n",
       " array([  3,  76,   5, 144, 238,  22,  29,   5,  69,   0]),\n",
       " array([  5,  58, 456,  16, 337,  23,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   7,   24, 1030,  463,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 76, 630,   4, 630,   2, 187,  33,   2, 511,   3]),\n",
       " array([  81,    8, 1155, 1229, 2306,    4,   80,    0,    0,    0]),\n",
       " array([ 337,    8,  664,   15,   27,   23,   12,    9, 1792,    0]),\n",
       " array([  10,    5,   69,  450,    4, 2160,    0,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 55, 446, 225,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([765,  81, 323,   4, 104, 664,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  17,   12,   19, 1306,  839,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([51, 17, 12,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([   3,    5,   69, 2001, 1505,  778,   26,    0,    0,    0]),\n",
       " array([ 361,   98,   16,  240,   54,  537,   57, 2067,  246,    0]),\n",
       " array([  29,  129,   26, 2879, 4041,  112,    0,    0,    0,    0]),\n",
       " array([1505,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  32, 1187,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  67, 2376,   81,   74,    1,    3,  421,   15,    1,    0]),\n",
       " array([251, 188, 932,  21, 388,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([48,  1,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  19,  634,    4,    2, 1319,   97,    5,   93,    0,    0]),\n",
       " array([  40, 1807,  208,  765,   79,    0,    0,    0,    0,    0]),\n",
       " array([1505,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([152, 225,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([181,  72,  66, 427,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2, 1099,   24,  132, 1390,  105,  104, 3447,  770,    0]),\n",
       " array([   4,    1,   65,    1, 3262,    1,    0,    0,    0,    0]),\n",
       " array([  19, 1139, 1653,   56,  284,  160,  427,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 59, 195,  94,  28, 450,  25,  12,  21, 225,   0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,  320,   32, 1822,    0,    0,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  73,   36,   76, 2759,  692,   14,    2,  307,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([2143,    7,   20, 1446,    3,  186,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 181,   22,   20, 2860,    0,    0,    0,    0,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 145, 1022,   23,   31,   13, 1344,    4,    1,    2,  260]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,    2, 2354,  841,    0,    0,    0,    0,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  432,  664,    1,   27,   23,   12, 1168,    0,    0]),\n",
       " array([100, 450,   4,  18,  28, 794,   0,   0,   0,   0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([110,   9, 408,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,   15,   46, 1417,    1,    2, 1422,    0,    0,    0]),\n",
       " array([  53,   23,    1,   47,   57, 3516,   22,    5,   42,  789]),\n",
       " array([  20, 3601,  115, 2009,    4,   18, 1482,    0,    0,    0]),\n",
       " array([480, 323,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1569,   57,    2,   53,   23, 3244,    0,    0,    0,    0]),\n",
       " array([  11,  241,  702,  339,   56, 2403,  115,   13,    0,    0]),\n",
       " array([216,  18, 828, 123,  54,   1,  64,  33,   0,   0]),\n",
       " array([   9,  318, 1717,    2,   89,   14,   29,    1,    0,    0]),\n",
       " array([  37,   18,    2,    1,  591,  171,   23, 1533,    0,    0]),\n",
       " array([   4,    2, 2837,    6,    9,   94,    3, 2406, 2447,    0]),\n",
       " array([ 31,  55, 535, 112,   6, 225,  48,  39,  23,   0]),\n",
       " array([  92, 1395,    2,  388,    0,    0,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([872,  39, 389,  75,  56,   0,   0,   0,   0,   0]),\n",
       " array([1440,   10,   28,    1,   47,  225,   37,    0,    0,    0]),\n",
       " array([   6,   20,    1, 2928,  323,    0,    0,    0,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([49,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([630,  34, 323, 805,  41,   4, 225,   0,   0,   0]),\n",
       " array([171, 225,   1,  66,  13,   3,  34,  20, 742,   0]),\n",
       " array([  4, 225,  37,  18, 805, 171, 310,   0,   0,   0]),\n",
       " array([  11, 1401,   23, 1949,   13,    0,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([291, 224,   3, 125,   0,   0,   0,   0,   0,   0]),\n",
       " array([  61,    2, 1034,   12,  128,    3,   11,   29, 2415,    0]),\n",
       " array([ 54,  64,  20,   1,  23, 714,   0,   0,   0,   0]),\n",
       " array([ 81,  21, 432, 936,   0,   0,   0,   0,   0,   0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([291, 703,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  28,   19, 1440,   12,  342,    0,    0,    0,    0,    0]),\n",
       " array([  10,   60,    6,  302,   41,    1,   11,   40, 2742,    0]),\n",
       " array([  3,  93,  61,  36, 982,   0,   0,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 12,  17,  13, 429,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 29, 195,  24, 151, 314,  47,  11,  21, 329,   0]),\n",
       " array([ 10, 231,  18, 536,   4,   1, 968, 251, 302,   0]),\n",
       " array([ 92,   1,  96,  13, 956, 418, 220,   0,   0,   0]),\n",
       " array([228,   5, 311, 730, 104,  41,   2, 248,   5, 131]),\n",
       " array([  5,  24,   2, 985,  62, 609,  62,  17,  12,   0]),\n",
       " array([  60,   24, 2605,    9,  264,   22,   17,   12,   13,  604]),\n",
       " array([ 815,   14, 1699,   52, 2499,    2, 3136,   12,  169,    0]),\n",
       " array([   2,  307, 2628,    3,   17,   12,    1,    0,    0,    0]),\n",
       " array([323, 225,  19, 180, 592,   0,   0,   0,   0,   0]),\n",
       " array([ 103,   12,    6,  302,  637, 2168,   64,    6,    7,    0]),\n",
       " array([   3, 1505,  778,    9,  120,  794,  820,    0,    0,    0]),\n",
       " array([104, 403, 951,  47,  21,   1,   0,   0,   0,   0]),\n",
       " array([ 878,   96, 2779,  120, 2150,   96,   14,    7,    0,    0]),\n",
       " array([1834,    6,   17,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 40,   1,  11,   2, 657,   0,   0,   0,   0,   0]),\n",
       " array([ 36, 134,  82, 128, 469,  22, 302,  59, 501,   0]),\n",
       " array([  4, 351,  79,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 123,   95,    7,  131,   17, 1696,    0,    0,    0,    0]),\n",
       " array([  4, 273,  19, 169,   1,   1, 184,  73,   0,   0]),\n",
       " array([ 60, 888,  86, 315, 680,  53,   0,   0,   0,   0]),\n",
       " array([11,  2,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  17, 2108,    1,    4,  302,   33,    2,    1,    0,    0]),\n",
       " array([  36,   37,   18,    1,   11,   40, 2799,   53,   59,    0]),\n",
       " array([   4,  105,   11,  193, 2524,  251,  788,  302,    0,    0]),\n",
       " array([  87,   93,   36,   76, 3858,    0,    0,    0,    0,    0]),\n",
       " array([165, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([152, 342,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 105,   19, 1836, 1304,    7,    4,   19, 2473,    0,    0]),\n",
       " array([  72,   79,  525,    4, 1232, 1185,    0,    0,    0,    0]),\n",
       " array([  39,   60,  243,  174,  138, 1424,   14,    2, 1916,    0]),\n",
       " array([ 272,   19, 1095,   22,    5,  131,  585,  281,    0,    0]),\n",
       " array([   1,   13, 1358,   14,   79,    0,    0,    0,    0,    0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48, 469,  13,  10,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5, 106,  50,   1, 181,  54,   0,   0,   0,   0]),\n",
       " array([ 99,   1,   6,  65, 264,  41, 284, 702,   0,   0]),\n",
       " array([  3, 337,   1,   5, 168,  19, 805,   0,   0,   0]),\n",
       " array([  39,   36,    3, 1187,  225,  869,    4,  358,    0,    0]),\n",
       " array([ 96, 694, 700,  79,  36,  37, 195, 537,   0,   0]),\n",
       " array([184,  74, 115,  42,  32,  54,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([   2,  260, 2028,    7,    0,    0,    0,    0,    0,    0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   3,  273,   19,  805, 1110,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([269,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([165, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([269,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([269,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,  160,    7,  236, 1278,   52, 1820,  428,   11,    9]),\n",
       " array([  54, 3763, 1057,   39,    8,  122,   76,    8,  326,    5]),\n",
       " array([  87,    1, 2312,   11,   10, 1324,  767,   23,    0,    0]),\n",
       " array([904, 173,  64,  11,   2,   1,   6,  20, 401,  97]),\n",
       " array([ 23,  58, 315, 120,  77,  73,  82,  23,  59,  22]),\n",
       " array([  1,   3,   2, 337, 122,   6,   8, 971,  73,   0]),\n",
       " array([ 647,   15,    1,    1,   34, 2175,   20,  177,   73,    0]),\n",
       " array([  14,    9,  159,    6,  377, 2707,    9,  223,   87,   13]),\n",
       " array([1903,   27,   88,  380,   50,   38, 2018,    5,    1,    0]),\n",
       " array([ 61, 173,  58, 662, 110,   9, 557,  10,  17,  59]),\n",
       " array([  32,  216,   64,    1,    4,  829,   33,    2, 1264,   39]),\n",
       " array([   1,  128,   17,   13,  881,   59, 1293,    4,   72,   27]),\n",
       " array([ 997,   97,   23,   59,   84,    4,  281, 1569,    4,    9]),\n",
       " array([ 373,    5,  530,   27,   50,  791,   23, 3419,   20, 1320]),\n",
       " array([ 619,   15, 2131,    5,  117,   43,  236,    5,    1,   13]),\n",
       " array([ 54,  11, 367,  57,  89, 845,  23,  59,   9,   1]),\n",
       " array([  64,   44,   11,   89, 1351,   23,   92, 2597,  245,    9]),\n",
       " array([94,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  22,   92,   23, 1035,   11,    2,  388,  259,   61,   55]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 55,  20,  46, 556,  87,  24, 151,   8, 122,   5]),\n",
       " array([1104,   58,   24,  559,  713,  125,   16, 2325,    0,    0]),\n",
       " array([   1,   92,    5,    9, 2421,  600,  524,   11,    8,   77]),\n",
       " array([1721,    3,  255,  376,  267,   64,  249,    3,    8,   46]),\n",
       " array([ 225,    5,   92,  344,   92, 2191,  200, 1784,   14,   65]),\n",
       " array([ 659,   64,   74,    1, 3345,  112,    6,  936,    0,    0]),\n",
       " array([1373,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 259,    2,  121, 1140,   12,   49,    4,  938,    7,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 369,    7,  102,   16,  168,    4, 1915,  166,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([310,   7,  37,  13,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 653,    5,  125,  338,   19, 1369, 1469,    0,    0,    0]),\n",
       " array([  98,   27,  709,  342,  174,   33,    2, 1231,    0,    0]),\n",
       " array([  25,  486,   50,    9,  203,    2, 1099,    1,   27,    0]),\n",
       " array([ 653,    5,   98,   27, 2544,  141,    3,  185,  141,    0]),\n",
       " array([ 49,  47,   7,   1,   7,  76, 807,  11, 179,   0]),\n",
       " array([ 171,    7,   76,  561,   11,  302,   20,  442, 1321,    0]),\n",
       " array([ 15,  20,   1, 158,  55,   1, 284,  23, 714,   0]),\n",
       " array([ 84,   4,   9,   1, 304,   1,   4,   1,   0,   0]),\n",
       " array([  52,   34,   52,  569,   20, 2392,    0,    0,    0,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  20,  442, 1321,   48, 3047,   32,  147,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 146,    7,  582,   17,   54, 1042,    9,   94,    0,    0]),\n",
       " array([  64,    1,   20,    1,    2, 3201,    6,    1,    0,    0]),\n",
       " array([ 73,  63,  95,   1,   1, 776,  13,   1,   0,   0]),\n",
       " array([  64,    1, 3088,   73,   17, 1892,  284,  147,    0,    0]),\n",
       " array([  57,    1,  465,    1,  117, 1140,    0,    0,    0,    0]),\n",
       " array([ 36,  41, 741,   4, 286,  38, 290,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 570, 1041,    8,   45,   50, 1170,  342,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 420,  636,  342,  210, 1717,   20,  922,    0,    0,    0]),\n",
       " array([   3, 1335,   81,   20,  947,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  8, 891, 140,  46, 159,   4,   7,   0,   0,   0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([164, 259,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,   69,  991,    4,   98,   19, 3581,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  61,   42,    7,  140,    7,   41, 3013,    1,    0,    0]),\n",
       " array([ 29,  41,   7,   1,  62,   9, 957,   1,  11,  46]),\n",
       " array([393,  61, 435,  19, 234, 122,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,  385,   19, 3581,   56,   46,  259,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,   92,  344,   98,    2, 1105,    3,  125,    9, 1469]),\n",
       " array([ 155,   81,   20, 2916,    0,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 48,   8, 218,   2, 340, 122,  67,   1,   9,   0]),\n",
       " array([ 157,  798,  298,   48,    8, 1270,    5, 2369,   81,   27]),\n",
       " array([2501,  630,   88,  380,  463,  320,  110,    9,    0,    0]),\n",
       " array([   1, 1389,    5,  419,   27,  682,  316,    9,    1,    0]),\n",
       " array([   1,    3,   73,   23, 2007,   17,   23,   72,   17,   75]),\n",
       " array([156,   3, 316,  17, 156,   3, 724,   3, 724,  23]),\n",
       " array([194,   3, 156,   1,  17, 156,  52, 815,  20,   0]),\n",
       " array([406,   1,  27,  52,  61, 491,  23,  95,  28, 243]),\n",
       " array([1339,    3,  880,   17,   48,    5,  516,   17,   61,   23]),\n",
       " array([17,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  74,   47, 1424,  340,    1,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([310,   1,  96,   9, 152, 363,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  9,   1, 259,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 49, 362, 934,  19,   1,   5,  86,  24,   7, 461]),\n",
       " array([   2, 1119,    1,   15,   16,   21, 1856,    0,    0,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  32,   46,  259,    5,   31,   13,  112,    6, 3711,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  13,  112,    6, 3711,    0,    0,    0,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([63, 37, 63, 37,  0,  0,  0,  0,  0,  0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([310,  32,  33,  19, 601,  67,  13, 724,   2,   0]),\n",
       " array([3980,  184,    8,   45,  541,   50,    2,  664,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([583,   7,   1, 428, 120,   1,  49,   0,   0,   0]),\n",
       " array([  7,  86,  75, 938,   2,  46, 121,  10, 366,  11]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,   31,  456,   38, 2886,  681,    3,  938,   38,   15]),\n",
       " array([  8, 757,  22,   5, 142,  75, 770,   0,   0,   0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 90,   5, 160,   7,   0,   0,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  96,   13,    4,  404, 1072,  123,   10,    5,  768,   77]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  7,  58,  18, 356,   1,  82,  60,  71,  34,   0]),\n",
       " array([   2,    1,   63,    1,   11, 3954, 1324,   95,   22, 1308]),\n",
       " array([  1, 312,   6,   1,  49,   5,  58,  19,   1,   0]),\n",
       " array([  76, 2907,   25,   19, 1462,   10,    7,  258,  168,    0]),\n",
       " array([  1,  17,  14, 405,  49,   7,  37,  75,  15,  79]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 32,  46, 259, 265,  16, 310,   5,  31,  13, 284]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 11, 396,   1,  75,  15,  16,   3,  67, 117,   7]),\n",
       " array([1571,  229,    6,   19,  326,    0,    0,    0,    0,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48,  46, 259,  85, 115,  18, 255,  82,   0,   0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([2064,    5,   42,   13,  727,   15,    7,   85,  285,  229]),\n",
       " array([ 27, 347, 204,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([310, 259,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  11, 2193, 1118,  139,    5,  311,    9,  567,  106,   17]),\n",
       " array([ 141,   17,   12,    2, 1099,   24,   88, 1095,  284,  170]),\n",
       " array([241, 323,   2, 580,  12, 220,  15,  74, 268,   6]),\n",
       " array([  40,  820,  264,   19,   45,    3, 1505,  778,   41,  243]),\n",
       " array([ 174,  138,   65,  445, 1185,   60,  198,  469,    0,    0]),\n",
       " array([  1,   3,   4,  80,  17, 811, 664,  21,  12, 139]),\n",
       " array([ 47, 109, 173,   3,  28,   5, 160,  75,  15,  79]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 102,   16, 1174,   46,  259,    5,   31, 1065,    7,   11]),\n",
       " array([ 238, 1452,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 72,  38, 525, 121,  25,  63,  12,  44,  63,  31]),\n",
       " array([2423,   40,  216, 2357,    0,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  11, 1270,    5,  131,   63,   58, 1085,    7,   56,   55]),\n",
       " array([ 49,  46, 164, 121, 588, 837, 412,  30,   0,   0]),\n",
       " array([   1,  112,   48, 1240,    3,   75,  703,   15,   79,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 32,  57,   9, 218, 259, 310,   5,  86,  13,   5]),\n",
       " array([   7,  132, 2357,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 56,  55, 269,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1325,  194,  229,    9, 2060,   60,   24,  670,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  8, 476,   4, 429,  32,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 96, 163,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([3245,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 71, 320,  40, 580, 670,   2, 592,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  60,  354,   11, 1266,   22,   24,   13,  707,   25,   82]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 28,   2,  46, 476,  12, 109,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 67, 784,  27,   6,   7,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  32,   67,  123, 1903,  123,  102,   27, 1164,    7,   27]),\n",
       " array([  14,  630,    9,  954,  379, 3351,    2,  907,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 61, 348, 219, 354, 104,   1,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 332,   21, 1786,    3,  630,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  55,   37,   36,  125,   65,    1,    3,   60, 1063,    0]),\n",
       " array([  44, 2365,    5,  588,   80,   79, 1112,   11,  648,    0]),\n",
       " array([  10,   36,   15, 4064, 1105,   78,  774,   50,  224,    0]),\n",
       " array([  4, 309,  40,   1, 208,  49, 966,  30,   1,   0]),\n",
       " array([   1,  342,   12,   23,  332,   19, 1098,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  32,  123,    9,   94,   10, 1818,    7,  376,   64,   23]),\n",
       " array([ 304, 1956,   64,    9,  234,    0,    0,    0,    0,    0]),\n",
       " array([ 645,   40, 1577,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  41,    1,  284,   40,  647,   56,  488,   40, 1098,    0]),\n",
       " array([ 344,   64,   60,   37, 1927,   79,  111,   40,  672,    0]),\n",
       " array([  53,   82,  540, 1517,   36,   24,   22,    1,   15, 2922]),\n",
       " array([1745,  627,    6,  680,    0,    0,    0,    0,    0,    0]),\n",
       " array([645,   7, 348, 219,   0,   0,   0,   0,   0,   0]),\n",
       " array([  85,   12,  342, 1366,   29,  648,   23,  308,    0,    0]),\n",
       " array([1854,   19,    1, 1095,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([48, 60, 41, 57, 17,  0,  0,  0,  0,  0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  65,  946,   18,   40, 2158,    1,  687,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 60, 179,  79,  13,  22, 713, 284,  65, 445,   0]),\n",
       " array([ 44, 239,  19,   1, 138,  19, 454,   3, 421,   0]),\n",
       " array([  15,  454,   54, 1357,   64,    1, 2229,    0,    0,    0]),\n",
       " array([ 646, 1505,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  60,   42, 2424,   79,  132, 1488,   40,  526,    0,    0]),\n",
       " array([  53,  308,   16, 2267,   15, 1406,   49,   47,    8, 1084]),\n",
       " array([  23,   10,    1,   67,  105,   27,   14,    9, 1611,    0]),\n",
       " array([   3,   23,   37,  808,  109, 2192,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  34,    2,    1,    6,    2, 2282,  399,   47,    7,    0]),\n",
       " array([   7,    1,    6,  302,    7, 2674,    1,    3,    1,    0]),\n",
       " array([   1,    7,  613,   10,    7,   78,   18, 3255,    0,    0]),\n",
       " array([ 673,   64,  483,    3,   74, 2668,  356,    0,    0,    0]),\n",
       " array([ 170,    2,  704,    9, 1786,    7,  553,    6,    1,    0]),\n",
       " array([  10,  203,    2, 2296,    6,  153,   61,   24,    7,  682]),\n",
       " array([  50, 1760,   10,    1,   58,  636,    1,    3,  420,    0]),\n",
       " array([  34, 1450,  932, 2476, 1429,    3, 1570,  668,    0,    0]),\n",
       " array([  15, 1461,    3,    1,  179, 1672,    3,  552,  287,    0]),\n",
       " array([  52,   33,    2, 1981,    6,  182,   67,  168,    2,  740]),\n",
       " array([  3,  80,   8, 664,  47,   7, 155, 817,  49,  47]),\n",
       " array([  39,  585,  190,  674,   56,  636,   66,    4,   65, 1327]),\n",
       " array([  25,   60,   79,    4,   40, 3963,    1,    0,    0,    0]),\n",
       " array([  28,   44,    2,  672,   41, 2130,   44,  345,   46,    1]),\n",
       " array([  96,   14,    2, 1377,  382,    1,   66,    0,    0,    0]),\n",
       " array([ 13,  14,   2,   1, 543,  16,   3,  42,   2,  84]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 1, 13,  5,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([165, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([123,   5,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  98,   60,   24, 1517,   27,   11,    0,    0,    0,    0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([   4,    2, 3475,    5,  516,   27,    0,    0,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 29,  12, 662,   6, 225,   0,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([529,  51,   1,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([3089,    2,    1,   57,    2,  157, 2396,    0,    0,    0]),\n",
       " array([ 15,  66,  23,   1, 103,  81,   2, 909,   0,   0]),\n",
       " array([  1,   4,  65, 672,  23,  12, 245, 525,   0,   0]),\n",
       " array([  4, 351,  34,   2, 445,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48, 152, 383,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 103,    1,    1,   20, 2566,  465,    0,    0,    0,    0]),\n",
       " array([   3,   73,   17, 3800,  528,  111,   26,  129,  440,  225]),\n",
       " array([   9,    1,    1,   25, 1595,   25,   26,  129,    0,    0]),\n",
       " array([  76,   13,   28,  683,    9, 2156,   26,  748,    9,  733]),\n",
       " array([ 196,    4,    1,  456,   13, 2411,    3, 3333,    0,    0]),\n",
       " array([ 337,   11, 2093,   22,   15,   30, 3076,  434,    3,    0]),\n",
       " array([   2,    1,    1,    6,   30, 2548,    0,    0,    0,    0]),\n",
       " array([ 26,   1, 249, 658, 978,  25,  39,   2, 187,   0]),\n",
       " array([  76,    1,    3,   95, 1618,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([155,  51,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  1, 225,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 291,  729,   27,  219,   52,   80, 1016, 1721,    0,    0]),\n",
       " array([ 89, 820,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  21,   31,    5, 1132,    4,  302,    0,    0,    0,    0]),\n",
       " array([165, 820,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 3,  5, 21,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([355, 820,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   9,    1,  885,    5,  678,   21,   14, 1280,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  98,   62,  104,    1,   10,   42, 1430,   65,  534,    0]),\n",
       " array([  57,    9, 3151,    1,    1, 3039,    1,    0,    0,    0]),\n",
       " array([ 1,  6,  9,  1,  1, 10,  1, 58,  0,  0]),\n",
       " array([1837,   15,  215,   10, 2236,   66,  104,  873, 1760,    0]),\n",
       " array([ 251,   82,    2,  421,   18,  163, 1936,  111,  174,   15]),\n",
       " array([  3, 645,  29, 946,   2, 580, 308,   4,  27,   0]),\n",
       " array([ 85,  12,   2,  94,   6,   8, 553, 391, 342,   0]),\n",
       " array([2336,   40, 1911,   55,  794, 1505,  105,    0,    0,    0]),\n",
       " array([   1, 2980,    4,   80,   46,    2,  445,    0,    0,    0]),\n",
       " array([705,   5,  15, 215,  10,  24,   2, 539,  31, 507]),\n",
       " array([  4, 309, 323,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([446,  51,  26,   1,   0,   0,   0,   0,   0,   0]),\n",
       " array([  30, 2184,   70,  151,  100, 1413,   14,    0,    0,    0]),\n",
       " array([  9, 165, 690,   6, 421,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  51, 1531,   16,   13,    0,    0,    0,    0,    0,    0]),\n",
       " array([   8,  648,   70,   82,   13, 3907,   16, 1085,    7,   56]),\n",
       " array([   2,  147,    5, 1239,   12,  344,    1,    0,    0,    0]),\n",
       " array([ 64, 744,   4,  16,   4, 342, 141,   0,   0,   0]),\n",
       " array([  5,  31, 787,   3, 421,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  44,    2,  149, 3651,  382,    0,    0,    0,    0,    0]),\n",
       " array([406, 594,  11,  77,  15,  43,   3,  38, 169,   1]),\n",
       " array([   1,   30,    1, 1105,  719,  235,    0,    0,    0,    0]),\n",
       " array([2598,   18,   30, 1021,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 30, 328,  32, 376,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 64, 215,  63,   1,   1,  28, 269,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  26, 3874,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  75,  457,   30, 2069,   11,    2, 1788,    0,    0,    0]),\n",
       " array([ 185,  770,   34,    2, 2344,   48,    2,  907,    0,    0]),\n",
       " array([ 97,  60,  37,  93,  40, 319, 146,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 870,    7,    8,  208,   56, 1030,    0,    0,    0,    0]),\n",
       " array([ 36,  41,  49, 219,   0,   0,   0,   0,   0,   0]),\n",
       " array([  84, 1911,  642, 1122,   11,   40,  528,    0,    0,    0]),\n",
       " array([ 123, 2739,   11, 1915,  424,   16, 1630,    0,    0,    0]),\n",
       " array([  36,   37,   18, 1712,  156, 1049,   36,   24, 1053,    0]),\n",
       " array([ 33,   1,   3,   1,   1,  36,  24, 311,   0,   0]),\n",
       " array([   2, 2763,    6,   40,  208,  563,  820,  260,    0,    0]),\n",
       " array([951,  65,   1,  25,  36, 456,  40, 161,   0,   0]),\n",
       " array([  10,  140,   40, 1656,   15, 3379,    0,    0,    0,    0]),\n",
       " array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([  78,  102,    7, 2856,    1,    0,    0,    0,    0,    0]),\n",
       " array([ 30, 229,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  595,    6, 1185,   24, 3598,    0,    0,    0,    0]),\n",
       " array([  3, 671,   4, 778,   3,   4, 225, 786,   0,   0]),\n",
       " array([   5,  419,   40, 1155,    4,   65, 3963,    1,    0,    0]),\n",
       " array([  3,  55,   5, 285, 146,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 171,   26, 2100,  396,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 653,   26, 2100,   13,   56,    0,    0,    0,    0,    0]),\n",
       " array([ 61, 244, 644, 228,   0,   0,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([814,  88, 380,   8,  45,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  96,   13,    9, 1786,    1,   36,  311,   65, 1577,    0]),\n",
       " array([  61, 2432,   26,   11,    9, 1786, 2436,   88,  380,    0]),\n",
       " array([  3, 272,  30, 229,  28, 521,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([4048,    6,    2, 1099,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 828,   16,   11, 2006,   10,    5,   59, 1695,    4, 3893]),\n",
       " array([ 403,   52,  956, 3552,  301,  252,   92,    5,   51,    0]),\n",
       " array([630,  88, 380, 228, 536,   8, 556,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1202, 1325,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 10, 435, 787,  25,  23,  76,   1,  48, 260,   0]),\n",
       " array([  23,  320,    2, 2544,    6,  225,    3,    5,   24,    0]),\n",
       " array([  1, 483,  27, 141,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  459,  546,   13, 1506,   50,    9,    1,    0,    0]),\n",
       " array([ 54,  64,   5,  93,   2, 457,   6, 225, 266,   0]),\n",
       " array([  50,  282, 3008,   94,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 49,   5, 100, 521,   0,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([137,  39,   7,  49,  13,  11,   2, 147,   6, 800]),\n",
       " array([ 22,   1,  11,  19, 161,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48,  72,  16,   1, 563,   0,   0,   0,   0,   0]),\n",
       " array([  11,  395,   25,  457,   25,   73,    5, 1045,   11,  133]),\n",
       " array([  25,  685,   25,   73,   40, 2624,  159,   59,  163,    0]),\n",
       " array([3, 1, 1, 4, 1, 0, 0, 0, 0, 0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1234,    6, 2248,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  61,   12,   17,   15, 1505,  778,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 25,  15,   9,  94,   1, 301,   1,   0,   0,   0]),\n",
       " array([   1,   99,    4,  101,    3,   99,    4, 1465,    0,    0]),\n",
       " array([   1,   27,   52,    1, 2260,    2,  205,    0,    0,    0]),\n",
       " array([2391, 1185,   11,    2,  148,    6,  302,    0,    0,    0]),\n",
       " array([196,  84,   9,   1,   1,  11,   2,   1,   0,   0]),\n",
       " array([   4,   72,   27, 2104,   57,   31,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 97,  12,  10, 819,   0,   0,   0,   0,   0,   0]),\n",
       " array([  53,  448,   16,   60,   92,  636,    7,    4,   19, 3963]),\n",
       " array([ 97,  12,  23, 185,  27, 338,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 72,  27, 525,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,   95, 1961,    2,  396,   22,   14,   40,  495,    0]),\n",
       " array([   2,  572,    1, 1294,  692,   14,   66,    0,    0,    0]),\n",
       " array([   2, 3533,  439, 4080,    2, 3783,   25,   60,   95, 3792]),\n",
       " array([  50, 3448,  637,   64,   60,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  22,   61, 2330,    7,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 31,   2, 118, 624,   4, 117,   5,  42,  13, 131]),\n",
       " array([ 97,  12,   2, 592,  41,   7, 217,  48,   2, 657]),\n",
       " array([  39,   13,   90, 1590,    7,  184,    7,   41,   28,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,   24,   57,    1, 1030,    3,   95,    0,    0,    0]),\n",
       " array([1915,    4,  766,   40,  502,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 61, 366,  65, 786,  93,   7,  47,  53, 649,   0]),\n",
       " array([ 60,  24,   1,  65, 153,   6, 599,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  25,    5, 1026,  225,    0,    0,    0,    0,    0,    0]),\n",
       " array([  65, 2473,    5,    2,    1,   41,    2, 3849,    0,    0]),\n",
       " array([  6,  65, 262, 599, 613,  66, 342,   0,   0,   0]),\n",
       " array([ 65, 157, 133,   6, 275,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  42, 369,   7,   0,   0,   0,   0,   0,   0]),\n",
       " array([  33,   34,    2, 2472,  767,   36,   24, 1030,    0,    0]),\n",
       " array([  33,    2,  147,   36,   24,  913,  463,   33,    2, 1733]),\n",
       " array([  36,   24,  128,    4, 1572,  208,   10,    7,    1,    0]),\n",
       " array([ 243,   16,  170,  342,    3,   20, 3849,    0,    0,    0]),\n",
       " array([   3,   10,    7,   13, 1582,    2,  432,   22,    0,    0]),\n",
       " array([   1,    2,  584,   15, 1105, 3251,    3,    1,    0,    0]),\n",
       " array([ 36, 345,  21, 157, 380,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([171,   5, 231, 456,   0,   0,   0,   0,   0,   0]),\n",
       " array([  7,  76,   1,   4,   9, 276,   1,   0,   0,   0]),\n",
       " array([  3,   1,   1,   4,   7,  82, 617,   5, 134,   0]),\n",
       " array([ 763,   19, 3228,  105,   19, 1247,    6,  215,    0,    0]),\n",
       " array([  10,  262,  115, 1197,   19,  936,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([215,  41,  60,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  10,  120,   41, 2047,   39,  144,  110,   18,   62,    0]),\n",
       " array([  25,   17,   76,  565,    4,    1,   77,   21, 3507,    0]),\n",
       " array([767,   7,  98,  16,   1,  39, 144, 179,   0,   0]),\n",
       " array([1956,   20,  557,   64,   88,   67,  556,    0,    0,    0]),\n",
       " array([ 39, 144, 131, 646, 101,   1, 720, 126,   0,   0]),\n",
       " array([   3,   10,   20,  998, 2734,   64,  245,    0,    0,    0]),\n",
       " array([  72,   27,  525,   52,   28,  193,   28, 3549,    0,    0]),\n",
       " array([3281,  141,    4, 1820,   20, 1579,    0,    0,    0,    0]),\n",
       " array([  3, 427, 225,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48,  16, 525,  80,   7,   9, 465,   6,  16,   0]),\n",
       " array([  39,  104,  883,   18,   13, 1535,   53,    6,    7,    0]),\n",
       " array([  22,   12,  956, 1099,  255,    6,    7,   22,   12,    0]),\n",
       " array([1725,    4,  203,  170,    2,  169,  342,    0,    0,    0]),\n",
       " array([   9, 2293,   25,  924,   25,   20,    9,  962, 1665,    0]),\n",
       " array([171, 527,   4,  34,  86,   5,   1,   0,   0,   0]),\n",
       " array([ 50,  34,   2, 257,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 37, 203,   2, 388,  11,  99, 205, 421,   0,   0]),\n",
       " array([  25,  296,   31,   18, 3510,  303,    7,    4,  774,    0]),\n",
       " array([  3, 956,  37, 857, 633, 112,   8, 607,   0,   0]),\n",
       " array([  53,  153,   41,  262, 2386,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 774,   47,    8, 1084,    0,    0,    0,    0,    0,    0]),\n",
       " array([80, 46, 21,  1,  3,  7, 37,  0,  0,  0]),\n",
       " array([3715,   11,   34,   15,   79,    0,    0,    0,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 28,  72,   2,   1,  18,   1, 273,  19,   1,   0]),\n",
       " array([ 25,   5,  24, 243,  66, 174,  39,   5,  42, 415]),\n",
       " array([ 215,    1,    4,   40, 1197,    2,  257,   31,  624,    0]),\n",
       " array([  14,    9,  912, 2391,   39,   36,  569,    2,  657,    0]),\n",
       " array([ 36, 142, 273,   2, 907,   0,   0,   0,   0,   0]),\n",
       " array([1955,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([179,  13,  40, 497,  51,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 224,    3, 1517,   19,  672, 3932,    0,    0,    0,    0]),\n",
       " array([  40,    1,   49,    4,    2,  820,    1, 1708,   79,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 67, 421,  15, 255,  22,  43,  14,   5,  42, 391]),\n",
       " array([637,  64,   9,   1,   0,   0,   0,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,  391, 1721,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  13,    1,    1,    9, 3395,    5,    1,    0,    0,    0]),\n",
       " array([  54,   64,   30, 1569,    3, 1311,    1,   30,  581,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 72,   2,  89,   1, 200,   2, 800, 819,   0,   0]),\n",
       " array([   3,    2,  260, 1089,   27,  316,    0,    0,    0,    0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 39,   5, 508, 225,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,   16,   84,    9, 2397,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 332,  104,  403,  534, 2067,    0,    0,    0,    0,    0]),\n",
       " array([ 525,    5, 1030,   11,   19, 1185, 1098,    0,    0,    0]),\n",
       " array([   3,  128,   29,  648,    5, 1293,   96,   13,    8,  147]),\n",
       " array([ 767,   26, 1283,   16,    1,   14,   30,  625,    0,    0]),\n",
       " array([  1, 111,  30, 264,   4,   2,   1,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([747,  26,   2,   1,   0,   0,   0,   0,   0,   0]),\n",
       " array([  10,   59,    2, 1731,    6,   19,    1,    1,    0,    0]),\n",
       " array([  26, 1349,   13, 1906,   16,   62,    0,    0,    0,    0]),\n",
       " array([   1,    3,   13,  794,    7,   24, 3393,   16,    0,    0]),\n",
       " array([  11,   19, 2437,    1,    0,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 39,   5,  87, 117,  43, 613,  21,  30, 418, 648]),\n",
       " array([  1,  13, 424,  30, 780,  22,  67, 556,  17,   0]),\n",
       " array([  97, 1281,   37,    1,  297,   15, 1628,    0,    0,    0]),\n",
       " array([  97,  169, 1780,   37,  765,    3,    1,    0,    0,    0]),\n",
       " array([   5,    2,  384,    1,   97,  891,   37,   18, 3664,    0]),\n",
       " array([   3, 2405,    1,  125,   54,   97,    2,    0,    0,    0]),\n",
       " array([1238,  692,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  10,   15,    2,    1, 2960,  391,  249,  805,    0,    0]),\n",
       " array([ 37,  71, 170,  65, 454,  36, 385,   2, 260,   0]),\n",
       " array([ 40, 302,  70, 110,   9, 733,   0,   0,   0,   0]),\n",
       " array([  82, 1591,   26,    4,    9,    1,    6,   21,  895,    0]),\n",
       " array([ 547, 2688, 3128,  138,    0,    0,    0,    0,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48, 580,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  62,   12,    2, 2881,   36,    2,    1,    0,    0,    0]),\n",
       " array([ 728,   26, 1491,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([160,  44,  32,  54,   8, 223,   0,   0,   0,   0]),\n",
       " array([103, 320,   9,   1,   4,   1,  38, 147,   0,   0]),\n",
       " array([  73,   63,  435, 1531,   16, 2680,   16,    5,   24,  163]),\n",
       " array([ 25,   7,  24, 163, 304,  29,   5, 115,   1,   0]),\n",
       " array([ 25,   7,  24, 151, 304,  14,   8, 659,   0,   0]),\n",
       " array([ 23,  10, 320,  22,   1,  20,  46,  31,   0,   0]),\n",
       " array([ 70,   1, 109, 968,   0,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 7, 37, 13, 18,  0,  0,  0,  0,  0,  0]),\n",
       " array([  2, 392,   6,  19,   1, 302,  86,  93,   0,   0]),\n",
       " array([   2, 3292,    6,   38,  161,  574,    9,    1,    0,    0]),\n",
       " array([637,  64,   9,   1,  32, 376,  64,   9,   1,   0]),\n",
       " array([   4,  955,   19,    1,    3,    4, 1107,   10,    0,    0]),\n",
       " array([  53,    4,    2,    1,    3, 2072,    6, 2332,    1,    0]),\n",
       " array([  58,  540,   22, 2354,  167,    5,  369,    7,    0,    0]),\n",
       " array([  11, 1347,    6,   29,    7,   41,   13,    4, 1913,    0]),\n",
       " array([  29,    7,   24,    1,   40, 1095,  125,   16,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  24,  99, 721,  81,  16,   3,  60,   1,   0]),\n",
       " array([   4,  125,  680, 3436,    0,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([87, 60, 13,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  56,  258,   60,    1, 1028,    1,    0,    0,    0,    0]),\n",
       " array([   3, 1011,  680,   15,  101,    6,   34,    2, 1553,    0]),\n",
       " array([1203,   36,   24,  908,   46,    3,   46, 2095,    6,   34]),\n",
       " array([   2, 1879,   11,   21,  657, 3867,    3,  445,    0,    0]),\n",
       " array([  36, 3434,    7,    2,    1,    4,   18,  908,  284,    0]),\n",
       " array([138,   2, 572,   1,  57,   0,   0,   0,   0,   0]),\n",
       " array([  19,  337, 1247,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5, 385,   7, 580,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 22, 142,  80,   8, 133, 781,   4, 105,   0,   0]),\n",
       " array([   9, 3794,    4,  858,    8,  465,    5,   42, 1919,   17]),\n",
       " array([  3, 190,  81,   8, 572, 268,  15, 215,   0,   0]),\n",
       " array([  10,   24, 1491,    2,  926,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  78,  104,  695, 1681,   53,    7, 2599,    0,    0,    0]),\n",
       " array([ 134,  457,   54,   73, 1577,    3, 1208,   37,    0,    0]),\n",
       " array([   5,    2,  657,  345, 3094,   72,    1,    3,    1,   18]),\n",
       " array([128,  34,   6,   1,   1,   0,   0,   0,   0,   0]),\n",
       " array([  73, 1055, 1560,  752,   25,    2,    1, 2896,    0,    0]),\n",
       " array([ 72,  27,  18, 128,   9,   1,  14,   2, 664,   0]),\n",
       " array([  32,   54,    5,   71,   14,   10,    5,   24,   13, 2055]),\n",
       " array([   8, 1297,   10,    1,   52,    1,   99,    1, 1044,    0]),\n",
       " array([ 53, 402, 887, 485, 193, 252,  24, 163,   0,   0]),\n",
       " array([   7, 4084,   16,  284,    0,    0,    0,    0,    0,    0]),\n",
       " array([11,  1,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 25,  39,   5, 712,   8, 234,  87,  18,   1,   0]),\n",
       " array([  11, 2332,    1,   15,  366,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 100, 2354,   41,    7,    0,    0,    0,    0,    0,    0]),\n",
       " array([  54, 1182,    4,   19,   46,  556,   64,    1,    0,    0]),\n",
       " array([  4,  79,  10, 102,   7, 879,  33,  19, 601,   0]),\n",
       " array([  39, 1028,  428,    7,   18, 3057,   56,  239,    7,    0]),\n",
       " array([  84,   74,   10,  433,   20, 1655,  806,   11,    1,    0]),\n",
       " array([  55,  518, 2575,   15,    7,  167,   18,   17,  604,    0]),\n",
       " array([  25,    4,   79,    4,   34,    2,  187,   10, 1187,  225]),\n",
       " array([2243,   21,  664, 2176,   11, 3319,    6,    2,   53,    0]),\n",
       " array([   8,  152, 2881,  604,    4,    2,    1,    5,  102,   27]),\n",
       " array([  15,   34,   20, 3962,    1,    3,   50,   21,  118,    0]),\n",
       " array([  14,   29,   23,   95,  138, 1185,  185,   27,    0,    0]),\n",
       " array([  15,   34,    2,    1,    3, 2440,    6,    2, 3620,    0]),\n",
       " array([1187,  225,  150,  203,    0,    0,    0,    0,    0,    0]),\n",
       " array([   2,    1, 1784,  195,    0,    0,    0,    0,    0,    0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([1187,  225,  150,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([150,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  31,  75, 974,   0,   0,   0,   0,   0,   0]),\n",
       " array([   3,   73,    8,  246,   12,  149,    7,   37, 1295,    0]),\n",
       " array([ 815,    5, 1487,   52,   32,    1,    5,  385,    7,    0]),\n",
       " array([   5,  331,    4, 4030,   19, 2881,    3,   57,   34,  492]),\n",
       " array([ 4,  1, 19, 46,  1,  0,  0,  0,  0,  0]),\n",
       " array([  4,   2,   1,   6,   8, 264,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  28,    4,   40, 1011,    0,    0,    0,    0,    0,    0]),\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# シーケンスの所得\n",
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n",
      "[138  36 982 144 673 125  16 106   0   0] => ['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', '']\n",
      "[34  0  0  0  0  0  0  0  0  0] => ['all', '', '', '', '', '', '', '', '', '']\n",
      "[106 106   0   0   0   0   0   0   0   0] => ['speak', 'speak', '', '', '', '', '', '', '', '']\n",
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "# 先端の確認\n",
    "for seq in sequences[:5]:\n",
    "    print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32777/32777 [00:06<00:00, 4767.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65379 65379 65379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 例\n",
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences, \n",
    "    window_size=2, \n",
    "    num_ns=4, \n",
    "    vocab_size=vocab_size, \n",
    "    seed=SEED)\n",
    "print(len(targets), len(contexts), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (((1024,), (1024, 5, 1)), (1024, 5)), types: ((tf.int32, tf.int64), tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# バッチ処理\n",
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: (((1024,), (1024, 5, 1)), (1024, 5)), types: ((tf.int32, tf.int64), tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# パフォーマンス向上\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラス化\n",
    "class Word2Vec(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.target_embedding = Embedding(vocab_size, \n",
    "                                      embedding_dim,\n",
    "                                      input_length=1,\n",
    "                                      name=\"w2v_embedding\", )\n",
    "        self.context_embedding = Embedding(vocab_size, \n",
    "                                       embedding_dim, \n",
    "                                       input_length=num_ns+1)\n",
    "        self.dots = Dot(axes=(3,2))\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "    def call(self, pair):\n",
    "        target, context = pair\n",
    "        we = self.target_embedding(target)\n",
    "        ce = self.context_embedding(context)\n",
    "        dots = self.dots([ce, we])\n",
    "        return self.flatten(dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の定義\n",
    "def custom_loss(x_logit, y_true):\n",
    "      return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 次元を１２８で走らせる\n",
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テンソルボード\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 1.6089 - accuracy: 0.2178\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.5919 - accuracy: 0.5911\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 1.5520 - accuracy: 0.6257\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.4747 - accuracy: 0.5788\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3769 - accuracy: 0.5765\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.2781 - accuracy: 0.6013\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1854 - accuracy: 0.6346\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.6707\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0194 - accuracy: 0.7035\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9452 - accuracy: 0.7361\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8764 - accuracy: 0.7659\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.8129 - accuracy: 0.7882\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7544 - accuracy: 0.8087\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.7009 - accuracy: 0.8266\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6519 - accuracy: 0.8416\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6073 - accuracy: 0.8549\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5666 - accuracy: 0.8673\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.5297 - accuracy: 0.8784\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.8883\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.4657 - accuracy: 0.8969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8f444eea00>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01368915, -0.01801699,  0.03389758, ..., -0.03584242,\n",
       "         0.03389646,  0.01040773],\n",
       "       [-0.1935789 ,  0.410412  , -0.41717118, ...,  0.0372398 ,\n",
       "        -0.03833184,  0.30931368],\n",
       "       [ 0.41742244, -0.2997097 , -0.20361443, ..., -0.15645918,\n",
       "         0.09588087, -0.4861499 ],\n",
       "       ...,\n",
       "       [-0.27210826, -0.30441785,  0.23364413, ..., -0.10338795,\n",
       "         0.01710282,  0.2932919 ],\n",
       "       [-0.04012244,  0.19175145, -0.21630152, ...,  0.1705216 ,\n",
       "         0.22705941,  0.22005133],\n",
       "       [ 0.02381506,  0.2593542 ,  0.14380749, ...,  0.17659187,\n",
       "         0.2668946 , -0.20168738]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重みの所得と語彙の提供\n",
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'vectors.tsv', 'metadata.tsv'をDLして分析\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('vectors.tsv')\n",
    "    files.download('metadata.tsv')\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】Iris（2値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:100]\n",
    "y = iris.target\n",
    "\n",
    "y_reduce = y[:100]\n",
    "y_reduce=  y_reduce.reshape(-1,1) == np.arange(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_reduce, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 96ms/step - loss: 0.6868 - accuracy: 0.6636 - val_loss: 0.5344 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5362 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.3916 - accuracy: 1.0000 - val_loss: 0.2138 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2391 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1112 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.0171e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 9.6210e-04 - accuracy: 1.0000 - val_loss: 3.6744e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 8.9662e-04 - accuracy: 1.0000 - val_loss: 3.1865e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.1723e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 3.3832e-04 - accuracy: 1.0000 - val_loss: 8.4175e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.7629e-04 - accuracy: 1.0000 - val_loss: 5.0505e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.3919e-04 - accuracy: 1.0000 - val_loss: 2.9302e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 7.7780e-05 - accuracy: 1.0000 - val_loss: 3.0602e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 9.4541e-05 - accuracy: 1.0000 - val_loss: 2.2306e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2306e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# モデル生成\n",
    "def generate_model(X):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=X_train.shape[1:]))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "model = generate_model(X_train)\n",
    "\n",
    "\n",
    "# コンパイル\n",
    "def generate_compile(model):\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                 optimizer=\"RMSprop\", \n",
    "                 metrics = ['accuracy'])\n",
    "    return model\n",
    "    \n",
    "model = generate_compile(model)\n",
    "\n",
    "# 学習とpredto評価を丸める\n",
    "def learning_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train,\n",
    "         batch_size=10,\n",
    "         epochs=20,\n",
    "         validation_data=(X_test, y_test),\n",
    "         verbose=1)\n",
    "    pred = model.predict(X_test)\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    return pred, scores\n",
    "\n",
    "pred, scores = learning_evaluate(model, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 4.1418089e-12]\n",
      " [1.0000000e+00 1.0797720e-11]\n",
      " [6.6402682e-11 1.0000000e+00]\n",
      " [6.6707315e-08 9.9999988e-01]\n",
      " [7.3346176e-11 1.0000000e+00]\n",
      " [1.0000000e+00 2.5075289e-12]\n",
      " [4.5177875e-11 1.0000000e+00]\n",
      " [7.2394984e-10 1.0000000e+00]\n",
      " [1.0000000e+00 1.1995229e-13]\n",
      " [2.7921282e-11 1.0000000e+00]\n",
      " [1.0000000e+00 2.3562166e-12]\n",
      " [1.0000000e+00 4.6004806e-12]\n",
      " [1.0000000e+00 2.7852362e-10]\n",
      " [1.0000000e+00 7.4773226e-12]\n",
      " [1.0000000e+00 2.8263128e-11]\n",
      " [1.0000000e+00 1.0897529e-11]]\n",
      "--------------------------------------------------\n",
      "2.2305617676465772e-05\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(\"-\"*50)\n",
    "print(scores[0]) # loss\n",
    "print(scores[1]) # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】Iris（多値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "y_hot = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 4), (96, 3), (24, 4))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_hot, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "X_train2.shape, y_train2.shape, X_val2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 情報を１度リセット\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 - 1s - loss: 0.9085 - accuracy: 0.5625 - val_loss: 0.8723 - val_accuracy: 0.7083\n",
      "Epoch 2/100\n",
      "10/10 - 0s - loss: 0.7385 - accuracy: 0.7396 - val_loss: 0.7000 - val_accuracy: 0.7083\n",
      "Epoch 3/100\n",
      "10/10 - 0s - loss: 0.6045 - accuracy: 0.7812 - val_loss: 0.5013 - val_accuracy: 0.9167\n",
      "Epoch 4/100\n",
      "10/10 - 0s - loss: 0.4691 - accuracy: 0.8333 - val_loss: 0.5807 - val_accuracy: 0.7083\n",
      "Epoch 5/100\n",
      "10/10 - 0s - loss: 0.4099 - accuracy: 0.8229 - val_loss: 0.3932 - val_accuracy: 0.7917\n",
      "Epoch 6/100\n",
      "10/10 - 0s - loss: 0.4309 - accuracy: 0.7917 - val_loss: 0.3331 - val_accuracy: 0.9167\n",
      "Epoch 7/100\n",
      "10/10 - 0s - loss: 0.2805 - accuracy: 0.9062 - val_loss: 0.7691 - val_accuracy: 0.7083\n",
      "Epoch 8/100\n",
      "10/10 - 0s - loss: 0.2785 - accuracy: 0.9167 - val_loss: 0.4483 - val_accuracy: 0.7083\n",
      "Epoch 9/100\n",
      "10/10 - 0s - loss: 0.2943 - accuracy: 0.8854 - val_loss: 0.2664 - val_accuracy: 0.9167\n",
      "Epoch 10/100\n",
      "10/10 - 0s - loss: 0.2369 - accuracy: 0.9271 - val_loss: 0.2444 - val_accuracy: 0.9167\n",
      "Epoch 11/100\n",
      "10/10 - 0s - loss: 0.3019 - accuracy: 0.8438 - val_loss: 0.2716 - val_accuracy: 0.9167\n",
      "Epoch 12/100\n",
      "10/10 - 0s - loss: 0.1539 - accuracy: 0.9583 - val_loss: 0.2499 - val_accuracy: 0.9167\n",
      "Epoch 13/100\n",
      "10/10 - 0s - loss: 0.1975 - accuracy: 0.9271 - val_loss: 0.2466 - val_accuracy: 0.9167\n",
      "Epoch 14/100\n",
      "10/10 - 0s - loss: 0.2729 - accuracy: 0.8854 - val_loss: 0.4651 - val_accuracy: 0.7083\n",
      "Epoch 15/100\n",
      "10/10 - 0s - loss: 0.2528 - accuracy: 0.8750 - val_loss: 0.2245 - val_accuracy: 0.9167\n",
      "Epoch 16/100\n",
      "10/10 - 0s - loss: 0.1473 - accuracy: 0.9688 - val_loss: 0.2360 - val_accuracy: 0.9167\n",
      "Epoch 17/100\n",
      "10/10 - 0s - loss: 0.0915 - accuracy: 0.9896 - val_loss: 0.4756 - val_accuracy: 0.7917\n",
      "Epoch 18/100\n",
      "10/10 - 0s - loss: 0.1580 - accuracy: 0.9583 - val_loss: 0.7493 - val_accuracy: 0.7083\n",
      "Epoch 19/100\n",
      "10/10 - 0s - loss: 0.2242 - accuracy: 0.8958 - val_loss: 0.2071 - val_accuracy: 0.9167\n",
      "Epoch 20/100\n",
      "10/10 - 0s - loss: 0.2440 - accuracy: 0.8854 - val_loss: 0.2312 - val_accuracy: 0.9167\n",
      "Epoch 21/100\n",
      "10/10 - 0s - loss: 0.1236 - accuracy: 0.9375 - val_loss: 0.2533 - val_accuracy: 0.9167\n",
      "Epoch 22/100\n",
      "10/10 - 0s - loss: 0.2052 - accuracy: 0.9271 - val_loss: 0.5067 - val_accuracy: 0.7917\n",
      "Epoch 23/100\n",
      "10/10 - 0s - loss: 0.2112 - accuracy: 0.9375 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "10/10 - 0s - loss: 0.1841 - accuracy: 0.9375 - val_loss: 0.2328 - val_accuracy: 0.9167\n",
      "Epoch 25/100\n",
      "10/10 - 0s - loss: 0.1358 - accuracy: 0.9479 - val_loss: 0.4108 - val_accuracy: 0.9167\n",
      "Epoch 26/100\n",
      "10/10 - 0s - loss: 0.1357 - accuracy: 0.9375 - val_loss: 0.3172 - val_accuracy: 0.9167\n",
      "Epoch 27/100\n",
      "10/10 - 0s - loss: 0.1284 - accuracy: 0.9271 - val_loss: 0.2588 - val_accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "10/10 - 0s - loss: 0.1110 - accuracy: 0.9688 - val_loss: 0.3435 - val_accuracy: 0.8333\n",
      "Epoch 29/100\n",
      "10/10 - 0s - loss: 0.1382 - accuracy: 0.9167 - val_loss: 0.4718 - val_accuracy: 0.8333\n",
      "Epoch 30/100\n",
      "10/10 - 0s - loss: 0.1457 - accuracy: 0.9375 - val_loss: 0.5008 - val_accuracy: 0.7917\n",
      "Epoch 31/100\n",
      "10/10 - 0s - loss: 0.1712 - accuracy: 0.9375 - val_loss: 0.3338 - val_accuracy: 0.9167\n",
      "Epoch 32/100\n",
      "10/10 - 0s - loss: 0.0833 - accuracy: 0.9792 - val_loss: 0.3439 - val_accuracy: 0.9167\n",
      "Epoch 33/100\n",
      "10/10 - 0s - loss: 0.1900 - accuracy: 0.9479 - val_loss: 0.2700 - val_accuracy: 0.9167\n",
      "Epoch 34/100\n",
      "10/10 - 0s - loss: 0.1091 - accuracy: 0.9583 - val_loss: 0.2247 - val_accuracy: 0.8750\n",
      "Epoch 35/100\n",
      "10/10 - 0s - loss: 0.2598 - accuracy: 0.8854 - val_loss: 0.2307 - val_accuracy: 0.8333\n",
      "Epoch 36/100\n",
      "10/10 - 0s - loss: 0.0734 - accuracy: 0.9792 - val_loss: 0.2326 - val_accuracy: 0.9167\n",
      "Epoch 37/100\n",
      "10/10 - 0s - loss: 0.1273 - accuracy: 0.9479 - val_loss: 0.2577 - val_accuracy: 0.9167\n",
      "Epoch 38/100\n",
      "10/10 - 0s - loss: 0.0887 - accuracy: 0.9583 - val_loss: 0.2284 - val_accuracy: 0.9167\n",
      "Epoch 39/100\n",
      "10/10 - 0s - loss: 0.0930 - accuracy: 0.9896 - val_loss: 0.2294 - val_accuracy: 0.9583\n",
      "Epoch 40/100\n",
      "10/10 - 0s - loss: 0.0364 - accuracy: 0.9896 - val_loss: 0.3522 - val_accuracy: 0.9167\n",
      "Epoch 41/100\n",
      "10/10 - 0s - loss: 0.3050 - accuracy: 0.9271 - val_loss: 0.2707 - val_accuracy: 0.9167\n",
      "Epoch 42/100\n",
      "10/10 - 0s - loss: 0.1470 - accuracy: 0.9479 - val_loss: 0.2262 - val_accuracy: 0.9583\n",
      "Epoch 43/100\n",
      "10/10 - 0s - loss: 0.0803 - accuracy: 0.9792 - val_loss: 0.2267 - val_accuracy: 0.9167\n",
      "Epoch 44/100\n",
      "10/10 - 0s - loss: 0.1089 - accuracy: 0.9583 - val_loss: 0.3910 - val_accuracy: 0.9167\n",
      "Epoch 45/100\n",
      "10/10 - 0s - loss: 0.1188 - accuracy: 0.9583 - val_loss: 0.2404 - val_accuracy: 0.8333\n",
      "Epoch 46/100\n",
      "10/10 - 0s - loss: 0.1375 - accuracy: 0.9375 - val_loss: 0.2620 - val_accuracy: 0.9167\n",
      "Epoch 47/100\n",
      "10/10 - 0s - loss: 0.0972 - accuracy: 0.9688 - val_loss: 0.2772 - val_accuracy: 0.9167\n",
      "Epoch 48/100\n",
      "10/10 - 0s - loss: 0.0882 - accuracy: 0.9583 - val_loss: 0.3230 - val_accuracy: 0.8333\n",
      "Epoch 49/100\n",
      "10/10 - 0s - loss: 0.0392 - accuracy: 1.0000 - val_loss: 0.2909 - val_accuracy: 0.9167\n",
      "Epoch 50/100\n",
      "10/10 - 0s - loss: 0.1122 - accuracy: 0.9688 - val_loss: 0.3489 - val_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "10/10 - 0s - loss: 0.1343 - accuracy: 0.9479 - val_loss: 0.2961 - val_accuracy: 0.9167\n",
      "Epoch 52/100\n",
      "10/10 - 0s - loss: 0.1118 - accuracy: 0.9583 - val_loss: 0.2273 - val_accuracy: 0.9167\n",
      "Epoch 53/100\n",
      "10/10 - 0s - loss: 0.0440 - accuracy: 0.9792 - val_loss: 0.2162 - val_accuracy: 0.9583\n",
      "Epoch 54/100\n",
      "10/10 - 0s - loss: 0.0661 - accuracy: 0.9688 - val_loss: 0.7723 - val_accuracy: 0.7083\n",
      "Epoch 55/100\n",
      "10/10 - 0s - loss: 0.1138 - accuracy: 0.9271 - val_loss: 0.3689 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "10/10 - 0s - loss: 0.1354 - accuracy: 0.9375 - val_loss: 0.3378 - val_accuracy: 0.9167\n",
      "Epoch 57/100\n",
      "10/10 - 0s - loss: 0.1159 - accuracy: 0.9583 - val_loss: 0.2136 - val_accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "10/10 - 0s - loss: 0.0873 - accuracy: 0.9688 - val_loss: 0.1911 - val_accuracy: 0.9583\n",
      "Epoch 59/100\n",
      "10/10 - 0s - loss: 0.0362 - accuracy: 1.0000 - val_loss: 0.3294 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "10/10 - 0s - loss: 0.1679 - accuracy: 0.9375 - val_loss: 0.2530 - val_accuracy: 0.9167\n",
      "Epoch 61/100\n",
      "10/10 - 0s - loss: 0.0464 - accuracy: 0.9896 - val_loss: 0.4407 - val_accuracy: 0.9167\n",
      "Epoch 62/100\n",
      "10/10 - 0s - loss: 0.1438 - accuracy: 0.9375 - val_loss: 0.3218 - val_accuracy: 0.9167\n",
      "Epoch 63/100\n",
      "10/10 - 0s - loss: 0.0761 - accuracy: 0.9688 - val_loss: 0.2846 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "10/10 - 0s - loss: 0.1429 - accuracy: 0.9271 - val_loss: 0.1937 - val_accuracy: 0.9583\n",
      "Epoch 65/100\n",
      "10/10 - 0s - loss: 0.0464 - accuracy: 0.9896 - val_loss: 0.2011 - val_accuracy: 0.9583\n",
      "Epoch 66/100\n",
      "10/10 - 0s - loss: 0.0865 - accuracy: 0.9688 - val_loss: 0.5173 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "10/10 - 0s - loss: 0.1043 - accuracy: 0.9583 - val_loss: 0.4740 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "10/10 - 0s - loss: 0.1492 - accuracy: 0.9583 - val_loss: 0.1970 - val_accuracy: 0.9583\n",
      "Epoch 69/100\n",
      "10/10 - 0s - loss: 0.0481 - accuracy: 0.9688 - val_loss: 0.5284 - val_accuracy: 0.8750\n",
      "Epoch 70/100\n",
      "10/10 - 0s - loss: 0.0558 - accuracy: 0.9792 - val_loss: 0.3440 - val_accuracy: 0.9167\n",
      "Epoch 71/100\n",
      "10/10 - 0s - loss: 0.0651 - accuracy: 0.9896 - val_loss: 0.2223 - val_accuracy: 0.9167\n",
      "Epoch 72/100\n",
      "10/10 - 0s - loss: 0.0686 - accuracy: 0.9688 - val_loss: 0.3422 - val_accuracy: 0.9167\n",
      "Epoch 73/100\n",
      "10/10 - 0s - loss: 0.2810 - accuracy: 0.9375 - val_loss: 0.2897 - val_accuracy: 0.9167\n",
      "Epoch 74/100\n",
      "10/10 - 0s - loss: 0.0491 - accuracy: 0.9896 - val_loss: 0.2894 - val_accuracy: 0.9167\n",
      "Epoch 75/100\n",
      "10/10 - 0s - loss: 0.0476 - accuracy: 0.9896 - val_loss: 0.5510 - val_accuracy: 0.8750\n",
      "Epoch 76/100\n",
      "10/10 - 0s - loss: 0.0690 - accuracy: 0.9792 - val_loss: 0.3306 - val_accuracy: 0.9167\n",
      "Epoch 77/100\n",
      "10/10 - 0s - loss: 0.0249 - accuracy: 1.0000 - val_loss: 0.5545 - val_accuracy: 0.9167\n",
      "Epoch 78/100\n",
      "10/10 - 0s - loss: 0.1071 - accuracy: 0.9688 - val_loss: 0.4152 - val_accuracy: 0.9167\n",
      "Epoch 79/100\n",
      "10/10 - 0s - loss: 0.0928 - accuracy: 0.9583 - val_loss: 0.2222 - val_accuracy: 0.9583\n",
      "Epoch 80/100\n",
      "10/10 - 0s - loss: 0.0564 - accuracy: 0.9792 - val_loss: 0.3556 - val_accuracy: 0.9167\n",
      "Epoch 81/100\n",
      "10/10 - 0s - loss: 0.0430 - accuracy: 0.9792 - val_loss: 0.3551 - val_accuracy: 0.9167\n",
      "Epoch 82/100\n",
      "10/10 - 0s - loss: 0.0965 - accuracy: 0.9688 - val_loss: 0.3312 - val_accuracy: 0.8333\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.0734 - accuracy: 0.9792 - val_loss: 0.2641 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "10/10 - 0s - loss: 0.0310 - accuracy: 0.9896 - val_loss: 0.5441 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "10/10 - 0s - loss: 0.1353 - accuracy: 0.9583 - val_loss: 0.2482 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "10/10 - 0s - loss: 0.0577 - accuracy: 0.9688 - val_loss: 0.2584 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "10/10 - 0s - loss: 0.0779 - accuracy: 0.9583 - val_loss: 0.3642 - val_accuracy: 0.9167\n",
      "Epoch 88/100\n",
      "10/10 - 0s - loss: 0.0445 - accuracy: 0.9792 - val_loss: 0.3069 - val_accuracy: 0.9167\n",
      "Epoch 89/100\n",
      "10/10 - 0s - loss: 0.0845 - accuracy: 0.9583 - val_loss: 0.6375 - val_accuracy: 0.8750\n",
      "Epoch 90/100\n",
      "10/10 - 0s - loss: 0.1040 - accuracy: 0.9792 - val_loss: 0.3870 - val_accuracy: 0.9167\n",
      "Epoch 91/100\n",
      "10/10 - 0s - loss: 0.1000 - accuracy: 0.9688 - val_loss: 0.1968 - val_accuracy: 0.9583\n",
      "Epoch 92/100\n",
      "10/10 - 0s - loss: 0.0616 - accuracy: 0.9792 - val_loss: 0.2449 - val_accuracy: 0.9167\n",
      "Epoch 93/100\n",
      "10/10 - 0s - loss: 0.0659 - accuracy: 0.9688 - val_loss: 0.2074 - val_accuracy: 0.9583\n",
      "Epoch 94/100\n",
      "10/10 - 0s - loss: 0.0515 - accuracy: 0.9688 - val_loss: 0.2156 - val_accuracy: 0.9167\n",
      "Epoch 95/100\n",
      "10/10 - 0s - loss: 0.0680 - accuracy: 0.9583 - val_loss: 0.2111 - val_accuracy: 0.9583\n",
      "Epoch 96/100\n",
      "10/10 - 0s - loss: 0.0480 - accuracy: 0.9896 - val_loss: 0.4757 - val_accuracy: 0.8333\n",
      "Epoch 97/100\n",
      "10/10 - 0s - loss: 0.0659 - accuracy: 0.9688 - val_loss: 0.4074 - val_accuracy: 0.9167\n",
      "Epoch 98/100\n",
      "10/10 - 0s - loss: 0.0426 - accuracy: 0.9792 - val_loss: 0.6784 - val_accuracy: 0.9167\n",
      "Epoch 99/100\n",
      "10/10 - 0s - loss: 0.0495 - accuracy: 0.9792 - val_loss: 0.2925 - val_accuracy: 0.9167\n",
      "Epoch 100/100\n",
      "10/10 - 0s - loss: 0.0791 - accuracy: 0.9896 - val_loss: 0.2453 - val_accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2453 - accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "# モデル生成\n",
    "def generate_model2(X):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=X.shape[1:]))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model2 = generate_model2(X_train2)\n",
    "    \n",
    "# コンパイル\n",
    "def compile_model2(model):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='RMSprop',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model2 = compile_model2(model2)\n",
    "\n",
    "# 学習〜予測〜評価\n",
    "def learning_evaluate2(model, X_train, y_train, X_val, y_val):\n",
    "    model.fit(X_train, y_train, \n",
    "             batch_size=10,\n",
    "             epochs=100,\n",
    "             verbose=2,\n",
    "             validation_data=(X_val, y_val))\n",
    "    pred = model.predict(X_val)\n",
    "    score = model.evaluate(X_val, y_val)\n",
    "    return pred, score\n",
    "\n",
    "pred2, score2 = learning_evaluate2(model2, X_train2, y_train2, X_val2, y_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 3.8329337e-10 1.0852408e-16]\n",
      " [7.4478493e-08 1.1659685e-03 9.9883395e-01]\n",
      " [1.0000000e+00 2.0828689e-10 2.5282693e-17]\n",
      " [1.8965734e-04 9.9945933e-01 3.5105858e-04]\n",
      " [2.3055331e-04 9.9939668e-01 3.7273401e-04]\n",
      " [1.6268856e-04 9.9900872e-01 8.2864688e-04]\n",
      " [3.5091018e-06 8.6585442e-03 9.9133801e-01]\n",
      " [1.4873319e-07 1.4260546e-03 9.9857378e-01]\n",
      " [1.0000000e+00 2.2485311e-09 1.2089943e-15]\n",
      " [1.3878329e-04 1.5065327e-01 8.4920800e-01]\n",
      " [4.1608463e-04 9.9768794e-01 1.8960027e-03]\n",
      " [3.0872360e-09 1.7010565e-04 9.9982989e-01]\n",
      " [1.0000000e+00 8.6170591e-11 6.0940120e-18]\n",
      " [7.0192286e-08 9.2894136e-04 9.9907100e-01]\n",
      " [1.0000000e+00 8.3924251e-10 2.9749425e-16]\n",
      " [2.3078042e-09 1.5330754e-04 9.9984670e-01]\n",
      " [1.6954666e-04 9.9939287e-01 4.3764059e-04]\n",
      " [1.0000000e+00 6.3324969e-13 3.8881512e-21]\n",
      " [4.6600829e-04 4.4462955e-01 5.5490452e-01]\n",
      " [1.0000000e+00 1.1277572e-09 3.1036515e-16]\n",
      " [1.0000000e+00 1.0692593e-09 2.7272439e-16]\n",
      " [3.9118033e-05 7.8525417e-02 9.2143542e-01]\n",
      " [6.3717403e-07 3.5817670e-03 9.9641764e-01]\n",
      " [4.9743729e-05 6.7011468e-02 9.3293881e-01]]\n",
      "--------------------------------------------------\n",
      "0.2452877312898636\n",
      "0.9166666865348816\n"
     ]
    }
   ],
   "source": [
    "print(pred2)\n",
    "print(\"-\"*50)\n",
    "print(score2[0]) # loss\n",
    "print(score2[1]) # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】House PricesをKerasで学習\n",
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Initializing from file failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-17f8caf980b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/yuki.tatsuoka/Downloads/house-prices-advanced-regression-techniques (1)/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhouse_price_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mhouse_price_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_rows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Initializing from file failed"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dir_path = '/Users/yuki.tatsuoka/Downloads/house-prices-advanced-regression-techniques (1)/'\n",
    "house_price_train = pd.read_csv(dir_path + 'train.csv')\n",
    "house_price_test = pd.read_csv(dir_path + 'test.csv')\n",
    "pd.set_option('display.max_rows', 300)\n",
    "\n",
    "\n",
    "y = house_price_train['SalePrice']\n",
    "X = house_price_train.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# object型の変換と欠損値を埋めることが必須条件\n",
    "X = X.fillna(0)\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対数と標準化\n",
    "y_log = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_log, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train3, X_val3, y_train3, y_val3 = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "X_train3.shape, y_train3.shape, X_val3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 情報を１度リセット\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# モデル生成\n",
    "def generate_model3(X):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=X.shape[1:]))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "model3 = generate_model3(X_train3)\n",
    "    \n",
    "# コンパイル\n",
    "def compile_model3(model):\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                 optimizer='RMSprop')\n",
    "    return model\n",
    "\n",
    "model3 = compile_model3(model3)\n",
    "\n",
    "# 学習〜予測〜評価\n",
    "def learning_evaluate3(model, X_train, y_train, X_val, y_val):\n",
    "    model.fit(X_train, y_train, \n",
    "             batch_size=10,\n",
    "             epochs=50,\n",
    "             verbose=2,\n",
    "             validation_data=(X_val, y_val))\n",
    "    pred = model.predict(X_val)\n",
    "    score = model.evaluate(X_val, y_val)\n",
    "    return pred, score\n",
    "\n",
    "pred3, score3 = learning_evaluate3(model3, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred3)\n",
    "print(\"-\"*50)\n",
    "print(score3) # loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】MNISTをKerasで学習\n",
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 28, 28, 1), (48000, 10), (12000, 28, 28, 1))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# さらにtrainとvalに分割\n",
    "X_train4, X_val4, y_train4, y_val4 = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "X_train4.shape, y_train4.shape, X_val4.shape\n",
    "\n",
    "# ワンホット\n",
    "y_train4 = to_categorical(y_train4)\n",
    "y_val4 = to_categorical(y_val4)\n",
    "\n",
    "# チャネルの追加\n",
    "X_train4 = X_train4.reshape(-1,28,28,1)\n",
    "X_val4 = X_val4.reshape(-1,28,28,1)\n",
    "\n",
    "X_train4.shape, y_train4.shape, X_val4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "240/240 - 17s - loss: 0.8423 - accuracy: 0.7920 - val_loss: 0.0849 - val_accuracy: 0.9772\n",
      "Epoch 2/10\n",
      "240/240 - 16s - loss: 0.1259 - accuracy: 0.9683 - val_loss: 0.0669 - val_accuracy: 0.9827\n",
      "Epoch 3/10\n",
      "240/240 - 16s - loss: 0.0844 - accuracy: 0.9796 - val_loss: 0.0538 - val_accuracy: 0.9871\n",
      "Epoch 4/10\n",
      "240/240 - 16s - loss: 0.0621 - accuracy: 0.9842 - val_loss: 0.0502 - val_accuracy: 0.9868\n",
      "Epoch 5/10\n",
      "240/240 - 16s - loss: 0.0512 - accuracy: 0.9866 - val_loss: 0.0448 - val_accuracy: 0.9883\n",
      "Epoch 6/10\n",
      "240/240 - 17s - loss: 0.0447 - accuracy: 0.9886 - val_loss: 0.0462 - val_accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "240/240 - 19s - loss: 0.0413 - accuracy: 0.9897 - val_loss: 0.0612 - val_accuracy: 0.9877\n",
      "Epoch 8/10\n",
      "240/240 - 18s - loss: 0.0374 - accuracy: 0.9907 - val_loss: 0.0483 - val_accuracy: 0.9903\n",
      "Epoch 9/10\n",
      "240/240 - 17s - loss: 0.0316 - accuracy: 0.9919 - val_loss: 0.0505 - val_accuracy: 0.9910\n",
      "Epoch 10/10\n",
      "240/240 - 16s - loss: 0.0305 - accuracy: 0.9926 - val_loss: 0.0618 - val_accuracy: 0.9890\n",
      "375/375 [==============================] - 1s 3ms/step - loss: 0.0618 - accuracy: 0.9890\n"
     ]
    }
   ],
   "source": [
    "# モデル生成\n",
    "def generate_model4(X):\n",
    "    model = Sequential()\n",
    "    Conv2D, MaxPool2D\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3,3), padding='same', input_shape=X.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model4 = generate_model4(X_train4)\n",
    "    \n",
    "# コンパイル\n",
    "def compile_model4(model):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='RMSprop',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model4 = compile_model4(model4)\n",
    "\n",
    "# 学習〜予測〜評価\n",
    "def learning_evaluate4(model, X_train, y_train, X_val, y_val):\n",
    "    history = model.fit(X_train, y_train, \n",
    "             batch_size=200,\n",
    "             epochs=10,\n",
    "             verbose=2,\n",
    "             validation_data=(X_val, y_val))\n",
    "    pred = model.predict(X_val)\n",
    "    score = model.evaluate(X_val, y_val)\n",
    "    return history, pred, score\n",
    "\n",
    "history, pred4, score4 = learning_evaluate4(model4, X_train4, y_train4, X_val4, y_val4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               401536    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 432,074\n",
      "Trainable params: 432,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.6599513e-38 1.6754950e-24 5.0317734e-22 ... 9.9505062e-21\n",
      "  1.4661611e-17 1.5327270e-21]\n",
      " [5.6666868e-21 3.5867039e-29 5.6140769e-22 ... 6.0976040e-22\n",
      "  2.0458387e-17 1.6777464e-24]\n",
      " [8.6558790e-20 1.4571417e-29 1.8642507e-24 ... 9.6852803e-22\n",
      "  2.2550201e-17 1.8653097e-25]\n",
      " ...\n",
      " [1.3090522e-28 7.6225687e-21 3.3611283e-22 ... 7.5341807e-17\n",
      "  5.0919616e-14 1.4885088e-13]\n",
      " [4.3729505e-21 1.0000000e+00 1.2070877e-13 ... 4.1023587e-11\n",
      "  2.0577066e-11 1.3531169e-10]\n",
      " [7.2351127e-24 1.6615475e-34 2.7597883e-26 ... 5.1001537e-26\n",
      "  5.2899581e-21 1.7556649e-29]]\n",
      "--------------------------------------------------\n",
      "0.061758529394865036\n",
      "0.9890000224113464\n"
     ]
    }
   ],
   "source": [
    "# 予測数値と損失と評価の確認\n",
    "print(pred4)\n",
    "print(\"-\"*50)\n",
    "print(score4[0]) # loss\n",
    "print(score4[1]) # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.00836268, -0.07339387, -0.133536  ,  0.02494086,\n",
       "           -0.10684297,  0.00449653,  0.05141568,  0.04797177,\n",
       "           -0.00345266,  0.01544612, -0.06140416,  0.08091657,\n",
       "           -0.06915998, -0.14636895,  0.02028309,  0.00379514,\n",
       "           -0.10343668,  0.09864499,  0.0366523 , -0.05809825,\n",
       "           -0.10107286, -0.05600003,  0.03977207, -0.08777133,\n",
       "           -0.04689405,  0.03063524, -0.08439587, -0.06233243,\n",
       "           -0.03448942,  0.08946505, -0.05569545, -0.1527438 ]],\n",
       " \n",
       "         [[ 0.00624437, -0.05712632,  0.01630817, -0.09240224,\n",
       "           -0.05267885,  0.06459565,  0.01460462, -0.10872636,\n",
       "            0.0622847 , -0.10799308, -0.11170595,  0.06404065,\n",
       "           -0.11124188, -0.0267617 ,  0.06696093, -0.09871303,\n",
       "            0.03996796, -0.02121791,  0.00201831, -0.05403918,\n",
       "            0.10574206, -0.03054587, -0.07346552, -0.03569731,\n",
       "            0.08484056,  0.06715852, -0.0406752 ,  0.0106782 ,\n",
       "           -0.10836516,  0.05031861, -0.09881202, -0.00662582]],\n",
       " \n",
       "         [[-0.14527561, -0.03309244,  0.07372493,  0.07719399,\n",
       "            0.10193683, -0.05753178, -0.09444748,  0.10338247,\n",
       "            0.08206554, -0.0007125 ,  0.04258568,  0.092498  ,\n",
       "           -0.02792265, -0.02053783, -0.0542401 , -0.10610081,\n",
       "           -0.09702951, -0.07083505, -0.06398628, -0.07751039,\n",
       "           -0.11154408,  0.04796582, -0.00081816, -0.03335841,\n",
       "           -0.1573097 , -0.10236838, -0.02257004, -0.00286531,\n",
       "            0.10924917,  0.03651375,  0.0408701 , -0.09905002]]],\n",
       " \n",
       " \n",
       "        [[[ 0.11269773,  0.08982176, -0.15216115,  0.02592182,\n",
       "            0.04963113,  0.07098614,  0.05522805,  0.0210434 ,\n",
       "            0.07233382,  0.00866518, -0.07114743, -0.1467596 ,\n",
       "           -0.08573269, -0.02841657, -0.07062737,  0.10095508,\n",
       "           -0.13155906, -0.14611435,  0.08123171,  0.13023053,\n",
       "            0.03031935,  0.07392045, -0.20663176,  0.08929078,\n",
       "           -0.02202191, -0.06705024, -0.0320062 ,  0.00506908,\n",
       "            0.12084402, -0.09688111, -0.07690524, -0.0235327 ]],\n",
       " \n",
       "         [[ 0.03856073,  0.09011799,  0.0137151 ,  0.08093565,\n",
       "           -0.03634074,  0.00774143, -0.10105996, -0.06850745,\n",
       "            0.02907018,  0.07330602,  0.07228192,  0.01946211,\n",
       "            0.08109742,  0.04610937, -0.00208113,  0.00321306,\n",
       "            0.08887859,  0.03920139, -0.03886749, -0.15418662,\n",
       "           -0.03668989, -0.0773844 , -0.02669946, -0.06206921,\n",
       "            0.065478  ,  0.11195166, -0.02259427,  0.04617973,\n",
       "            0.02006299, -0.08466223,  0.05187176,  0.08667503]],\n",
       " \n",
       "         [[-0.09775863,  0.04348214,  0.04374221, -0.15035217,\n",
       "            0.06882179, -0.15486078,  0.00275224, -0.13828902,\n",
       "           -0.07541028, -0.13298738, -0.03238117, -0.03653314,\n",
       "           -0.05445508,  0.08288746, -0.11387247,  0.11410173,\n",
       "            0.0837423 ,  0.01218478, -0.09654992,  0.13095537,\n",
       "            0.08477242, -0.11511637,  0.02806262, -0.16513678,\n",
       "            0.05859566, -0.11046656, -0.06655461,  0.02479104,\n",
       "            0.0121617 ,  0.06912494, -0.18275915, -0.07102656]]],\n",
       " \n",
       " \n",
       "        [[[-0.07224823, -0.07356513,  0.00998051, -0.0360723 ,\n",
       "            0.03560202, -0.1404161 , -0.10711188,  0.04262033,\n",
       "           -0.05936562, -0.04798974, -0.0764382 , -0.0882557 ,\n",
       "           -0.07859723, -0.05035506,  0.02798746, -0.11099806,\n",
       "            0.08705327,  0.0588764 ,  0.06213726, -0.17920618,\n",
       "            0.01249679,  0.02608876,  0.11469451,  0.02834773,\n",
       "            0.00904985,  0.06772022,  0.05348266,  0.03667371,\n",
       "           -0.01936302,  0.12040384, -0.11797612,  0.10394255]],\n",
       " \n",
       "         [[-0.05509043,  0.08447218, -0.13727704, -0.1037912 ,\n",
       "           -0.0610537 , -0.15769367, -0.00792363,  0.09179728,\n",
       "           -0.14709741, -0.0902823 ,  0.04380972, -0.04677669,\n",
       "            0.04053348,  0.07420141, -0.07974885,  0.11769515,\n",
       "            0.00642602,  0.01837253, -0.02721142, -0.00621442,\n",
       "           -0.04148332, -0.04368497, -0.10380019, -0.01506175,\n",
       "            0.02610523, -0.10346143,  0.08973373, -0.010434  ,\n",
       "           -0.08198527, -0.10223579, -0.09360506, -0.08696675]],\n",
       " \n",
       "         [[-0.2278894 , -0.07390299, -0.03264078,  0.07900201,\n",
       "           -0.00276761,  0.10854109, -0.0856263 ,  0.00398966,\n",
       "           -0.01022657,  0.05493849,  0.05644881, -0.1021039 ,\n",
       "            0.06910425, -0.08278371,  0.03671271, -0.07561973,\n",
       "           -0.07852878,  0.02598407,  0.03648147, -0.11470557,\n",
       "           -0.09421081,  0.04359645, -0.03434752, -0.07850429,\n",
       "           -0.01521888, -0.06153789, -0.10570233, -0.0535697 ,\n",
       "           -0.04294617,  0.0696614 ,  0.02954345,  0.11657541]]]],\n",
       "       dtype=float32),\n",
       " array([ 0.06460545,  0.20877415, -0.02218386,  0.09325012,  0.18923672,\n",
       "         0.0492374 ,  0.06987154,  0.15161213,  0.15849039, -0.12511632,\n",
       "        -0.05580162, -0.04017052,  0.12349932, -0.03699267, -0.07828839,\n",
       "         0.21464187, -0.07561156, -0.1753616 ,  0.22894797,  0.01775894,\n",
       "        -0.09576067,  0.18709296,  0.08020771, -0.00703648, -0.07819837,\n",
       "        -0.06455985, -0.00099268, -0.14860706,  0.20520541, -0.15047936,\n",
       "        -0.03273102,  0.04368896], dtype=float32),\n",
       " array([[[[ 6.24049716e-02,  6.43488839e-02, -2.59657502e-02, ...,\n",
       "           -3.98202389e-02,  8.52415618e-03,  1.81917811e-03],\n",
       "          [-4.81701232e-02,  1.18346468e-01,  2.26492546e-02, ...,\n",
       "            9.09691527e-02, -1.75751839e-02, -1.01283696e-02],\n",
       "          [ 4.61907983e-02,  8.41656625e-02, -4.00044769e-02, ...,\n",
       "            9.69336033e-02, -2.40593497e-02,  1.31014124e-01],\n",
       "          ...,\n",
       "          [-8.11050460e-03, -1.12446897e-01,  5.38836569e-02, ...,\n",
       "           -2.38189884e-02,  7.67777488e-02,  4.24211519e-03],\n",
       "          [-6.21384867e-02, -3.22069377e-02,  5.36879338e-02, ...,\n",
       "            2.88706627e-02,  9.64308437e-03,  1.52787507e-01],\n",
       "          [ 6.11068830e-02,  3.09091248e-02, -3.40366289e-02, ...,\n",
       "           -2.65583936e-02, -1.02799468e-01,  5.14907343e-03]],\n",
       " \n",
       "         [[ 1.24373280e-01, -1.42535130e-02,  7.01619964e-03, ...,\n",
       "           -4.24153768e-02, -7.28550553e-02,  8.36982504e-02],\n",
       "          [-6.87779263e-02, -5.05538918e-02,  5.99343143e-02, ...,\n",
       "           -7.03962520e-03, -4.57068207e-03, -3.17266695e-02],\n",
       "          [ 7.27532580e-02,  1.12495922e-01,  4.87360358e-02, ...,\n",
       "           -3.71879973e-02, -6.96148574e-02,  6.20891936e-02],\n",
       "          ...,\n",
       "          [-4.91286628e-02,  7.06327558e-02,  1.98123064e-02, ...,\n",
       "           -4.54520583e-02, -1.27531111e-01, -2.36584917e-02],\n",
       "          [-1.12804063e-01, -4.25915793e-02,  1.10352160e-02, ...,\n",
       "            5.20949718e-03, -2.28663534e-02, -4.25228961e-02],\n",
       "          [-1.13342881e-01, -2.18482502e-02,  5.15115671e-02, ...,\n",
       "            1.75449792e-02,  3.88123989e-02, -4.82189916e-02]],\n",
       " \n",
       "         [[-5.36276214e-03,  1.38570219e-01,  7.98703954e-02, ...,\n",
       "           -4.35024016e-02, -1.48289669e-02,  2.78550573e-02],\n",
       "          [-3.05414014e-02, -3.95428427e-02, -4.60918210e-02, ...,\n",
       "            1.84633136e-02, -7.11185709e-02, -7.87919164e-02],\n",
       "          [ 4.49838266e-02,  2.21686978e-02, -2.85422523e-02, ...,\n",
       "            1.91639047e-02,  7.01304600e-02, -9.35878418e-03],\n",
       "          ...,\n",
       "          [ 3.87537591e-02, -3.98595259e-03,  3.06151472e-02, ...,\n",
       "           -2.24938281e-02, -4.11515869e-02, -7.83201605e-02],\n",
       "          [ 2.02297028e-02, -1.50845334e-01,  8.67892895e-03, ...,\n",
       "            4.46644202e-02,  3.12487222e-03, -2.77911033e-03],\n",
       "          [-5.91227487e-02, -2.54449937e-02, -6.65807649e-02, ...,\n",
       "           -4.20794562e-02, -5.55668585e-03, -4.40957919e-02]]],\n",
       " \n",
       " \n",
       "        [[[ 7.57199107e-03,  6.14418723e-02, -8.64494368e-02, ...,\n",
       "           -3.11088916e-02, -8.17972496e-02, -9.03549492e-02],\n",
       "          [-1.37384325e-01, -7.43908659e-02, -1.11142926e-01, ...,\n",
       "           -1.00490309e-01, -3.93323041e-02, -6.51349574e-02],\n",
       "          [ 1.49693410e-03,  7.17008710e-02,  1.15749270e-01, ...,\n",
       "            1.32456437e-01, -7.13906735e-02,  6.10978156e-02],\n",
       "          ...,\n",
       "          [-9.23591554e-02, -8.30777958e-02,  1.84090771e-02, ...,\n",
       "           -1.03528038e-01, -2.70175990e-02, -1.39551489e-02],\n",
       "          [ 2.29216293e-02,  7.34226406e-02, -4.85337302e-02, ...,\n",
       "            8.91532153e-02,  2.11780276e-02,  3.30315940e-02],\n",
       "          [-5.59579581e-02, -5.56483828e-02, -5.91754317e-02, ...,\n",
       "           -1.19167157e-01,  9.24149379e-02,  7.32305720e-02]],\n",
       " \n",
       "         [[-3.09072193e-02, -6.85819089e-02,  5.55375479e-02, ...,\n",
       "            6.84941038e-02,  3.24855261e-02,  2.64178813e-02],\n",
       "          [ 8.30186829e-02,  4.62430418e-02,  5.46856364e-03, ...,\n",
       "            4.80603725e-02, -6.65931776e-02, -5.28545789e-02],\n",
       "          [ 1.95106193e-02, -4.70795743e-02,  6.08136430e-02, ...,\n",
       "            1.95858050e-02,  5.67944497e-02, -6.17985800e-02],\n",
       "          ...,\n",
       "          [-8.01297873e-02,  3.51463594e-02, -1.27531786e-03, ...,\n",
       "            3.63869444e-02, -8.16060230e-02,  1.89034678e-02],\n",
       "          [ 6.82891998e-03, -4.80693541e-02, -6.52609169e-02, ...,\n",
       "            2.24881712e-02,  6.69899285e-02,  4.08071140e-03],\n",
       "          [-1.56057002e-02, -4.65349481e-02, -8.89887474e-03, ...,\n",
       "           -4.31190543e-02, -5.25191277e-02, -4.47714515e-02]],\n",
       " \n",
       "         [[ 2.02157218e-02,  9.96849388e-02,  1.63699910e-01, ...,\n",
       "            8.85363072e-02, -1.58301014e-02, -5.36691882e-02],\n",
       "          [ 4.91420701e-02, -7.95658380e-02, -2.75061280e-03, ...,\n",
       "           -1.11682668e-01, -6.67363405e-02, -1.40381560e-01],\n",
       "          [ 8.41874033e-02, -1.89269558e-02, -1.07735977e-01, ...,\n",
       "            7.91122671e-03, -1.45525644e-02, -1.66679379e-02],\n",
       "          ...,\n",
       "          [ 3.19092534e-02, -1.22264907e-01, -3.50532308e-02, ...,\n",
       "           -9.59749450e-05, -7.96819851e-02,  5.12589142e-02],\n",
       "          [ 6.21639043e-02,  4.04226966e-02,  6.41146749e-02, ...,\n",
       "           -2.19510756e-02,  3.77353318e-02, -6.50575086e-02],\n",
       "          [-8.23209509e-02,  2.81413700e-02,  4.22486477e-02, ...,\n",
       "            1.73925161e-02, -1.52565110e-02,  4.57451679e-02]]],\n",
       " \n",
       " \n",
       "        [[[-4.04637381e-02,  1.67794209e-02, -7.58582503e-02, ...,\n",
       "            3.50223407e-02, -3.63249481e-02, -2.11395081e-02],\n",
       "          [ 6.14324287e-02, -8.79344270e-02,  6.86970949e-02, ...,\n",
       "           -3.79569083e-03,  1.06314924e-02,  2.40718778e-02],\n",
       "          [-4.71229292e-02,  7.88569730e-03, -6.20638253e-03, ...,\n",
       "            3.09984107e-02, -5.54292090e-02,  5.14906459e-03],\n",
       "          ...,\n",
       "          [ 4.79388237e-03, -2.83042062e-02, -9.90073904e-02, ...,\n",
       "            4.10880856e-02, -6.01299703e-02, -4.99354228e-02],\n",
       "          [ 4.11004834e-02,  2.21521892e-02, -5.46954721e-02, ...,\n",
       "            2.44336985e-02, -1.84864011e-02, -1.63084358e-01],\n",
       "          [ 5.48574440e-02, -2.73590572e-02,  1.43084452e-02, ...,\n",
       "            1.22535331e-02, -1.23178922e-02,  7.73373432e-03]],\n",
       " \n",
       "         [[ 1.08243510e-01,  5.52836992e-02, -1.15336418e-01, ...,\n",
       "           -1.21636698e-02,  9.29042604e-03,  8.16627580e-05],\n",
       "          [ 6.12134561e-02, -7.64410123e-02,  6.42584777e-03, ...,\n",
       "            1.95456836e-02,  5.92507385e-02,  6.23681583e-02],\n",
       "          [ 8.12512487e-02,  5.10891527e-02, -3.82088684e-02, ...,\n",
       "           -7.13447407e-02,  2.28887182e-02,  7.22169830e-03],\n",
       "          ...,\n",
       "          [ 8.64855796e-02, -1.64500289e-02, -3.11342087e-02, ...,\n",
       "            1.32961515e-02,  1.69754978e-02,  1.78512232e-03],\n",
       "          [-1.30353803e-02,  5.75131513e-02, -3.07894964e-02, ...,\n",
       "           -6.66015297e-02,  1.04110204e-01, -1.32466376e-01],\n",
       "          [-4.84465025e-02, -6.36577457e-02,  3.82076874e-02, ...,\n",
       "           -3.33844014e-02, -7.59258270e-02,  2.22117882e-02]],\n",
       " \n",
       "         [[ 6.78253919e-03, -2.51700040e-02,  2.95116624e-04, ...,\n",
       "           -5.17356955e-03, -1.68738123e-02, -4.45138179e-02],\n",
       "          [ 1.88340843e-02,  3.76914218e-02, -1.46206487e-02, ...,\n",
       "            1.65999383e-02,  9.09867361e-02,  3.54117341e-02],\n",
       "          [-1.37473419e-02,  3.74845974e-02, -8.06790292e-02, ...,\n",
       "           -4.71307300e-02, -6.55836388e-02,  7.69539401e-02],\n",
       "          ...,\n",
       "          [ 1.94617528e-02, -4.85402383e-02, -5.19822203e-02, ...,\n",
       "           -7.28732869e-02, -2.55213771e-02, -4.77639809e-02],\n",
       "          [-4.00990807e-02, -5.49984351e-02, -5.00640571e-02, ...,\n",
       "            1.16956078e-01,  1.31904483e-01,  5.52602997e-03],\n",
       "          [-1.49027541e-01, -1.55623863e-02, -3.92580628e-02, ...,\n",
       "           -6.85799494e-03, -4.71439101e-02,  9.48352274e-03]]]],\n",
       "       dtype=float32),\n",
       " array([-0.09694838, -0.05157317, -0.07338639, -0.05565591, -0.08366968,\n",
       "        -0.07190955, -0.0545391 , -0.05863427, -0.0850453 , -0.05935574,\n",
       "        -0.09112207, -0.10194582, -0.12940875, -0.07130769, -0.06125177,\n",
       "        -0.13781738, -0.10126599, -0.02119757, -0.04547379, -0.10027882,\n",
       "        -0.08104196, -0.07133006, -0.07534061, -0.05698267, -0.03479903,\n",
       "        -0.13430603, -0.03786274, -0.12320075, -0.07480384, -0.05099799,\n",
       "        -0.07897887, -0.08410556, -0.1436378 , -0.09549174, -0.06401521,\n",
       "        -0.0142027 , -0.06423742, -0.02943965, -0.05207774, -0.02483124,\n",
       "        -0.10561975, -0.11270699, -0.07630953, -0.10019591, -0.1750403 ,\n",
       "        -0.08783308, -0.11400133, -0.01238205, -0.08121894, -0.05731985,\n",
       "        -0.09159215, -0.07247627, -0.07057428, -0.10318158, -0.03946429,\n",
       "        -0.08445992, -0.11487701, -0.01878141, -0.09181547, -0.11133599,\n",
       "        -0.14340445, -0.12705354, -0.02445674, -0.07959316], dtype=float32),\n",
       " array([[ 1.57270338e-02,  1.15088973e-04,  4.93336059e-02, ...,\n",
       "          5.77147081e-02, -4.18493338e-02, -4.31327000e-02],\n",
       "        [-2.74271220e-02,  4.83142808e-02, -5.70547022e-02, ...,\n",
       "          8.92912745e-02, -7.42671825e-03, -4.73293401e-02],\n",
       "        [-2.03210935e-02, -3.53172719e-02,  2.45732255e-02, ...,\n",
       "          4.18558456e-02, -2.93858442e-02,  4.94758552e-03],\n",
       "        ...,\n",
       "        [ 1.21684186e-02,  2.24202145e-02, -1.99869904e-03, ...,\n",
       "         -1.24509111e-02,  1.08627025e-02,  1.86023619e-02],\n",
       "        [ 1.79605782e-02, -7.22058564e-02, -1.72462091e-02, ...,\n",
       "         -4.09844751e-03,  1.61821675e-02, -5.78209013e-02],\n",
       "        [-3.50356065e-02,  3.48969512e-02, -1.32761106e-01, ...,\n",
       "          5.76480590e-02,  3.71595398e-02, -4.60737422e-02]], dtype=float32),\n",
       " array([-1.66299231e-02, -4.78032157e-02,  8.18432942e-02, -1.38196722e-02,\n",
       "        -6.33515418e-02, -2.15554237e-02, -2.53538508e-02, -7.02998266e-02,\n",
       "        -2.76643857e-02, -8.75314325e-03,  1.83233507e-02,  9.38703418e-02,\n",
       "        -3.66566442e-02, -4.24520951e-03, -4.24616821e-02, -2.38173138e-02,\n",
       "        -3.56163643e-02, -2.59478968e-02, -1.00898677e-02,  1.40226632e-02,\n",
       "         1.01081086e-02, -4.26896624e-02, -6.31110817e-02, -1.20736156e-02,\n",
       "        -5.64290211e-02, -1.28413871e-01, -3.21713537e-02,  8.19105469e-03,\n",
       "        -9.08690691e-02, -3.68692875e-02, -5.46883121e-02, -7.98412971e-03,\n",
       "        -3.63924131e-02, -2.04411112e-02,  2.61543016e-03, -3.03734597e-02,\n",
       "         4.10847478e-02, -9.20700654e-02, -8.11552182e-02, -3.43323760e-02,\n",
       "        -1.30201787e-01, -1.84262060e-02, -1.20898843e-01, -7.29302987e-02,\n",
       "        -4.49669212e-02,  8.21646750e-02,  2.18675919e-02, -7.25161750e-03,\n",
       "        -2.83090807e-02,  1.29549019e-02, -6.62996545e-02, -2.35516541e-02,\n",
       "        -5.37843183e-02, -2.69727744e-02, -3.74810211e-02, -5.17190360e-02,\n",
       "        -3.44068632e-02, -5.98413795e-02,  2.51469109e-02, -7.10533932e-02,\n",
       "        -7.07386807e-02, -1.40384594e-02,  2.09108908e-02, -3.13956626e-02,\n",
       "        -4.02632207e-02, -9.95519012e-02, -6.80163279e-02, -2.79599484e-02,\n",
       "         5.76938801e-02,  2.26685107e-02, -1.14995968e-02,  8.98943935e-03,\n",
       "        -6.07867017e-02, -7.98354894e-02, -4.22691479e-02, -5.30809872e-02,\n",
       "         2.56643035e-02, -6.06035814e-02, -6.22265227e-02, -1.98752750e-02,\n",
       "        -1.69194452e-02, -6.21776842e-02, -3.36166918e-02, -3.61599661e-02,\n",
       "        -4.93942536e-02, -3.50786112e-02, -2.31561400e-02, -7.27421865e-02,\n",
       "        -6.97532743e-02, -6.88573271e-02, -1.28382686e-04, -1.42038846e-02,\n",
       "        -3.07930801e-02, -4.21912372e-02, -5.02927341e-02,  8.19934811e-03,\n",
       "        -1.39672458e-02, -1.05564259e-01, -6.81299269e-02, -1.71915200e-02,\n",
       "        -6.42388985e-02, -1.96677335e-02,  9.67573468e-03, -1.36168050e-02,\n",
       "         3.96989174e-02, -4.45118658e-02, -1.06143299e-02, -3.65030095e-02,\n",
       "        -2.91655632e-03, -5.91158345e-02, -2.63728239e-02, -7.90919811e-02,\n",
       "        -1.76413991e-02, -1.02779055e-02,  1.48467980e-02, -3.27442326e-02,\n",
       "        -4.97336239e-02, -9.19443928e-03,  4.33685910e-03, -1.48525666e-02,\n",
       "        -1.73723307e-02, -4.81175259e-02, -2.00717803e-02, -8.25891122e-02,\n",
       "        -3.35054658e-02, -1.95416175e-02, -2.96198316e-02,  7.56104887e-02],\n",
       "       dtype=float32),\n",
       " array([[-0.16069989,  0.01127611,  0.07084607, ..., -0.01893693,\n",
       "         -0.08036902,  0.06941979],\n",
       "        [ 0.1376171 ,  0.03710471,  0.18563172, ..., -0.0906333 ,\n",
       "          0.01967683, -0.0096534 ],\n",
       "        [-0.19470935,  0.13205004,  0.14166613, ...,  0.08990118,\n",
       "          0.12600651, -0.01802   ],\n",
       "        ...,\n",
       "        [-0.09652067,  0.08617333, -0.04482067, ...,  0.19027339,\n",
       "          0.08218378, -0.08559268],\n",
       "        [-0.04372913, -0.06949026, -0.09783581, ...,  0.05248255,\n",
       "         -0.15522371, -0.13101588],\n",
       "        [-0.00702411, -0.07551178, -0.13098648, ..., -0.13001296,\n",
       "         -0.13724576,  0.06515772]], dtype=float32),\n",
       " array([-0.02982577, -0.01616251,  0.05154095, -0.04316918, -0.05932702,\n",
       "        -0.03817615, -0.02517262,  0.00885085, -0.01000763, -0.02583515,\n",
       "        -0.03760894, -0.03554542,  0.05019009, -0.0581456 , -0.02920279,\n",
       "        -0.02073605, -0.0611865 , -0.02420655,  0.02436764, -0.04244864,\n",
       "         0.01863821, -0.03876187, -0.03518309, -0.06994918,  0.0112733 ,\n",
       "         0.02039469, -0.01446071, -0.01912428,  0.01833502, -0.0055478 ,\n",
       "        -0.03117037, -0.04927616, -0.04652501,  0.00957499, -0.04994704,\n",
       "        -0.04973517,  0.01068083, -0.03859653, -0.02352689, -0.0307709 ,\n",
       "        -0.04245624, -0.01825728,  0.04055122, -0.00668677, -0.01023413,\n",
       "         0.00419809, -0.00757846, -0.04236663, -0.05558592, -0.05418874,\n",
       "         0.0034289 ,  0.0229248 , -0.06335903, -0.04770842,  0.0095236 ,\n",
       "        -0.00646592, -0.02566383, -0.04459333, -0.04933389,  0.03480628,\n",
       "        -0.06459369,  0.02481799,  0.0164461 ,  0.0158848 ], dtype=float32),\n",
       " array([[-0.06217498,  0.14026128,  0.20957026, ...,  0.04212422,\n",
       "          0.02419296, -0.13429624],\n",
       "        [ 0.12986797, -0.1016594 , -0.07003102, ..., -0.00888965,\n",
       "         -0.05459081, -0.27047354],\n",
       "        [-0.2181558 ,  0.10138176,  0.03340915, ..., -0.1717187 ,\n",
       "          0.19108772, -0.04698732],\n",
       "        ...,\n",
       "        [ 0.20443921,  0.14845464, -0.18318303, ..., -0.15823314,\n",
       "         -0.14535221,  0.14214554],\n",
       "        [-0.20036954,  0.15065973, -0.05548367, ..., -0.13932763,\n",
       "          0.25865868, -0.12782496],\n",
       "        [ 0.16578637,  0.10938226, -0.21679097, ..., -0.11502334,\n",
       "          0.06525112,  0.072203  ]], dtype=float32),\n",
       " array([-0.01739683, -0.06850409, -0.05379515,  0.06883742, -0.02891578,\n",
       "         0.08034082,  0.0039405 , -0.01327065,  0.01132237, -0.06625386,\n",
       "        -0.01822014,  0.02958813, -0.00627818, -0.00629887,  0.01156176,\n",
       "        -0.07813716, -0.05978752,  0.03360629, -0.06038691, -0.04304173,\n",
       "         0.00730002, -0.01652037,  0.03108   ,  0.04530059, -0.04537207,\n",
       "        -0.05676345,  0.04071768, -0.0250683 , -0.00275783, -0.03016289,\n",
       "        -0.01057076, -0.00859716], dtype=float32),\n",
       " array([[-0.12734741, -0.14334199, -0.03180434, ...,  0.00613238,\n",
       "          0.27093706,  0.2605528 ],\n",
       "        [ 0.13846898,  0.09624873,  0.18847996, ..., -0.23490803,\n",
       "          0.13833342,  0.20301114],\n",
       "        [ 0.16391149,  0.17678438, -0.08105294, ...,  0.32922986,\n",
       "          0.03690829,  0.15984634],\n",
       "        ...,\n",
       "        [ 0.16322087,  0.07963515, -0.19012217, ...,  0.13428643,\n",
       "          0.36364353, -0.05937631],\n",
       "        [-0.08507928,  0.03313982, -0.13959186, ..., -0.154052  ,\n",
       "         -0.2577777 ,  0.04482433],\n",
       "        [ 0.08261498, -0.27754733,  0.09118851, ...,  0.05011739,\n",
       "         -0.0081185 , -0.07012691]], dtype=float32),\n",
       " array([-0.09110096,  0.0381559 ,  0.02441081, -0.01448834, -0.03763887,\n",
       "        -0.06221492, -0.13485758,  0.06879219, -0.08434395, -0.13039774,\n",
       "        -0.10838717, -0.05268683, -0.13327424, -0.04467667, -0.04232995,\n",
       "        -0.00403182,  0.08492272, -0.0392336 , -0.07661282, -0.13194066,\n",
       "        -0.05056434, -0.14713502, -0.06504162, -0.14534955, -0.05006934,\n",
       "        -0.06287672,  0.02320346, -0.17027642, -0.11311468,  0.00607704,\n",
       "        -0.12392569, -0.01713101], dtype=float32),\n",
       " array([[ 0.38951495, -0.5856999 ,  0.08068263,  0.2160251 ,  0.1911765 ,\n",
       "         -0.16246149, -0.38210446, -0.20233265,  0.20988472, -0.07608289],\n",
       "        [-0.51586705, -0.758301  , -0.49935067,  0.3254306 , -0.8063689 ,\n",
       "          0.29183307, -0.02157727, -0.27997413,  0.04773535, -0.03919887],\n",
       "        [-0.4428464 , -0.44708765,  0.27252173, -0.28345332,  0.20377244,\n",
       "         -0.4046274 , -1.0168991 , -0.33275184, -0.23795184,  0.37319103],\n",
       "        [-0.6880587 , -0.02474453,  0.04255161, -0.42494813,  0.33009943,\n",
       "          0.3012089 , -0.07837856,  0.2786415 , -0.1740506 ,  0.08947186],\n",
       "        [-0.40030187,  0.09968198,  0.1128656 ,  0.18284047,  0.26965535,\n",
       "         -0.2795213 , -0.37553802,  0.20368913,  0.3040075 ,  0.16480535],\n",
       "        [ 0.25830042,  0.11179765, -0.31774262, -0.02068537, -0.70532626,\n",
       "          0.23991145,  0.12295296, -0.7281389 ,  0.24298309, -0.16075465],\n",
       "        [ 0.03485617,  0.05772075,  0.09820471, -0.51507294,  0.02807265,\n",
       "         -0.11476599,  0.17369317, -0.5010085 , -0.18090542, -0.63102585],\n",
       "        [-0.67935336, -0.3711493 , -0.45917532, -0.16350767, -0.8945023 ,\n",
       "          0.17535526, -0.4194795 , -0.7299589 , -0.23562044,  0.11161501],\n",
       "        [-0.21728632,  0.255255  , -0.1867227 ,  0.18325554, -0.19028763,\n",
       "         -0.15985523, -0.04479229, -0.579866  ,  0.3287496 , -0.22639345],\n",
       "        [ 0.23908491,  0.1720449 , -0.39073366, -0.8203811 , -0.5603096 ,\n",
       "         -0.4959996 , -0.12070584, -0.03892118, -0.47650814, -0.08506003],\n",
       "        [ 0.06454713,  0.2943731 ,  0.22094382, -0.25109196, -0.31154537,\n",
       "         -0.4755006 , -0.67921966, -0.22762612, -0.2758406 , -0.15733035],\n",
       "        [-0.4488504 ,  0.2101686 , -0.3123661 ,  0.2733626 , -0.3460054 ,\n",
       "          0.18289916, -0.32356524,  0.08976306,  0.06588314, -0.15658155],\n",
       "        [-0.66682476,  0.23600826,  0.15214415,  0.1368964 , -0.20318913,\n",
       "         -0.50947344, -0.0227635 ,  0.04429819, -0.31138343, -0.40003142],\n",
       "        [-0.58293116, -0.43521026, -0.6888639 ,  0.26928762,  0.21231288,\n",
       "          0.28265738, -0.11971441,  0.09278186, -0.35316017,  0.00782337],\n",
       "        [-0.60272175,  0.18676497, -0.62071395, -0.39307344,  0.21710928,\n",
       "          0.07805733, -0.28158802, -0.2639771 , -0.20862754,  0.15900713],\n",
       "        [-0.8822817 ,  0.08513529, -0.22558104, -0.35759652,  0.18228695,\n",
       "         -0.5872035 , -0.24515715,  0.23304859, -0.2345161 ,  0.252836  ],\n",
       "        [-0.40049613, -0.34302664,  0.12094458, -0.2264229 , -0.63173985,\n",
       "         -0.21096238,  0.1814915 , -0.5656745 ,  0.32128784,  0.15879402],\n",
       "        [-0.15221359, -0.14152539, -0.9710246 , -0.784599  , -0.5959705 ,\n",
       "         -0.17660718,  0.14486323, -0.297738  ,  0.05712412, -0.68576   ],\n",
       "        [-0.55075216,  0.2079692 ,  0.15855338, -0.28289056, -0.15783073,\n",
       "         -0.3794169 , -1.0014443 ,  0.22411028, -0.3413378 ,  0.03783355],\n",
       "        [-0.50260526,  0.07303984, -0.08408454, -0.30556744,  0.03633889,\n",
       "         -0.5917677 , -0.6623257 ,  0.01627235, -0.34917408, -0.18420671],\n",
       "        [ 0.00177456, -0.9044099 , -0.7464869 , -0.3678461 , -0.20416981,\n",
       "         -0.24941187,  0.21697198, -0.47788733, -0.45237786,  0.22061984],\n",
       "        [ 0.25727397, -0.30277133,  0.19132361, -0.14808147,  0.01943233,\n",
       "         -0.2371626 , -0.14148623, -0.28194293, -0.3735145 , -0.09744249],\n",
       "        [ 0.12283284, -0.4776317 ,  0.10729824, -0.15327297, -0.70939565,\n",
       "         -0.77003556, -0.24548173,  0.04104146,  0.02294696, -0.27349246],\n",
       "        [ 0.26691437, -0.7744603 , -0.05170497, -0.23253185,  0.00225668,\n",
       "         -0.4848263 ,  0.21017972,  0.19001326, -0.25255102, -0.1535206 ],\n",
       "        [-0.18325928, -0.26061973, -0.6238007 , -0.22370782,  0.05039711,\n",
       "          0.29069665,  0.3222114 ,  0.2692136 ,  0.08758016, -0.17209628],\n",
       "        [-0.611077  , -0.5163097 ,  0.00616633,  0.15116037, -0.44403   ,\n",
       "          0.00196173,  0.2132409 , -0.5978441 , -0.29191086, -0.806295  ],\n",
       "        [-0.48223945, -0.2648803 ,  0.11942753, -0.03866314,  0.13101336,\n",
       "         -0.03034318, -0.08375977, -0.5000677 ,  0.20188051, -0.27437133],\n",
       "        [-0.38181555, -0.53825456,  0.1036438 ,  0.09722708, -0.4961938 ,\n",
       "          0.22239225,  0.28660738, -0.06360809, -0.27892956,  0.15683067],\n",
       "        [-0.40288785, -0.5091255 , -0.36069   , -0.3228091 , -0.30627522,\n",
       "          0.2545479 , -0.57011384,  0.29219022,  0.0195374 ,  0.28637314],\n",
       "        [ 0.17625031, -0.32122478, -0.51191616, -0.29629195,  0.03922869,\n",
       "         -0.7465456 , -0.5063158 ,  0.011016  ,  0.10493875,  0.15227634],\n",
       "        [-0.43085623, -0.09352579,  0.23519088,  0.23067246, -0.54285973,\n",
       "         -0.13542455, -0.5989857 ,  0.24216747, -0.14125893, -0.18004449],\n",
       "        [-0.4370192 , -0.43373236, -0.46104893, -0.01409706,  0.1782915 ,\n",
       "         -0.50463724, -0.8572632 , -0.66974914, -0.4610993 ,  0.21171468]],\n",
       "       dtype=float32),\n",
       " array([-0.06815377, -0.1668891 , -0.19281945, -0.11303585, -0.07334515,\n",
       "         0.03687704, -0.08104765, -0.04253238,  0.28019124,  0.0859989 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重みの所得\n",
    "model4.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# accracy可視化\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#loss可視化\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#　valが最初から高いので過学習気味か？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】（アドバンス課題）PyTorchへの書き換え\n",
    "4種類の問題をPyTorchに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
