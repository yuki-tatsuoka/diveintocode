{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】公式チュートリアルモデルを分担して実行\n",
    "TensorFLowの公式チュートリアルモデルを分担して実行してください。\n",
    "\n",
    "\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。\n",
    "\n",
    "\n",
    "models/tutorials at master · tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vecを採用\n",
    "# ここからword2vecのドキュメントコードになります。\n",
    "import io\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dot, Embedding, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 \n",
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The wide road shimmered in the hot sun\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'the': 1, 'wide': 2, 'road': 3, 'shimmered': 4, 'in': 5, 'hot': 6, 'sun': 7}\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "# トークンから整数インデックスへのマッピングを保存するための語彙を作成\n",
    "\n",
    "vocab, index = {}, 1 # start indexing from 1\n",
    "vocab['<pad>'] = 0 # add a padding token \n",
    "\n",
    "for token in tokens:\n",
    "    if token not in vocab: \n",
    "        vocab[token] = index\n",
    "        index += 1\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'the', 2: 'wide', 3: 'road', 4: 'shimmered', 5: 'in', 6: 'hot', 7: 'sun'}\n"
     ]
    }
   ],
   "source": [
    "# dictの順番を入れ替える\n",
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "print(inverse_vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 1, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 文章をベクトル化\n",
    "example_sequence = [vocab[word] for word in tokens]\n",
    "print(example_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 6],\n",
       " [2, 3],\n",
       " [5, 3],\n",
       " [6, 7],\n",
       " [3, 5],\n",
       " [4, 1],\n",
       " [2, 4],\n",
       " [1, 4],\n",
       " [6, 1],\n",
       " [1, 2],\n",
       " [1, 7],\n",
       " [3, 1],\n",
       " [4, 5],\n",
       " [5, 1],\n",
       " [7, 1],\n",
       " [3, 4],\n",
       " [5, 6],\n",
       " [4, 2],\n",
       " [1, 5],\n",
       " [3, 2],\n",
       " [2, 1],\n",
       " [7, 6],\n",
       " [5, 4],\n",
       " [4, 3],\n",
       " [6, 5],\n",
       " [1, 3]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スキップグラムを生成する\n",
    "# Word2Vecのデータ準備を簡素化する便利な関数を提供します。\n",
    "# スキップぐらむは全てのベクトルの組み合わせを出力している\n",
    "\n",
    "window_size = 2\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      example_sequence, \n",
    "      vocabulary_size=vocab_size, # 文章のトータルの長さ\n",
    "      window_size=window_size, # 前後のコンテキストの数\n",
    "      negative_samples=0, # ネガティブサンプリングの数\n",
    "    shuffle=True) # ドロップアウト\n",
    "print(len(positive_skip_grams))\n",
    "\n",
    "positive_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6): (the, hot)\n",
      "(2, 3): (wide, road)\n",
      "(5, 3): (in, road)\n",
      "(6, 7): (hot, sun)\n",
      "(3, 5): (road, in)\n"
     ]
    }
   ],
   "source": [
    "# 例(さっきの奴を表示している)\n",
    "for target, context in positive_skip_grams[:5]:\n",
    "    print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 1 4 3], shape=(4,), dtype=int64)\n",
      "['wide', 'the', 'shimmered', 'road']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[6]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スキップぐらむからtarget、contex-wordを抽出\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "# ネガティブサンプリングの数\n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class, # ポジティブクラス全体\n",
    "    num_true=1, # ポジティブクラスの数？\n",
    "    num_sampled=num_ns, # ネガティブサンプリングの数\n",
    "    unique=True, # all the negative samples should be unique\n",
    "    range_max=vocab_size, # 持ってくる特徴量の範囲\n",
    "    seed=SEED, \n",
    "    name=\"negative_sampling\" \n",
    ")\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])\n",
    "\n",
    "#tf.constant(context_word, dtype=\"int64\")\n",
    "#tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "context_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング例\n",
    "# 次元を増やす\n",
    "negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
    "\n",
    "# ポジティブワードとネガティブワードを合体させる\n",
    "context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "# ラベルの作成\n",
    "label = tf.constant([1] + [0]*num_ns, dtype=\"int64\") \n",
    "\n",
    "# 次元を潰す\n",
    "target = tf.squeeze(target_word)\n",
    "context = tf.squeeze(context)\n",
    "label =  tf.squeeze(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_index    : 1\n",
      "target_word     : the\n",
      "context_indices : [6 2 1 4 3]\n",
      "context_words   : ['hot', 'wide', 'the', 'shimmered', 'road']\n",
      "label           : [1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# labelの確認\n",
    "print(f\"target_index    : {target}\")\n",
    "print(f\"target_word     : {inverse_vocab[target_word]}\")\n",
    "print(f\"context_indices : {context}\")\n",
    "print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n",
    "print(f\"label           : {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target  : tf.Tensor(1, shape=(), dtype=int32)\n",
      "context : tf.Tensor([6 2 1 4 3], shape=(5,), dtype=int64)\n",
      "label   : tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# スキップグラムネガティブサンプリングWord2Vecモデルをトレーニングする\n",
    "print(f\"target  :\", target)\n",
    "print(f\"context :\", context )\n",
    "print(f\"label   :\", label )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
      " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
     ]
    }
   ],
   "source": [
    "# 単語頻度ランクベースの確率的サンプリングテーブルを生成\n",
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
    "print(sampling_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータを生成する\n",
    "\n",
    "# スキップグラムとネガティブサンプリングのペアをシーケンスに与える\n",
    "# ウィンドウズサイズは負のサンプルに基づく\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "    targets, contexts, labels = [], [], []\n",
    "    # vocab_sizeトークンのサンプリングテーブルを作成\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "    \n",
    "    # データセット内のすべてのシーケンス(文)に反復\n",
    "    for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "    # シーケンス(文)の正のスキップグラムペアを生成します。.\n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "            sequence, \n",
    "            vocabulary_size=vocab_size,\n",
    "            sampling_table=sampling_table,\n",
    "            window_size=window_size,\n",
    "            negative_samples=0)\n",
    "\n",
    "    # トレーニング例を作成するために、各ポジティブスキップグラムペアを反復します。 \n",
    "    # 正のコンテキストワードと負のサンプル。.\n",
    "        for target_word, context_word in positive_skip_grams:\n",
    "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                true_classes=context_class,\n",
    "                num_true=1,\n",
    "                num_sampled=num_ns, \n",
    "                unique=True, \n",
    "                range_max=vocab_size, \n",
    "                seed=SEED, \n",
    "                name=\"negative_sampling\")\n",
    "\n",
    "      # コンテキストを作成し、ベクトルにラベルを付けます(1つのターゲットワード)\n",
    "            negative_sampling_candidates = tf.expand_dims(negative_sampling_candidates, 1)\n",
    "\n",
    "            context = tf.concat([context_class, negative_sampling_candidates], 0)\n",
    "            label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
    "\n",
    "      # トレーニングの例からグローバルリストに各要素を追加します。.\n",
    "            targets.append(target_word)\n",
    "            contexts.append(context)\n",
    "            labels.append(label)\n",
    "    return targets, contexts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コーパスのDL\n",
    "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n"
     ]
    }
   ],
   "source": [
    "# コーパスの文章\n",
    "with open(path_to_file) as f: \n",
    "    lines = f.read().splitlines()\n",
    "for line in lines[:20]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FilterDataset shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ベクトル化のためにDatasetへ変換\n",
    "text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))\n",
    "text_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コーパスから文をベクトル化する\n",
    "# カスタム標準化機能を作成して、テキストを下げます。 \n",
    "# 句読点の削除\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    return tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation), '')\n",
    "\n",
    "# サイズと単語数を順番に定義します。.\n",
    "vocab_size = 4096\n",
    "sequence_length = 10\n",
    "\n",
    "# テキストベクトル化レイヤーを使用して、文字列を正規化、分割、およびマップします。\n",
    "#整数、output_sequence_length lengthを設定して、すべてのサンプルを同じ長さにパッドします。.\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization, # 正規化\n",
    "    max_tokens=vocab_size, # 語彙の最大値\n",
    "    output_mode='int', \n",
    "    output_sequence_length=sequence_length) # 出力する文章の長さ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストデータセットでadaptを呼び出して、語彙を作成します。\n",
    "vectorize_layer.adapt(text_ds.batch(1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a', 'that', 'in', 'is', 'not', 'for', 'with', 'me', 'it', 'be', 'your']\n"
     ]
    }
   ],
   "source": [
    "# 語彙にアクセス\n",
    "# 参照用に作成したボキャブラリーを保存します。.\n",
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトル生成\n",
    "def vectorize_text(text):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return tf.squeeze(vectorize_layer(text))\n",
    "\n",
    "# text_dsでデータを修正します。.\n",
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([138,  36, 982, 144, 673, 125,  16, 106,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([106, 106,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   7,   41,   34, 1286,  344,    4,  200,   64,    4, 3690]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([1286, 1286,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  89,    7,   93, 1187,  225,   12, 2442,  592,    4,    2]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  36, 2655,   36, 2655,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  72,   79,  506,   27,    3,   56,   24, 1390,   57,   40]),\n",
       " array([644,   9,   1,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  32,   54, 2863,  885,   72,   17,   18,  163,  146,  146]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 74, 218,  46, 595,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,   41,    1,  172,  595,    2, 1780,   46,    0,    0]),\n",
       " array([  29, 1323,    1,   47,   58,    1,   79,   39,   60,    0]),\n",
       " array([ 58, 573,  79,  22,   2,   1, 334,  17,  76,   0]),\n",
       " array([1870,   36,  258, 1026,   60,    1,   79,    1,    0,    0]),\n",
       " array([ 22,  60, 131,  36,  41, 100, 267,   2,   1,  10]),\n",
       " array([   1,   79,    2, 2346,    6,   40, 1540,   12,   25,   88]),\n",
       " array([ 1,  4,  1, 65,  1, 40,  0,  0,  0,  0]),\n",
       " array([2871,   12,    9, 1375,    4,   66,   72,   79,  625,   21]),\n",
       " array([ 40,   1, 251,  36, 662,   1,  14,   2, 260,  93]),\n",
       " array([ 106,   21,   11,    1,   14, 2461,   13,   11, 3329,   14]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  58,    7,  982, 3696,  170, 1187,  225,    0,    0,    0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 170,   27,   89,  339,    9,  157, 1033,    4,    2,    1]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1834,    7,   29, 1519,   23,  320,  163,   14,   20,  659]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([157,  56,   3, 231,  18, 496,   4, 102,  27,  46]),\n",
       " array([ 556, 1169,   22,   10,   23, 3500,  245,   15,  145,  450]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([181,  22, 106,  13,   1,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  71, 214,   7,  29,  23,  70, 163,   1,  23]),\n",
       " array([ 17,   4,  10, 384, 171,   1, 153, 115,  18,   0]),\n",
       " array([496,   4,  71,  17,  59,  14,  20, 659,  23,  95]),\n",
       " array([ 303,   20,  223,    3,    4,   18, 1781,  450,   53,   23]),\n",
       " array([ 12, 196, 184,   2,   1,   6,  20, 638,   0,   0]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  29,   23,  142,  309,   11,   20,  408,    7, 1199,    9]),\n",
       " array([1206,   11,   27,    7,   86,   11,   32,  177,   71,   23]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  39,    5,   86,   13,    5,  451,   13,   18, 2022,    6]),\n",
       " array([  23,   70,  742,   15,    1,    4, 3322,   11, 3431,    0]),\n",
       " array([  29, 4083,   41,  104,    2,  205,  649,   48,    2,  445]),\n",
       " array([  12,    1,   90,  188,   36, 2956,   62,    4,    2, 1319]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([49, 49,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([752, 103, 194,  62,   0,   0,   0,   0,   0,   0]),\n",
       " array([165, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 446,  154,    1,   74,   10,   70, 1196,  712,    0,    0]),\n",
       " array([  2, 307,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([339,  74, 605, 394,  58,  34,   2, 257,  76,  28]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  29,    1,    8, 2208,   11,  158,   97,   75,    7,    0]),\n",
       " array([ 15,   1,   3,   1,   2, 390, 106,   5, 160,   7]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  40,  388,   12,   13, 1504,    4,    2, 1520,   60,   24]),\n",
       " array([  92,    1,   21,    1,   29,   36, 1368,    4,   42,    0]),\n",
       " array([ 53,  44,  56, 315, 847,  11, 780,  60,  71, 172]),\n",
       " array([2089,   24,  751,    1,   60,   37,   93,   36,    0,    0]),\n",
       " array([ 24, 751, 395, 100,   0,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  90,  628,    8,   46,  208,  109,  605, 1942,    0,    0]),\n",
       " array([  31,    7, 2840,  969,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,  142,   51,   36,   41, 1268,  702,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5, 117,   7, 208, 120,   1, 497,   0,   0,   0]),\n",
       " array([  24,    2, 1780,    6,    7,   14,   19, 1610,    0,    0]),\n",
       " array([  19, 2870,   11,   21, 3136,    7,   78,   25,   56,    0]),\n",
       " array([ 537,   57,    2,  182,   15,   19,    1,   25, 1954,   66]),\n",
       " array([170,   2, 820, 329, 202, 690,  31,  47,   0,   0]),\n",
       " array([   2,  177,   17, 1623, 3150,  610,  352,    1,    0,    0]),\n",
       " array([  6,  54, 751,   1,   1,  64, 115, 195,   0,   0]),\n",
       " array([ 787,   11,   19, 3612,   14,    2, 3136,    0,    0,    0]),\n",
       " array([   2,  260,   13,    2, 1780,   80,   17,    3,    0,    0]),\n",
       " array([ 19, 987,   4,  66,  13, 395,  86, 309, 833,   0]),\n",
       " array([   7,   41, 3314,   33, 3193,    0,    0,    0,    0,    0]),\n",
       " array([ 770,   97,   54,    1,    7,    3,    7, 1346,    0,    0]),\n",
       " array([  2,   1,  48,   2, 329, 103, 497,  14,   7,  84]),\n",
       " array([ 73,   7, 699,  66,  25, 658,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([497,  14,  79, 139, 310,  60, 439,   1,  14,  79]),\n",
       " array([  82, 1052,   79,    4, 3690,    3,   65,    1,    0,    0]),\n",
       " array([   1,   15, 2402,   80,    1,   14,    1,    4,    0,    0]),\n",
       " array([3347,    1, 3432, 1830,  144, 1870,  968,    0,    0,    0]),\n",
       " array([   1,  170,    2,  683,    3, 2322,   54,    0,    0,    0]),\n",
       " array([2336, 2883, 1830,    4,    1,  111,    3,    1,    0,    0]),\n",
       " array([   2,  172,   39,    2,  664, 1126,   79,   13,  111,   60]),\n",
       " array([413,  34,   2,  77,  60, 203,  79,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([478,   7,  86,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 691,  969, 1729,    1,    0,    0,    0,    0,    0,    0]),\n",
       " array([  52,   18, 1861,    6, 1696,    5,   37,  117,    7,    0]),\n",
       " array([  9, 798, 639,  17,  78,  18,   7,  24, 311,  17]),\n",
       " array([  22,  228,   17, 1636,    8,  502,    5,   31, 2834,    0]),\n",
       " array([   4, 2279,  818,    9,  234,   54,    0,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 56,  67, 125,  17,  51,  82,   7,  86,  13, 131]),\n",
       " array([   1,  219,   40, 1991,   15,    9,  639,   22,   88,  818]),\n",
       " array([  7, 959,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  85,   59,    9,  118,   73,   34,    2, 1842, 2636,    0]),\n",
       " array([   1,  170,    2, 1490,  141, 1861,   17,    0,    0,    0]),\n",
       " array([  10,  337,   84,    9, 3643,   17,   95, 1016,    0,    0]),\n",
       " array([   5,    2, 3002,   48,    2,  407, 1119,    3,    1,    0]),\n",
       " array([ 227,    1,    2,    1,  134, 1597,    0,    0,    0,    0]),\n",
       " array([  84, 1072,   15,    2,  257,   97,    2,  205, 1681,    0]),\n",
       " array([  95,   98,    3,  125, 1384, 1683, 1007,  808,    0,    0]),\n",
       " array([   3,    1,    1,   95, 1670,    0,    0,    0,    0,    0]),\n",
       " array([ 214,    2, 2031,    3, 1198,  572,    0,    0,    0,    0]),\n",
       " array([   6,    2, 1329,  407,    2, 1490, 2481,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  56,   51,   29,  351,  128,    2, 1490,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  51,    5,   37,  117,    7,   15,    9,  409,    6, 1058]),\n",
       " array([  53,  439,  285,   50,    2, 3566,   22,  196,  141,    0]),\n",
       " array([  14,  155,    7,    5,   78,   80,    2, 1490, 1058,    0]),\n",
       " array([  25,   56,   25,    1,    1, 3430,    0,    0,    0,    0]),\n",
       " array([   4,    2, 2722, 2636,    2, 2628, 1363,    0,    0,    0]),\n",
       " array([ 10,   1,  20,   1, 196,  28, 120,   1,   0,   0]),\n",
       " array([  25,    7,    1,   40, 1281,   14,   10,    0,    0,    0]),\n",
       " array([ 60,  41,  13, 110,  25,   7,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 19,   1, 351,  29,   0,   0,   0,   0,   0,   0]),\n",
       " array([  2,   1, 210,   2,   1, 349,   0,   0,   0,   0]),\n",
       " array([   2, 3154,  133,    2,  596,   40,  733,    0,    0,    0]),\n",
       " array([  40, 2881,    2, 3036,    2,  266,   40,    1,    0,    0]),\n",
       " array([  15,  205,    1,    3, 2611, 2675,    0,    0,    0,    0]),\n",
       " array([11, 21, 40,  1, 39, 10, 60,  0,  0,  0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([29, 55,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([1814,   16,   21,  383,  910,   29,   55,   29,   55,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  87,   33,    2,    1, 1490,   18,    1,    0,    0,    0]),\n",
       " array([ 103,   12,    2, 1631,   48,    2,  407,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([56, 29, 55,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2, 1306,    1,   39,   60,   95, 2004,    0,    0,    0]),\n",
       " array([  29,  231,    2, 1490,  351,    0,    0,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  31, 117,   7,   0,   0,   0,   0,   0,   0]),\n",
       " array([  39,  585, 3820,    9,    1,   29,    7,   24,  234,    0]),\n",
       " array([601, 850, 585, 125,   2,   1, 351,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([3258,  244,  301,   17,    0,    0,    0,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([887,  16,  21,  46, 328,   0,   0,   0,   0,   0]),\n",
       " array([  19,  120,  392, 1490,   59,    1,    0,    0,    0,    0]),\n",
       " array([  13, 1920,   84,   20,    1,    3,  141, 2481,    0,    0]),\n",
       " array([ 139,   12,   17,    8,    1,  208, 1017,   23,    0,    0]),\n",
       " array([  10,    5, 1218,    2,  580, 1978,   57,   89,    0,    0]),\n",
       " array([ 53,   7,  42, 189,  81,   3, 741,  17,  12,   0]),\n",
       " array([ 471,    5,   69,    2,    1,    3,    2, 2561,    0,    0]),\n",
       " array([   6,    2, 1329,  407,   22,   39,    7,   42,  532,    0]),\n",
       " array([  5, 415,  17, 473,   2, 531,   6,  19, 147,   0]),\n",
       " array([196,   4,   2, 675,   2, 133,   4,   2, 979,  48]),\n",
       " array([   3,  473,    2,    1,    3, 2343,    6,   94,    0,    0]),\n",
       " array([   2,    1,    1,    3,  882, 3604, 1736,    0,    0,    0]),\n",
       " array([  50,   16, 1218,   10, 1538,    1,    0,    0,    0,    0]),\n",
       " array([3891,   60,  189,    3,  171,   10,   34,   57,  240,    0]),\n",
       " array([   7,    8,   46,    1,  500,    2, 1490,  543,   16,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([137,  51,  56,  56,   0,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([171,  34,  57, 240, 142,   0,   0,   0,   0,   0]),\n",
       " array([ 98,  29,   5,  42, 959, 112,   4, 524,   0,   0]),\n",
       " array([ 82,   5, 115,  80,   8,   1, 111,  10,  34,   0]),\n",
       " array([  50,   16,   42,  300, 1218,    2,    1,    6,   34,    0]),\n",
       " array([  3, 168,  16,  22,   2,   1,  29,  71,   7, 817]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  17,   59,   88,  351,   61, 3845,    7,   21,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2, 1281,    6,  302,   41,   21,   46, 1490,    0,    0]),\n",
       " array([   3,    7,    2, 2628, 2636,   14,    1,    0,    0,    0]),\n",
       " array([  65, 2742,    3,   65, 1318, 3723,  389,    1,    0,    0]),\n",
       " array([2525,    2, 3279,   48,    2,  572,    7,   37,  281,    0]),\n",
       " array([  32, 2118, 1396,   53,    7, 1218,    0,    0,    0,    0]),\n",
       " array([ 22,  17,   1,  52, 194,  50,  66,   4,   7,   0]),\n",
       " array([  3,  32, 177,  50, 969,  29,  42,   7, 131,   0]),\n",
       " array([   7,    2,  169, 3320,    6,   21,    1,    0,    0,    0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,    2,  169, 3320,   90,    2,  169, 3320,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 14,  10, 145,  74,  48,   2,   1,   1,   1,   0]),\n",
       " array([   6,   21,  120,  790, 2115,   26, 3649,    1,    0,    0]),\n",
       " array([  26, 1921,   10,  129,  852,   11,  147,    4,  682,    0]),\n",
       " array([   1,   89,    4,  766,   99, 1331,    0,    0,    0,    0]),\n",
       " array([  22,   80,    7,  501,   19, 2879,    1,    3,    1,    0]),\n",
       " array([ 302,    3,   38, 3447,   41,   57,    2,  626,    6,  786]),\n",
       " array([  2,  74, 649,  86,  24,   1,   0,   0,   0,   0]),\n",
       " array([1454,  152,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([527, 327,   2, 390,   7,   1,   1,   0,   0,   0]),\n",
       " array([  10,    1,    2,  172,    1,    6,   19, 1440,    0,    0]),\n",
       " array([ 80, 969,   1,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 270,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 36,  24, 195,  19,  46, 218,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,   10,   31,  102,   46,  248,    4,   43,   31, 1124]),\n",
       " array([ 1,  1, 29, 58,  7, 24,  7,  1,  0,  0]),\n",
       " array([ 10,  84, 123, 212, 123, 373,   2,  74,   1,   7]),\n",
       " array([  2, 205, 308,   7, 450,  23,  10,   1,   4,   7]),\n",
       " array([  97,   23,   87,  281,    7, 3027, 1697,    7,    1,    0]),\n",
       " array([97,  1,  1,  7, 41, 32,  1, 32,  0,  0]),\n",
       " array([  64,   12,    2,    1,    6,  477,   81,    2, 2669,    0]),\n",
       " array([ 52,   1,  11,   2, 374,  19, 638,  12,   0,   0]),\n",
       " array([  4,  80,  27, 446, 202, 886,   1,  27,   0,   0]),\n",
       " array([  3, 699,  10, 466,  95,  17,   0,   0,   0,   0]),\n",
       " array([ 103, 1472, 2174,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([1472,   19,  391,    3,   19, 1722,   41,    0,    0,    0]),\n",
       " array([   9, 1013,  775, 2031,  103, 1703,  120,   10,    0,    0]),\n",
       " array([  53,   58, 1962,   20, 1175,   23,   10,    1,    0,    0]),\n",
       " array([  81,   19, 2414,    1,   15,    1,    6,  951,    0,    0]),\n",
       " array([   3,    1,  174,    1,   15, 2922,  829,  563,  599,  563]),\n",
       " array([  15,  282, 2358,    7,   42,  661,    9,  319,    0,    0]),\n",
       " array([  3, 185,  27, 152,  10,  59,  44,  19, 391,   0]),\n",
       " array([  27, 1138,   10,   59,   19, 2176,  327,    2,  390,    0]),\n",
       " array([  10,   11,  104, 1423, 2124,    6,    2,  445,    0,    0]),\n",
       " array([   7,  535,  170,    2,  152, 1520,  103,    0,    0,    0]),\n",
       " array([480,   2, 260, 273,   7,  11,   1,  53, 252,   0]),\n",
       " array([  58, 1817,   47,   74,  356,  327,   65, 2568,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  14, 1390,   57,   65,  161,    1, 1203,   60,   71,    0]),\n",
       " array([  2, 445,  12,  56,   1,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([829, 847,  60,  71,   0,   0,   0,   0,   0,   0]),\n",
       " array([1745,  458,   33,    2,  477,    3, 2604,    4,   93,    0]),\n",
       " array([ 327,  163,    5,    2, 1319, 1202,   84,    4,  981,    0]),\n",
       " array([103,   1,   3, 103,   1, 649,   1,   0,   0,   0]),\n",
       " array([  3, 102, 112,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,    1, 1069, 2617,  751,    0,    0,    0,    0,    0]),\n",
       " array([   3,    1,  110,   25,  190,   13,   11,   65, 2372,    0]),\n",
       " array([1717,   65,    1, 2562,   60,   71,  413,    0,    0,    0]),\n",
       " array([2402,  394,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  58,    2, 2347,  362,  934,   65,    1,    0,    0,    0]),\n",
       " array([  3,  72,  16, 364,   8, 465,  67,  80,   9,   1]),\n",
       " array([  15, 2853,    6,  104,    1, 1760,   25,  467,    0,    0]),\n",
       " array([  25,    5,  231,    1,    8, 3580,    0,    0,    0,    0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([181, 104,  41, 788,   1,   1,   0,   0,   0,   0]),\n",
       " array([  14,  171,    1,   60, 1071,    1,    0,    0,    0,    0]),\n",
       " array([  82,   41,   60, 1362, 2739,   22,    5,  369,    7,    0]),\n",
       " array([  29,  500,    2,  205, 2520,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 60,  41,   1, 829, 847,   0,   0,   0,   0,   0]),\n",
       " array([  60,  279,   60,   76,    1, 3388,  284,    1,    0,    0]),\n",
       " array([  10,    1,  963, 1146, 1098,   10, 1827,   86, 1126,    0]),\n",
       " array([  10, 1160,   59,  128,   14, 1945,   10,    2,  260,  530]),\n",
       " array([1390,   14,    2,  683,  153,  337,   15,  104,    1,    0]),\n",
       " array([  60,    1,   65,    1,   53,  145, 2481,    0,    0,    0]),\n",
       " array([   3,    9, 2612, 1687,   66,    9,  517,   74,    0,    0]),\n",
       " array([  4, 488,   2, 133,   6,   1,   0,   0,   0,   0]),\n",
       " array([   3,   80,  719,  264,  155,    1, 2852,   65, 2450,    0]),\n",
       " array([ 25,  60,  58, 829,  66,  47,   2,   1,  48,   2]),\n",
       " array([ 1, 65,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  29,   12, 1687,   66,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 831,  692,    4,  927,   65, 3913,    1,    0,    0,    0]),\n",
       " array([   6,   65,  161, 1247, 1221,    1,  293,    0,    0,    0]),\n",
       " array([232,   1,   3,   5,  93,   1,   0,   0,   0,   0]),\n",
       " array([  2,   1,  87,  24,  89,   1,   2, 445,   0,   0]),\n",
       " array([ 251,   28, 2330,   15,   16,   17,   31,   11,  118,    0]),\n",
       " array([766,  81, 264,   3, 769, 284, 865,   1,   0,   0]),\n",
       " array([14,  1,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 21,  12, 517,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 75, 410,   7, 287,   7,   1,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 972, 1187,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 62, 327,   2, 390,   0,   0,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  229,   12,   51,    2, 1099,   41,   11,  395,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  69, 991,  47, 818,  55,  36,  37, 590, 433]),\n",
       " array([  40, 3530,    1,   98,   40,  262,    1,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 225,   96,  139,   10,    7,   24, 2378,  448,   79,    0]),\n",
       " array([   2, 1099,   41,   11,  395,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([60, 24,  9,  1,  0,  0,  0,  0,  0,  0]),\n",
       " array([2067,  342,   10,   31,  239,    7,    4,  818,    0,    0]),\n",
       " array([   5,  565,   11,    1,   20, 2347,    0,    0,    0,    0]),\n",
       " array([  3,  76,   5, 144, 238,  22,  29,   5,  69,   0]),\n",
       " array([  5,  58, 456,  16, 337,  23,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   7,   24, 1030,  463,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 76, 630,   4, 630,   2, 187,  33,   2, 511,   3]),\n",
       " array([  81,    8, 1155, 1229, 2306,    4,   80,    0,    0,    0]),\n",
       " array([ 337,    8,  664,   15,   27,   23,   12,    9, 1792,    0]),\n",
       " array([  10,    5,   69,  450,    4, 2160,    0,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 55, 446, 225,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([765,  81, 323,   4, 104, 664,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  17,   12,   19, 1306,  839,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([51, 17, 12,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([   3,    5,   69, 2001, 1505,  778,   26,    0,    0,    0]),\n",
       " array([ 361,   98,   16,  240,   54,  537,   57, 2067,  246,    0]),\n",
       " array([  29,  129,   26, 2879, 4041,  112,    0,    0,    0,    0]),\n",
       " array([1505,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  32, 1187,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  67, 2376,   81,   74,    1,    3,  421,   15,    1,    0]),\n",
       " array([251, 188, 932,  21, 388,   0,   0,   0,   0,   0]),\n",
       " array([154,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([48,  1,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  19,  634,    4,    2, 1319,   97,    5,   93,    0,    0]),\n",
       " array([  40, 1807,  208,  765,   79,    0,    0,    0,    0,    0]),\n",
       " array([1505,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([152, 225,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([181,  72,  66, 427,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2, 1099,   24,  132, 1390,  105,  104, 3447,  770,    0]),\n",
       " array([   4,    1,   65,    1, 3262,    1,    0,    0,    0,    0]),\n",
       " array([  19, 1139, 1653,   56,  284,  160,  427,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 59, 195,  94,  28, 450,  25,  12,  21, 225,   0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,  320,   32, 1822,    0,    0,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  73,   36,   76, 2759,  692,   14,    2,  307,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([2143,    7,   20, 1446,    3,  186,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 181,   22,   20, 2860,    0,    0,    0,    0,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 145, 1022,   23,   31,   13, 1344,    4,    1,    2,  260]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,    2, 2354,  841,    0,    0,    0,    0,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  432,  664,    1,   27,   23,   12, 1168,    0,    0]),\n",
       " array([100, 450,   4,  18,  28, 794,   0,   0,   0,   0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([110,   9, 408,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,   15,   46, 1417,    1,    2, 1422,    0,    0,    0]),\n",
       " array([  53,   23,    1,   47,   57, 3516,   22,    5,   42,  789]),\n",
       " array([  20, 3601,  115, 2009,    4,   18, 1482,    0,    0,    0]),\n",
       " array([480, 323,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1569,   57,    2,   53,   23, 3244,    0,    0,    0,    0]),\n",
       " array([  11,  241,  702,  339,   56, 2403,  115,   13,    0,    0]),\n",
       " array([216,  18, 828, 123,  54,   1,  64,  33,   0,   0]),\n",
       " array([   9,  318, 1717,    2,   89,   14,   29,    1,    0,    0]),\n",
       " array([  37,   18,    2,    1,  591,  171,   23, 1533,    0,    0]),\n",
       " array([   4,    2, 2837,    6,    9,   94,    3, 2406, 2447,    0]),\n",
       " array([ 31,  55, 535, 112,   6, 225,  48,  39,  23,   0]),\n",
       " array([  92, 1395,    2,  388,    0,    0,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([872,  39, 389,  75,  56,   0,   0,   0,   0,   0]),\n",
       " array([1440,   10,   28,    1,   47,  225,   37,    0,    0,    0]),\n",
       " array([   6,   20,    1, 2928,  323,    0,    0,    0,    0,    0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([49,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([630,  34, 323, 805,  41,   4, 225,   0,   0,   0]),\n",
       " array([171, 225,   1,  66,  13,   3,  34,  20, 742,   0]),\n",
       " array([  4, 225,  37,  18, 805, 171, 310,   0,   0,   0]),\n",
       " array([  11, 1401,   23, 1949,   13,    0,    0,    0,    0,    0]),\n",
       " array([232,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([291, 224,   3, 125,   0,   0,   0,   0,   0,   0]),\n",
       " array([  61,    2, 1034,   12,  128,    3,   11,   29, 2415,    0]),\n",
       " array([ 54,  64,  20,   1,  23, 714,   0,   0,   0,   0]),\n",
       " array([ 81,  21, 432, 936,   0,   0,   0,   0,   0,   0]),\n",
       " array([293,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([291, 703,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  28,   19, 1440,   12,  342,    0,    0,    0,    0,    0]),\n",
       " array([  10,   60,    6,  302,   41,    1,   11,   40, 2742,    0]),\n",
       " array([  3,  93,  61,  36, 982,   0,   0,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 12,  17,  13, 429,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 29, 195,  24, 151, 314,  47,  11,  21, 329,   0]),\n",
       " array([ 10, 231,  18, 536,   4,   1, 968, 251, 302,   0]),\n",
       " array([ 92,   1,  96,  13, 956, 418, 220,   0,   0,   0]),\n",
       " array([228,   5, 311, 730, 104,  41,   2, 248,   5, 131]),\n",
       " array([  5,  24,   2, 985,  62, 609,  62,  17,  12,   0]),\n",
       " array([  60,   24, 2605,    9,  264,   22,   17,   12,   13,  604]),\n",
       " array([ 815,   14, 1699,   52, 2499,    2, 3136,   12,  169,    0]),\n",
       " array([   2,  307, 2628,    3,   17,   12,    1,    0,    0,    0]),\n",
       " array([323, 225,  19, 180, 592,   0,   0,   0,   0,   0]),\n",
       " array([ 103,   12,    6,  302,  637, 2168,   64,    6,    7,    0]),\n",
       " array([   3, 1505,  778,    9,  120,  794,  820,    0,    0,    0]),\n",
       " array([104, 403, 951,  47,  21,   1,   0,   0,   0,   0]),\n",
       " array([ 878,   96, 2779,  120, 2150,   96,   14,    7,    0,    0]),\n",
       " array([1834,    6,   17,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 40,   1,  11,   2, 657,   0,   0,   0,   0,   0]),\n",
       " array([ 36, 134,  82, 128, 469,  22, 302,  59, 501,   0]),\n",
       " array([  4, 351,  79,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 123,   95,    7,  131,   17, 1696,    0,    0,    0,    0]),\n",
       " array([  4, 273,  19, 169,   1,   1, 184,  73,   0,   0]),\n",
       " array([ 60, 888,  86, 315, 680,  53,   0,   0,   0,   0]),\n",
       " array([11,  2,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  17, 2108,    1,    4,  302,   33,    2,    1,    0,    0]),\n",
       " array([  36,   37,   18,    1,   11,   40, 2799,   53,   59,    0]),\n",
       " array([   4,  105,   11,  193, 2524,  251,  788,  302,    0,    0]),\n",
       " array([  87,   93,   36,   76, 3858,    0,    0,    0,    0,    0]),\n",
       " array([165, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([152, 342,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 105,   19, 1836, 1304,    7,    4,   19, 2473,    0,    0]),\n",
       " array([  72,   79,  525,    4, 1232, 1185,    0,    0,    0,    0]),\n",
       " array([  39,   60,  243,  174,  138, 1424,   14,    2, 1916,    0]),\n",
       " array([ 272,   19, 1095,   22,    5,  131,  585,  281,    0,    0]),\n",
       " array([   1,   13, 1358,   14,   79,    0,    0,    0,    0,    0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48, 469,  13,  10,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5, 106,  50,   1, 181,  54,   0,   0,   0,   0]),\n",
       " array([ 99,   1,   6,  65, 264,  41, 284, 702,   0,   0]),\n",
       " array([  3, 337,   1,   5, 168,  19, 805,   0,   0,   0]),\n",
       " array([  39,   36,    3, 1187,  225,  869,    4,  358,    0,    0]),\n",
       " array([ 96, 694, 700,  79,  36,  37, 195, 537,   0,   0]),\n",
       " array([184,  74, 115,  42,  32,  54,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([   2,  260, 2028,    7,    0,    0,    0,    0,    0,    0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   3,  273,   19,  805, 1110,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([269,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([165, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([269,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([269,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,  160,    7,  236, 1278,   52, 1820,  428,   11,    9]),\n",
       " array([  54, 3763, 1057,   39,    8,  122,   76,    8,  326,    5]),\n",
       " array([  87,    1, 2312,   11,   10, 1324,  767,   23,    0,    0]),\n",
       " array([904, 173,  64,  11,   2,   1,   6,  20, 401,  97]),\n",
       " array([ 23,  58, 315, 120,  77,  73,  82,  23,  59,  22]),\n",
       " array([  1,   3,   2, 337, 122,   6,   8, 971,  73,   0]),\n",
       " array([ 647,   15,    1,    1,   34, 2175,   20,  177,   73,    0]),\n",
       " array([  14,    9,  159,    6,  377, 2707,    9,  223,   87,   13]),\n",
       " array([1903,   27,   88,  380,   50,   38, 2018,    5,    1,    0]),\n",
       " array([ 61, 173,  58, 662, 110,   9, 557,  10,  17,  59]),\n",
       " array([  32,  216,   64,    1,    4,  829,   33,    2, 1264,   39]),\n",
       " array([   1,  128,   17,   13,  881,   59, 1293,    4,   72,   27]),\n",
       " array([ 997,   97,   23,   59,   84,    4,  281, 1569,    4,    9]),\n",
       " array([ 373,    5,  530,   27,   50,  791,   23, 3419,   20, 1320]),\n",
       " array([ 619,   15, 2131,    5,  117,   43,  236,    5,    1,   13]),\n",
       " array([ 54,  11, 367,  57,  89, 845,  23,  59,   9,   1]),\n",
       " array([  64,   44,   11,   89, 1351,   23,   92, 2597,  245,    9]),\n",
       " array([94,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  22,   92,   23, 1035,   11,    2,  388,  259,   61,   55]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 55,  20,  46, 556,  87,  24, 151,   8, 122,   5]),\n",
       " array([1104,   58,   24,  559,  713,  125,   16, 2325,    0,    0]),\n",
       " array([   1,   92,    5,    9, 2421,  600,  524,   11,    8,   77]),\n",
       " array([1721,    3,  255,  376,  267,   64,  249,    3,    8,   46]),\n",
       " array([ 225,    5,   92,  344,   92, 2191,  200, 1784,   14,   65]),\n",
       " array([ 659,   64,   74,    1, 3345,  112,    6,  936,    0,    0]),\n",
       " array([1373,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 259,    2,  121, 1140,   12,   49,    4,  938,    7,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 369,    7,  102,   16,  168,    4, 1915,  166,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([310,   7,  37,  13,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 653,    5,  125,  338,   19, 1369, 1469,    0,    0,    0]),\n",
       " array([  98,   27,  709,  342,  174,   33,    2, 1231,    0,    0]),\n",
       " array([  25,  486,   50,    9,  203,    2, 1099,    1,   27,    0]),\n",
       " array([ 653,    5,   98,   27, 2544,  141,    3,  185,  141,    0]),\n",
       " array([ 49,  47,   7,   1,   7,  76, 807,  11, 179,   0]),\n",
       " array([ 171,    7,   76,  561,   11,  302,   20,  442, 1321,    0]),\n",
       " array([ 15,  20,   1, 158,  55,   1, 284,  23, 714,   0]),\n",
       " array([ 84,   4,   9,   1, 304,   1,   4,   1,   0,   0]),\n",
       " array([  52,   34,   52,  569,   20, 2392,    0,    0,    0,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  20,  442, 1321,   48, 3047,   32,  147,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 146,    7,  582,   17,   54, 1042,    9,   94,    0,    0]),\n",
       " array([  64,    1,   20,    1,    2, 3201,    6,    1,    0,    0]),\n",
       " array([ 73,  63,  95,   1,   1, 776,  13,   1,   0,   0]),\n",
       " array([  64,    1, 3088,   73,   17, 1892,  284,  147,    0,    0]),\n",
       " array([  57,    1,  465,    1,  117, 1140,    0,    0,    0,    0]),\n",
       " array([ 36,  41, 741,   4, 286,  38, 290,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 570, 1041,    8,   45,   50, 1170,  342,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 420,  636,  342,  210, 1717,   20,  922,    0,    0,    0]),\n",
       " array([   3, 1335,   81,   20,  947,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  8, 891, 140,  46, 159,   4,   7,   0,   0,   0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([164, 259,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,   69,  991,    4,   98,   19, 3581,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  61,   42,    7,  140,    7,   41, 3013,    1,    0,    0]),\n",
       " array([ 29,  41,   7,   1,  62,   9, 957,   1,  11,  46]),\n",
       " array([393,  61, 435,  19, 234, 122,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,  385,   19, 3581,   56,   46,  259,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,   92,  344,   98,    2, 1105,    3,  125,    9, 1469]),\n",
       " array([ 155,   81,   20, 2916,    0,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 48,   8, 218,   2, 340, 122,  67,   1,   9,   0]),\n",
       " array([ 157,  798,  298,   48,    8, 1270,    5, 2369,   81,   27]),\n",
       " array([2501,  630,   88,  380,  463,  320,  110,    9,    0,    0]),\n",
       " array([   1, 1389,    5,  419,   27,  682,  316,    9,    1,    0]),\n",
       " array([   1,    3,   73,   23, 2007,   17,   23,   72,   17,   75]),\n",
       " array([156,   3, 316,  17, 156,   3, 724,   3, 724,  23]),\n",
       " array([194,   3, 156,   1,  17, 156,  52, 815,  20,   0]),\n",
       " array([406,   1,  27,  52,  61, 491,  23,  95,  28, 243]),\n",
       " array([1339,    3,  880,   17,   48,    5,  516,   17,   61,   23]),\n",
       " array([17,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  74,   47, 1424,  340,    1,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([310,   1,  96,   9, 152, 363,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  9,   1, 259,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 49, 362, 934,  19,   1,   5,  86,  24,   7, 461]),\n",
       " array([   2, 1119,    1,   15,   16,   21, 1856,    0,    0,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  32,   46,  259,    5,   31,   13,  112,    6, 3711,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  13,  112,    6, 3711,    0,    0,    0,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([63, 37, 63, 37,  0,  0,  0,  0,  0,  0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([310,  32,  33,  19, 601,  67,  13, 724,   2,   0]),\n",
       " array([3980,  184,    8,   45,  541,   50,    2,  664,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([583,   7,   1, 428, 120,   1,  49,   0,   0,   0]),\n",
       " array([  7,  86,  75, 938,   2,  46, 121,  10, 366,  11]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   5,   31,  456,   38, 2886,  681,    3,  938,   38,   15]),\n",
       " array([  8, 757,  22,   5, 142,  75, 770,   0,   0,   0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 90,   5, 160,   7,   0,   0,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  96,   13,    4,  404, 1072,  123,   10,    5,  768,   77]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  7,  58,  18, 356,   1,  82,  60,  71,  34,   0]),\n",
       " array([   2,    1,   63,    1,   11, 3954, 1324,   95,   22, 1308]),\n",
       " array([  1, 312,   6,   1,  49,   5,  58,  19,   1,   0]),\n",
       " array([  76, 2907,   25,   19, 1462,   10,    7,  258,  168,    0]),\n",
       " array([  1,  17,  14, 405,  49,   7,  37,  75,  15,  79]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 32,  46, 259, 265,  16, 310,   5,  31,  13, 284]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 11, 396,   1,  75,  15,  16,   3,  67, 117,   7]),\n",
       " array([1571,  229,    6,   19,  326,    0,    0,    0,    0,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48,  46, 259,  85, 115,  18, 255,  82,   0,   0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([2064,    5,   42,   13,  727,   15,    7,   85,  285,  229]),\n",
       " array([ 27, 347, 204,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([310, 259,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  11, 2193, 1118,  139,    5,  311,    9,  567,  106,   17]),\n",
       " array([ 141,   17,   12,    2, 1099,   24,   88, 1095,  284,  170]),\n",
       " array([241, 323,   2, 580,  12, 220,  15,  74, 268,   6]),\n",
       " array([  40,  820,  264,   19,   45,    3, 1505,  778,   41,  243]),\n",
       " array([ 174,  138,   65,  445, 1185,   60,  198,  469,    0,    0]),\n",
       " array([  1,   3,   4,  80,  17, 811, 664,  21,  12, 139]),\n",
       " array([ 47, 109, 173,   3,  28,   5, 160,  75,  15,  79]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 102,   16, 1174,   46,  259,    5,   31, 1065,    7,   11]),\n",
       " array([ 238, 1452,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([436,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 72,  38, 525, 121,  25,  63,  12,  44,  63,  31]),\n",
       " array([2423,   40,  216, 2357,    0,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  11, 1270,    5,  131,   63,   58, 1085,    7,   56,   55]),\n",
       " array([ 49,  46, 164, 121, 588, 837, 412,  30,   0,   0]),\n",
       " array([   1,  112,   48, 1240,    3,   75,  703,   15,   79,    0]),\n",
       " array([837,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 32,  57,   9, 218, 259, 310,   5,  86,  13,   5]),\n",
       " array([   7,  132, 2357,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([1140,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 56,  55, 269,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1325,  194,  229,    9, 2060,   60,   24,  670,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  8, 476,   4, 429,  32,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 96, 163,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([3245,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 71, 320,  40, 580, 670,   2, 592,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  60,  354,   11, 1266,   22,   24,   13,  707,   25,   82]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 28,   2,  46, 476,  12, 109,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 67, 784,  27,   6,   7,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  32,   67,  123, 1903,  123,  102,   27, 1164,    7,   27]),\n",
       " array([  14,  630,    9,  954,  379, 3351,    2,  907,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 61, 348, 219, 354, 104,   1,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 332,   21, 1786,    3,  630,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  55,   37,   36,  125,   65,    1,    3,   60, 1063,    0]),\n",
       " array([  44, 2365,    5,  588,   80,   79, 1112,   11,  648,    0]),\n",
       " array([  10,   36,   15, 4064, 1105,   78,  774,   50,  224,    0]),\n",
       " array([  4, 309,  40,   1, 208,  49, 966,  30,   1,   0]),\n",
       " array([   1,  342,   12,   23,  332,   19, 1098,    0,    0,    0]),\n",
       " array([ 89, 567,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  32,  123,    9,   94,   10, 1818,    7,  376,   64,   23]),\n",
       " array([ 304, 1956,   64,    9,  234,    0,    0,    0,    0,    0]),\n",
       " array([ 645,   40, 1577,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  41,    1,  284,   40,  647,   56,  488,   40, 1098,    0]),\n",
       " array([ 344,   64,   60,   37, 1927,   79,  111,   40,  672,    0]),\n",
       " array([  53,   82,  540, 1517,   36,   24,   22,    1,   15, 2922]),\n",
       " array([1745,  627,    6,  680,    0,    0,    0,    0,    0,    0]),\n",
       " array([645,   7, 348, 219,   0,   0,   0,   0,   0,   0]),\n",
       " array([  85,   12,  342, 1366,   29,  648,   23,  308,    0,    0]),\n",
       " array([1854,   19,    1, 1095,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([48, 60, 41, 57, 17,  0,  0,  0,  0,  0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  65,  946,   18,   40, 2158,    1,  687,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 60, 179,  79,  13,  22, 713, 284,  65, 445,   0]),\n",
       " array([ 44, 239,  19,   1, 138,  19, 454,   3, 421,   0]),\n",
       " array([  15,  454,   54, 1357,   64,    1, 2229,    0,    0,    0]),\n",
       " array([ 646, 1505,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  60,   42, 2424,   79,  132, 1488,   40,  526,    0,    0]),\n",
       " array([  53,  308,   16, 2267,   15, 1406,   49,   47,    8, 1084]),\n",
       " array([  23,   10,    1,   67,  105,   27,   14,    9, 1611,    0]),\n",
       " array([   3,   23,   37,  808,  109, 2192,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  34,    2,    1,    6,    2, 2282,  399,   47,    7,    0]),\n",
       " array([   7,    1,    6,  302,    7, 2674,    1,    3,    1,    0]),\n",
       " array([   1,    7,  613,   10,    7,   78,   18, 3255,    0,    0]),\n",
       " array([ 673,   64,  483,    3,   74, 2668,  356,    0,    0,    0]),\n",
       " array([ 170,    2,  704,    9, 1786,    7,  553,    6,    1,    0]),\n",
       " array([  10,  203,    2, 2296,    6,  153,   61,   24,    7,  682]),\n",
       " array([  50, 1760,   10,    1,   58,  636,    1,    3,  420,    0]),\n",
       " array([  34, 1450,  932, 2476, 1429,    3, 1570,  668,    0,    0]),\n",
       " array([  15, 1461,    3,    1,  179, 1672,    3,  552,  287,    0]),\n",
       " array([  52,   33,    2, 1981,    6,  182,   67,  168,    2,  740]),\n",
       " array([  3,  80,   8, 664,  47,   7, 155, 817,  49,  47]),\n",
       " array([  39,  585,  190,  674,   56,  636,   66,    4,   65, 1327]),\n",
       " array([  25,   60,   79,    4,   40, 3963,    1,    0,    0,    0]),\n",
       " array([  28,   44,    2,  672,   41, 2130,   44,  345,   46,    1]),\n",
       " array([  96,   14,    2, 1377,  382,    1,   66,    0,    0,    0]),\n",
       " array([ 13,  14,   2,   1, 543,  16,   3,  42,   2,  84]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 1, 13,  5,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([165, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([123,   5,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  98,   60,   24, 1517,   27,   11,    0,    0,    0,    0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([   4,    2, 3475,    5,  516,   27,    0,    0,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 29,  12, 662,   6, 225,   0,   0,   0,   0,   0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([529,  51,   1,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([3089,    2,    1,   57,    2,  157, 2396,    0,    0,    0]),\n",
       " array([ 15,  66,  23,   1, 103,  81,   2, 909,   0,   0]),\n",
       " array([  1,   4,  65, 672,  23,  12, 245, 525,   0,   0]),\n",
       " array([  4, 351,  34,   2, 445,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48, 152, 383,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 103,    1,    1,   20, 2566,  465,    0,    0,    0,    0]),\n",
       " array([   3,   73,   17, 3800,  528,  111,   26,  129,  440,  225]),\n",
       " array([   9,    1,    1,   25, 1595,   25,   26,  129,    0,    0]),\n",
       " array([  76,   13,   28,  683,    9, 2156,   26,  748,    9,  733]),\n",
       " array([ 196,    4,    1,  456,   13, 2411,    3, 3333,    0,    0]),\n",
       " array([ 337,   11, 2093,   22,   15,   30, 3076,  434,    3,    0]),\n",
       " array([   2,    1,    1,    6,   30, 2548,    0,    0,    0,    0]),\n",
       " array([ 26,   1, 249, 658, 978,  25,  39,   2, 187,   0]),\n",
       " array([  76,    1,    3,   95, 1618,    0,    0,    0,    0,    0]),\n",
       " array([ 89, 733,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([155,  51,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  1, 225,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 291,  729,   27,  219,   52,   80, 1016, 1721,    0,    0]),\n",
       " array([ 89, 820,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  21,   31,    5, 1132,    4,  302,    0,    0,    0,    0]),\n",
       " array([165, 820,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 3,  5, 21,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([355, 820,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   9,    1,  885,    5,  678,   21,   14, 1280,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  98,   62,  104,    1,   10,   42, 1430,   65,  534,    0]),\n",
       " array([  57,    9, 3151,    1,    1, 3039,    1,    0,    0,    0]),\n",
       " array([ 1,  6,  9,  1,  1, 10,  1, 58,  0,  0]),\n",
       " array([1837,   15,  215,   10, 2236,   66,  104,  873, 1760,    0]),\n",
       " array([ 251,   82,    2,  421,   18,  163, 1936,  111,  174,   15]),\n",
       " array([  3, 645,  29, 946,   2, 580, 308,   4,  27,   0]),\n",
       " array([ 85,  12,   2,  94,   6,   8, 553, 391, 342,   0]),\n",
       " array([2336,   40, 1911,   55,  794, 1505,  105,    0,    0,    0]),\n",
       " array([   1, 2980,    4,   80,   46,    2,  445,    0,    0,    0]),\n",
       " array([705,   5,  15, 215,  10,  24,   2, 539,  31, 507]),\n",
       " array([  4, 309, 323,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([446,  51,  26,   1,   0,   0,   0,   0,   0,   0]),\n",
       " array([  30, 2184,   70,  151,  100, 1413,   14,    0,    0,    0]),\n",
       " array([  9, 165, 690,   6, 421,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  51, 1531,   16,   13,    0,    0,    0,    0,    0,    0]),\n",
       " array([   8,  648,   70,   82,   13, 3907,   16, 1085,    7,   56]),\n",
       " array([   2,  147,    5, 1239,   12,  344,    1,    0,    0,    0]),\n",
       " array([ 64, 744,   4,  16,   4, 342, 141,   0,   0,   0]),\n",
       " array([  5,  31, 787,   3, 421,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  44,    2,  149, 3651,  382,    0,    0,    0,    0,    0]),\n",
       " array([406, 594,  11,  77,  15,  43,   3,  38, 169,   1]),\n",
       " array([   1,   30,    1, 1105,  719,  235,    0,    0,    0,    0]),\n",
       " array([2598,   18,   30, 1021,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 30, 328,  32, 376,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 64, 215,  63,   1,   1,  28, 269,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  26, 3874,  225,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  75,  457,   30, 2069,   11,    2, 1788,    0,    0,    0]),\n",
       " array([ 185,  770,   34,    2, 2344,   48,    2,  907,    0,    0]),\n",
       " array([ 97,  60,  37,  93,  40, 319, 146,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 870,    7,    8,  208,   56, 1030,    0,    0,    0,    0]),\n",
       " array([ 36,  41,  49, 219,   0,   0,   0,   0,   0,   0]),\n",
       " array([  84, 1911,  642, 1122,   11,   40,  528,    0,    0,    0]),\n",
       " array([ 123, 2739,   11, 1915,  424,   16, 1630,    0,    0,    0]),\n",
       " array([  36,   37,   18, 1712,  156, 1049,   36,   24, 1053,    0]),\n",
       " array([ 33,   1,   3,   1,   1,  36,  24, 311,   0,   0]),\n",
       " array([   2, 2763,    6,   40,  208,  563,  820,  260,    0,    0]),\n",
       " array([951,  65,   1,  25,  36, 456,  40, 161,   0,   0]),\n",
       " array([  10,  140,   40, 1656,   15, 3379,    0,    0,    0,    0]),\n",
       " array([1, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " array([  78,  102,    7, 2856,    1,    0,    0,    0,    0,    0]),\n",
       " array([ 30, 229,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  595,    6, 1185,   24, 3598,    0,    0,    0,    0]),\n",
       " array([  3, 671,   4, 778,   3,   4, 225, 786,   0,   0]),\n",
       " array([   5,  419,   40, 1155,    4,   65, 3963,    1,    0,    0]),\n",
       " array([  3,  55,   5, 285, 146,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 171,   26, 2100,  396,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 653,   26, 2100,   13,   56,    0,    0,    0,    0,    0]),\n",
       " array([ 61, 244, 644, 228,   0,   0,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([814,  88, 380,   8,  45,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  96,   13,    9, 1786,    1,   36,  311,   65, 1577,    0]),\n",
       " array([  61, 2432,   26,   11,    9, 1786, 2436,   88,  380,    0]),\n",
       " array([  3, 272,  30, 229,  28, 521,   0,   0,   0,   0]),\n",
       " array([462,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([4048,    6,    2, 1099,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 828,   16,   11, 2006,   10,    5,   59, 1695,    4, 3893]),\n",
       " array([ 403,   52,  956, 3552,  301,  252,   92,    5,   51,    0]),\n",
       " array([630,  88, 380, 228, 536,   8, 556,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1202, 1325,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([ 10, 435, 787,  25,  23,  76,   1,  48, 260,   0]),\n",
       " array([  23,  320,    2, 2544,    6,  225,    3,    5,   24,    0]),\n",
       " array([  1, 483,  27, 141,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([   2,  459,  546,   13, 1506,   50,    9,    1,    0,    0]),\n",
       " array([ 54,  64,   5,  93,   2, 457,   6, 225, 266,   0]),\n",
       " array([  50,  282, 3008,   94,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 49,   5, 100, 521,   0,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([137,  39,   7,  49,  13,  11,   2, 147,   6, 800]),\n",
       " array([ 22,   1,  11,  19, 161,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48,  72,  16,   1, 563,   0,   0,   0,   0,   0]),\n",
       " array([  11,  395,   25,  457,   25,   73,    5, 1045,   11,  133]),\n",
       " array([  25,  685,   25,   73,   40, 2624,  159,   59,  163,    0]),\n",
       " array([3, 1, 1, 4, 1, 0, 0, 0, 0, 0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([1234,    6, 2248,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  61,   12,   17,   15, 1505,  778,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 25,  15,   9,  94,   1, 301,   1,   0,   0,   0]),\n",
       " array([   1,   99,    4,  101,    3,   99,    4, 1465,    0,    0]),\n",
       " array([   1,   27,   52,    1, 2260,    2,  205,    0,    0,    0]),\n",
       " array([2391, 1185,   11,    2,  148,    6,  302,    0,    0,    0]),\n",
       " array([196,  84,   9,   1,   1,  11,   2,   1,   0,   0]),\n",
       " array([   4,   72,   27, 2104,   57,   31,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 97,  12,  10, 819,   0,   0,   0,   0,   0,   0]),\n",
       " array([  53,  448,   16,   60,   92,  636,    7,    4,   19, 3963]),\n",
       " array([ 97,  12,  23, 185,  27, 338,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 72,  27, 525,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  23,   95, 1961,    2,  396,   22,   14,   40,  495,    0]),\n",
       " array([   2,  572,    1, 1294,  692,   14,   66,    0,    0,    0]),\n",
       " array([   2, 3533,  439, 4080,    2, 3783,   25,   60,   95, 3792]),\n",
       " array([  50, 3448,  637,   64,   60,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  22,   61, 2330,    7,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 31,   2, 118, 624,   4, 117,   5,  42,  13, 131]),\n",
       " array([ 97,  12,   2, 592,  41,   7, 217,  48,   2, 657]),\n",
       " array([  39,   13,   90, 1590,    7,  184,    7,   41,   28,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,   24,   57,    1, 1030,    3,   95,    0,    0,    0]),\n",
       " array([1915,    4,  766,   40,  502,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 61, 366,  65, 786,  93,   7,  47,  53, 649,   0]),\n",
       " array([ 60,  24,   1,  65, 153,   6, 599,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  25,    5, 1026,  225,    0,    0,    0,    0,    0,    0]),\n",
       " array([  65, 2473,    5,    2,    1,   41,    2, 3849,    0,    0]),\n",
       " array([  6,  65, 262, 599, 613,  66, 342,   0,   0,   0]),\n",
       " array([ 65, 157, 133,   6, 275,   0,   0,   0,   0,   0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  42, 369,   7,   0,   0,   0,   0,   0,   0]),\n",
       " array([  33,   34,    2, 2472,  767,   36,   24, 1030,    0,    0]),\n",
       " array([  33,    2,  147,   36,   24,  913,  463,   33,    2, 1733]),\n",
       " array([  36,   24,  128,    4, 1572,  208,   10,    7,    1,    0]),\n",
       " array([ 243,   16,  170,  342,    3,   20, 3849,    0,    0,    0]),\n",
       " array([   3,   10,    7,   13, 1582,    2,  432,   22,    0,    0]),\n",
       " array([   1,    2,  584,   15, 1105, 3251,    3,    1,    0,    0]),\n",
       " array([ 36, 345,  21, 157, 380,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([171,   5, 231, 456,   0,   0,   0,   0,   0,   0]),\n",
       " array([  7,  76,   1,   4,   9, 276,   1,   0,   0,   0]),\n",
       " array([  3,   1,   1,   4,   7,  82, 617,   5, 134,   0]),\n",
       " array([ 763,   19, 3228,  105,   19, 1247,    6,  215,    0,    0]),\n",
       " array([  10,  262,  115, 1197,   19,  936,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([215,  41,  60,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  10,  120,   41, 2047,   39,  144,  110,   18,   62,    0]),\n",
       " array([  25,   17,   76,  565,    4,    1,   77,   21, 3507,    0]),\n",
       " array([767,   7,  98,  16,   1,  39, 144, 179,   0,   0]),\n",
       " array([1956,   20,  557,   64,   88,   67,  556,    0,    0,    0]),\n",
       " array([ 39, 144, 131, 646, 101,   1, 720, 126,   0,   0]),\n",
       " array([   3,   10,   20,  998, 2734,   64,  245,    0,    0,    0]),\n",
       " array([  72,   27,  525,   52,   28,  193,   28, 3549,    0,    0]),\n",
       " array([3281,  141,    4, 1820,   20, 1579,    0,    0,    0,    0]),\n",
       " array([  3, 427, 225,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48,  16, 525,  80,   7,   9, 465,   6,  16,   0]),\n",
       " array([  39,  104,  883,   18,   13, 1535,   53,    6,    7,    0]),\n",
       " array([  22,   12,  956, 1099,  255,    6,    7,   22,   12,    0]),\n",
       " array([1725,    4,  203,  170,    2,  169,  342,    0,    0,    0]),\n",
       " array([   9, 2293,   25,  924,   25,   20,    9,  962, 1665,    0]),\n",
       " array([171, 527,   4,  34,  86,   5,   1,   0,   0,   0]),\n",
       " array([ 50,  34,   2, 257,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 37, 203,   2, 388,  11,  99, 205, 421,   0,   0]),\n",
       " array([  25,  296,   31,   18, 3510,  303,    7,    4,  774,    0]),\n",
       " array([  3, 956,  37, 857, 633, 112,   8, 607,   0,   0]),\n",
       " array([  53,  153,   41,  262, 2386,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 774,   47,    8, 1084,    0,    0,    0,    0,    0,    0]),\n",
       " array([80, 46, 21,  1,  3,  7, 37,  0,  0,  0]),\n",
       " array([3715,   11,   34,   15,   79,    0,    0,    0,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 28,  72,   2,   1,  18,   1, 273,  19,   1,   0]),\n",
       " array([ 25,   5,  24, 243,  66, 174,  39,   5,  42, 415]),\n",
       " array([ 215,    1,    4,   40, 1197,    2,  257,   31,  624,    0]),\n",
       " array([  14,    9,  912, 2391,   39,   36,  569,    2,  657,    0]),\n",
       " array([ 36, 142, 273,   2, 907,   0,   0,   0,   0,   0]),\n",
       " array([1955,    0,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([179,  13,  40, 497,  51,   0,   0,   0,   0,   0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 224,    3, 1517,   19,  672, 3932,    0,    0,    0,    0]),\n",
       " array([  40,    1,   49,    4,    2,  820,    1, 1708,   79,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 67, 421,  15, 255,  22,  43,  14,   5,  42, 391]),\n",
       " array([637,  64,   9,   1,   0,   0,   0,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  36,  391, 1721,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  13,    1,    1,    9, 3395,    5,    1,    0,    0,    0]),\n",
       " array([  54,   64,   30, 1569,    3, 1311,    1,   30,  581,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 72,   2,  89,   1, 200,   2, 800, 819,   0,   0]),\n",
       " array([   3,    2,  260, 1089,   27,  316,    0,    0,    0,    0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 39,   5, 508, 225,   0,   0,   0,   0,   0,   0]),\n",
       " array([   1,   16,   84,    9, 2397,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 332,  104,  403,  534, 2067,    0,    0,    0,    0,    0]),\n",
       " array([ 525,    5, 1030,   11,   19, 1185, 1098,    0,    0,    0]),\n",
       " array([   3,  128,   29,  648,    5, 1293,   96,   13,    8,  147]),\n",
       " array([ 767,   26, 1283,   16,    1,   14,   30,  625,    0,    0]),\n",
       " array([  1, 111,  30, 264,   4,   2,   1,   0,   0,   0]),\n",
       " array([342,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([747,  26,   2,   1,   0,   0,   0,   0,   0,   0]),\n",
       " array([  10,   59,    2, 1731,    6,   19,    1,    1,    0,    0]),\n",
       " array([  26, 1349,   13, 1906,   16,   62,    0,    0,    0,    0]),\n",
       " array([   1,    3,   13,  794,    7,   24, 3393,   16,    0,    0]),\n",
       " array([  11,   19, 2437,    1,    0,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 39,   5,  87, 117,  43, 613,  21,  30, 418, 648]),\n",
       " array([  1,  13, 424,  30, 780,  22,  67, 556,  17,   0]),\n",
       " array([  97, 1281,   37,    1,  297,   15, 1628,    0,    0,    0]),\n",
       " array([  97,  169, 1780,   37,  765,    3,    1,    0,    0,    0]),\n",
       " array([   5,    2,  384,    1,   97,  891,   37,   18, 3664,    0]),\n",
       " array([   3, 2405,    1,  125,   54,   97,    2,    0,    0,    0]),\n",
       " array([1238,  692,    0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([  10,   15,    2,    1, 2960,  391,  249,  805,    0,    0]),\n",
       " array([ 37,  71, 170,  65, 454,  36, 385,   2, 260,   0]),\n",
       " array([ 40, 302,  70, 110,   9, 733,   0,   0,   0,   0]),\n",
       " array([  82, 1591,   26,    4,    9,    1,    6,   21,  895,    0]),\n",
       " array([ 547, 2688, 3128,  138,    0,    0,    0,    0,    0,    0]),\n",
       " array([778,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 48, 580,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  62,   12,    2, 2881,   36,    2,    1,    0,    0,    0]),\n",
       " array([ 728,   26, 1491,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([160,  44,  32,  54,   8, 223,   0,   0,   0,   0]),\n",
       " array([103, 320,   9,   1,   4,   1,  38, 147,   0,   0]),\n",
       " array([  73,   63,  435, 1531,   16, 2680,   16,    5,   24,  163]),\n",
       " array([ 25,   7,  24, 163, 304,  29,   5, 115,   1,   0]),\n",
       " array([ 25,   7,  24, 151, 304,  14,   8, 659,   0,   0]),\n",
       " array([ 23,  10, 320,  22,   1,  20,  46,  31,   0,   0]),\n",
       " array([ 70,   1, 109, 968,   0,   0,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 7, 37, 13, 18,  0,  0,  0,  0,  0,  0]),\n",
       " array([  2, 392,   6,  19,   1, 302,  86,  93,   0,   0]),\n",
       " array([   2, 3292,    6,   38,  161,  574,    9,    1,    0,    0]),\n",
       " array([637,  64,   9,   1,  32, 376,  64,   9,   1,   0]),\n",
       " array([   4,  955,   19,    1,    3,    4, 1107,   10,    0,    0]),\n",
       " array([  53,    4,    2,    1,    3, 2072,    6, 2332,    1,    0]),\n",
       " array([  58,  540,   22, 2354,  167,    5,  369,    7,    0,    0]),\n",
       " array([  11, 1347,    6,   29,    7,   41,   13,    4, 1913,    0]),\n",
       " array([  29,    7,   24,    1,   40, 1095,  125,   16,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  24,  99, 721,  81,  16,   3,  60,   1,   0]),\n",
       " array([   4,  125,  680, 3436,    0,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([87, 60, 13,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([  56,  258,   60,    1, 1028,    1,    0,    0,    0,    0]),\n",
       " array([   3, 1011,  680,   15,  101,    6,   34,    2, 1553,    0]),\n",
       " array([1203,   36,   24,  908,   46,    3,   46, 2095,    6,   34]),\n",
       " array([   2, 1879,   11,   21,  657, 3867,    3,  445,    0,    0]),\n",
       " array([  36, 3434,    7,    2,    1,    4,   18,  908,  284,    0]),\n",
       " array([138,   2, 572,   1,  57,   0,   0,   0,   0,   0]),\n",
       " array([  19,  337, 1247,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5, 385,   7, 580,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 22, 142,  80,   8, 133, 781,   4, 105,   0,   0]),\n",
       " array([   9, 3794,    4,  858,    8,  465,    5,   42, 1919,   17]),\n",
       " array([  3, 190,  81,   8, 572, 268,  15, 215,   0,   0]),\n",
       " array([  10,   24, 1491,    2,  926,    0,    0,    0,    0,    0]),\n",
       " array([225,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  78,  104,  695, 1681,   53,    7, 2599,    0,    0,    0]),\n",
       " array([ 134,  457,   54,   73, 1577,    3, 1208,   37,    0,    0]),\n",
       " array([   5,    2,  657,  345, 3094,   72,    1,    3,    1,   18]),\n",
       " array([128,  34,   6,   1,   1,   0,   0,   0,   0,   0]),\n",
       " array([  73, 1055, 1560,  752,   25,    2,    1, 2896,    0,    0]),\n",
       " array([ 72,  27,  18, 128,   9,   1,  14,   2, 664,   0]),\n",
       " array([  32,   54,    5,   71,   14,   10,    5,   24,   13, 2055]),\n",
       " array([   8, 1297,   10,    1,   52,    1,   99,    1, 1044,    0]),\n",
       " array([ 53, 402, 887, 485, 193, 252,  24, 163,   0,   0]),\n",
       " array([   7, 4084,   16,  284,    0,    0,    0,    0,    0,    0]),\n",
       " array([11,  1,  1,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 25,  39,   5, 712,   8, 234,  87,  18,   1,   0]),\n",
       " array([  11, 2332,    1,   15,  366,    0,    0,    0,    0,    0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([ 100, 2354,   41,    7,    0,    0,    0,    0,    0,    0]),\n",
       " array([  54, 1182,    4,   19,   46,  556,   64,    1,    0,    0]),\n",
       " array([  4,  79,  10, 102,   7, 879,  33,  19, 601,   0]),\n",
       " array([  39, 1028,  428,    7,   18, 3057,   56,  239,    7,    0]),\n",
       " array([  84,   74,   10,  433,   20, 1655,  806,   11,    1,    0]),\n",
       " array([  55,  518, 2575,   15,    7,  167,   18,   17,  604,    0]),\n",
       " array([  25,    4,   79,    4,   34,    2,  187,   10, 1187,  225]),\n",
       " array([2243,   21,  664, 2176,   11, 3319,    6,    2,   53,    0]),\n",
       " array([   8,  152, 2881,  604,    4,    2,    1,    5,  102,   27]),\n",
       " array([  15,   34,   20, 3962,    1,    3,   50,   21,  118,    0]),\n",
       " array([  14,   29,   23,   95,  138, 1185,  185,   27,    0,    0]),\n",
       " array([  15,   34,    2,    1,    3, 2440,    6,    2, 3620,    0]),\n",
       " array([1187,  225,  150,  203,    0,    0,    0,    0,    0,    0]),\n",
       " array([   2,    1, 1784,  195,    0,    0,    0,    0,    0,    0]),\n",
       " array([34,  0,  0,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([1187,  225,  150,    0,    0,    0,    0,    0,    0,    0]),\n",
       " array([150,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  5,  31,  75, 974,   0,   0,   0,   0,   0,   0]),\n",
       " array([   3,   73,    8,  246,   12,  149,    7,   37, 1295,    0]),\n",
       " array([ 815,    5, 1487,   52,   32,    1,    5,  385,    7,    0]),\n",
       " array([   5,  331,    4, 4030,   19, 2881,    3,   57,   34,  492]),\n",
       " array([ 4,  1, 19, 46,  1,  0,  0,  0,  0,  0]),\n",
       " array([  4,   2,   1,   6,   8, 264,   0,   0,   0,   0]),\n",
       " array([323,   0,   0,   0,   0,   0,   0,   0,   0,   0]),\n",
       " array([  28,    4,   40, 1011,    0,    0,    0,    0,    0,    0]),\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# シーケンスの所得\n",
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "print(len(sequences))\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n",
      "[138  36 982 144 673 125  16 106   0   0] => ['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', '']\n",
      "[34  0  0  0  0  0  0  0  0  0] => ['all', '', '', '', '', '', '', '', '', '']\n",
      "[106 106   0   0   0   0   0   0   0   0] => ['speak', 'speak', '', '', '', '', '', '', '', '']\n",
      "[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "# 先端の確認\n",
    "for seq in sequences[:5]:\n",
    "    print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32777/32777 [00:06<00:00, 5089.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64651 64651 64651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 例\n",
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences, \n",
    "    window_size=2, \n",
    "    num_ns=4, \n",
    "    vocab_size=vocab_size, \n",
    "    seed=SEED)\n",
    "print(len(targets), len(contexts), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: (((1024,), (1024, 5, 1)), (1024, 5)), types: ((tf.int32, tf.int64), tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# バッチ処理\n",
    "BATCH_SIZE = 1024\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: (((1024,), (1024, 5, 1)), (1024, 5)), types: ((tf.int32, tf.int64), tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# パフォーマンス向上\n",
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラス化\n",
    "class Word2Vec(Model):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(Word2Vec, self).__init__()\n",
    "        self.target_embedding = Embedding(vocab_size, \n",
    "                                      embedding_dim,\n",
    "                                      input_length=1,\n",
    "                                      name=\"w2v_embedding\", )\n",
    "        self.context_embedding = Embedding(vocab_size, \n",
    "                                       embedding_dim, \n",
    "                                       input_length=num_ns+1)\n",
    "        self.dots = Dot(axes=(3,2))\n",
    "        self.flatten = Flatten()\n",
    "\n",
    "    def call(self, pair):\n",
    "        target, context = pair\n",
    "        we = self.target_embedding(target)\n",
    "        ce = self.context_embedding(context)\n",
    "        dots = self.dots([ce, we])\n",
    "        return self.flatten(dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数の定義\n",
    "def custom_loss(x_logit, y_true):\n",
    "      return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 次元を１２８で走らせる\n",
    "embedding_dim = 128\n",
    "word2vec = Word2Vec(vocab_size, embedding_dim)\n",
    "word2vec.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テンソルボード\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 1s 7ms/step - loss: 1.6088 - accuracy: 0.2188\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.5920 - accuracy: 0.5946\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.5526 - accuracy: 0.6468\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.4753 - accuracy: 0.5965\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.3765 - accuracy: 0.5902\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 1.2761 - accuracy: 0.6109\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.1821 - accuracy: 0.6421\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0953 - accuracy: 0.6762\n",
      "Epoch 9/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 1.0151 - accuracy: 0.7088\n",
      "Epoch 10/20\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.9410 - accuracy: 0.7405\n",
      "Epoch 11/20\n",
      "63/63 [==============================] - 1s 8ms/step - loss: 0.8726 - accuracy: 0.7669\n",
      "Epoch 12/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8095 - accuracy: 0.7900\n",
      "Epoch 13/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7515 - accuracy: 0.8088\n",
      "Epoch 14/20\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.6983 - accuracy: 0.8261\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.6498 - accuracy: 0.8420\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.8546\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.5651 - accuracy: 0.8678\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.5284 - accuracy: 0.8784\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4951 - accuracy: 0.8877\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.4648 - accuracy: 0.8968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd7cf98e160>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01777324, -0.04818541,  0.0336642 , ..., -0.01610544,\n",
       "        -0.01888617,  0.01173959],\n",
       "       [-0.21491548, -0.09562506, -0.29324782, ...,  0.22355206,\n",
       "         0.03199128, -0.08307762],\n",
       "       [-0.04242772, -0.14221635,  0.15783072, ..., -0.09992789,\n",
       "         0.06234811,  0.00075427],\n",
       "       ...,\n",
       "       [-0.21100168, -0.06658164, -0.01553096, ...,  0.11437622,\n",
       "        -0.06671057, -0.06058596],\n",
       "       [ 0.05052953, -0.26799157, -0.17670132, ..., -0.08679438,\n",
       "         0.18281646,  0.17766985],\n",
       "       [ 0.2778715 ,  0.0074762 ,  0.27932513, ...,  0.2141611 ,\n",
       "         0.13084942, -0.26934868]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重みの所得と語彙の提供\n",
    "weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'vectors.tsv', 'metadata.tsv'をDLして分析\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('vectors.tsv')\n",
    "    files.download('metadata.tsv')\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】Iris（2値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data[:100]\n",
    "y = iris.target\n",
    "\n",
    "y_reduce = y[:100]\n",
    "y_reduce=  y_reduce.reshape(-1,1) == np.arange(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_reduce, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7/7 [==============================] - 1s 118ms/step - loss: 0.6837 - accuracy: 0.5311 - val_loss: 0.5126 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.8803 - val_loss: 0.3451 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2828 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.2001 - accuracy: 1.0000 - val_loss: 0.1466 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1144 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 5.4714e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 8.2199e-04 - accuracy: 1.0000 - val_loss: 3.3794e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.5931e-04 - accuracy: 1.0000 - val_loss: 2.2316e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.0060e-04 - accuracy: 1.0000 - val_loss: 1.4420e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 2.1854e-04 - accuracy: 1.0000 - val_loss: 8.9357e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.0198e-04 - accuracy: 1.0000 - val_loss: 5.3039e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2012e-04 - accuracy: 1.0000 - val_loss: 3.3377e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.8977e-05 - accuracy: 1.0000 - val_loss: 1.9910e-05 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9910e-05 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# モデル生成\n",
    "def generate_model(X):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=X_train.shape[1:]))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(2, activation=\"softmax\"))\n",
    "    return model\n",
    "\n",
    "model = generate_model(X_train)\n",
    "\n",
    "# コンパイル\n",
    "def generate_compile(model):\n",
    "    model.compile(loss=\"binary_crossentropy\",\n",
    "                 optimizer=\"RMSprop\", \n",
    "                 metrics = ['accuracy'])\n",
    "    return model\n",
    "    \n",
    "model = generate_compile(model)\n",
    "\n",
    "# 学習とpredto評価を丸める\n",
    "def learning_evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train,\n",
    "         batch_size=10,\n",
    "         epochs=20,\n",
    "         validation_data=(X_test, y_test),\n",
    "         verbose=1)\n",
    "    pred = model.predict(X_test)\n",
    "    scores = model.evaluate(X_test, y_test)\n",
    "    return pred, scores\n",
    "\n",
    "pred, scores = learning_evaluate(model, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 3.6623393e-10]\n",
      " [1.0000000e+00 7.7537932e-10]\n",
      " [5.6286173e-14 1.0000000e+00]\n",
      " [2.5883149e-09 1.0000000e+00]\n",
      " [2.2040438e-13 1.0000000e+00]\n",
      " [1.0000000e+00 1.9002067e-10]\n",
      " [1.3381340e-13 1.0000000e+00]\n",
      " [7.0104950e-12 1.0000000e+00]\n",
      " [1.0000000e+00 3.5319244e-11]\n",
      " [2.9707366e-15 1.0000000e+00]\n",
      " [1.0000000e+00 1.7477234e-10]\n",
      " [1.0000000e+00 3.6578712e-10]\n",
      " [1.0000000e+00 5.3483880e-09]\n",
      " [1.0000000e+00 4.5502629e-10]\n",
      " [1.0000000e+00 1.0737372e-09]\n",
      " [1.0000000e+00 5.1329468e-10]]\n",
      "--------------------------------------------------\n",
      "1.991049066418782e-05\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(pred)\n",
    "print(\"-\"*50)\n",
    "print(scores[0]) # loss\n",
    "print(scores[1]) # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】Iris（多値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "y_hot = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((96, 4), (96, 3), (24, 4))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_hot, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "X_train2.shape, y_train2.shape, X_val2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 情報を１度リセット\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 - 1s - loss: 0.9544 - accuracy: 0.5417 - val_loss: 0.7132 - val_accuracy: 0.6250\n",
      "Epoch 2/100\n",
      "10/10 - 0s - loss: 0.6427 - accuracy: 0.7292 - val_loss: 0.5590 - val_accuracy: 0.7083\n",
      "Epoch 3/100\n",
      "10/10 - 0s - loss: 0.5749 - accuracy: 0.6667 - val_loss: 0.4879 - val_accuracy: 0.7083\n",
      "Epoch 4/100\n",
      "10/10 - 0s - loss: 0.5602 - accuracy: 0.6771 - val_loss: 0.4583 - val_accuracy: 0.7917\n",
      "Epoch 5/100\n",
      "10/10 - 0s - loss: 0.5074 - accuracy: 0.7500 - val_loss: 0.4186 - val_accuracy: 0.9167\n",
      "Epoch 6/100\n",
      "10/10 - 0s - loss: 0.3870 - accuracy: 0.8333 - val_loss: 0.3852 - val_accuracy: 0.8333\n",
      "Epoch 7/100\n",
      "10/10 - 0s - loss: 0.3775 - accuracy: 0.8229 - val_loss: 0.3317 - val_accuracy: 0.9167\n",
      "Epoch 8/100\n",
      "10/10 - 0s - loss: 0.3385 - accuracy: 0.8542 - val_loss: 0.2792 - val_accuracy: 0.9167\n",
      "Epoch 9/100\n",
      "10/10 - 0s - loss: 0.2567 - accuracy: 0.8854 - val_loss: 0.4581 - val_accuracy: 0.7083\n",
      "Epoch 10/100\n",
      "10/10 - 0s - loss: 0.2138 - accuracy: 0.9167 - val_loss: 0.4341 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "10/10 - 0s - loss: 0.2351 - accuracy: 0.9167 - val_loss: 0.2435 - val_accuracy: 0.9167\n",
      "Epoch 12/100\n",
      "10/10 - 0s - loss: 0.2241 - accuracy: 0.9062 - val_loss: 0.4176 - val_accuracy: 0.7917\n",
      "Epoch 13/100\n",
      "10/10 - 0s - loss: 0.1745 - accuracy: 0.9271 - val_loss: 0.2089 - val_accuracy: 0.9167\n",
      "Epoch 14/100\n",
      "10/10 - 0s - loss: 0.1160 - accuracy: 0.9688 - val_loss: 0.3667 - val_accuracy: 0.8750\n",
      "Epoch 15/100\n",
      "10/10 - 0s - loss: 0.1698 - accuracy: 0.9271 - val_loss: 0.4133 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "10/10 - 0s - loss: 0.1512 - accuracy: 0.9583 - val_loss: 0.2374 - val_accuracy: 0.9167\n",
      "Epoch 17/100\n",
      "10/10 - 0s - loss: 0.1532 - accuracy: 0.9479 - val_loss: 0.4012 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "10/10 - 0s - loss: 0.1428 - accuracy: 0.9271 - val_loss: 0.2007 - val_accuracy: 0.9167\n",
      "Epoch 19/100\n",
      "10/10 - 0s - loss: 0.2938 - accuracy: 0.9167 - val_loss: 0.2082 - val_accuracy: 0.9583\n",
      "Epoch 20/100\n",
      "10/10 - 0s - loss: 0.1012 - accuracy: 0.9479 - val_loss: 0.2246 - val_accuracy: 0.8333\n",
      "Epoch 21/100\n",
      "10/10 - 0s - loss: 0.1985 - accuracy: 0.9271 - val_loss: 0.2562 - val_accuracy: 0.9167\n",
      "Epoch 22/100\n",
      "10/10 - 0s - loss: 0.1763 - accuracy: 0.9167 - val_loss: 0.2788 - val_accuracy: 0.9167\n",
      "Epoch 23/100\n",
      "10/10 - 0s - loss: 0.0718 - accuracy: 0.9792 - val_loss: 0.3723 - val_accuracy: 0.9167\n",
      "Epoch 24/100\n",
      "10/10 - 0s - loss: 0.0973 - accuracy: 0.9583 - val_loss: 0.3978 - val_accuracy: 0.9167\n",
      "Epoch 25/100\n",
      "10/10 - 0s - loss: 0.1795 - accuracy: 0.9167 - val_loss: 0.2545 - val_accuracy: 0.9167\n",
      "Epoch 26/100\n",
      "10/10 - 0s - loss: 0.1231 - accuracy: 0.9479 - val_loss: 0.5730 - val_accuracy: 0.7917\n",
      "Epoch 27/100\n",
      "10/10 - 0s - loss: 0.1432 - accuracy: 0.9583 - val_loss: 0.2102 - val_accuracy: 0.9167\n",
      "Epoch 28/100\n",
      "10/10 - 0s - loss: 0.0691 - accuracy: 0.9792 - val_loss: 0.7281 - val_accuracy: 0.7083\n",
      "Epoch 29/100\n",
      "10/10 - 0s - loss: 0.1289 - accuracy: 0.9479 - val_loss: 0.2321 - val_accuracy: 0.9167\n",
      "Epoch 30/100\n",
      "10/10 - 0s - loss: 0.0896 - accuracy: 0.9375 - val_loss: 0.6663 - val_accuracy: 0.7917\n",
      "Epoch 31/100\n",
      "10/10 - 0s - loss: 0.0929 - accuracy: 0.9688 - val_loss: 0.4188 - val_accuracy: 0.9167\n",
      "Epoch 32/100\n",
      "10/10 - 0s - loss: 0.1792 - accuracy: 0.9479 - val_loss: 1.1888 - val_accuracy: 0.6667\n",
      "Epoch 33/100\n",
      "10/10 - 0s - loss: 0.1860 - accuracy: 0.9688 - val_loss: 0.2206 - val_accuracy: 0.9167\n",
      "Epoch 34/100\n",
      "10/10 - 0s - loss: 0.0704 - accuracy: 0.9688 - val_loss: 1.0950 - val_accuracy: 0.6667\n",
      "Epoch 35/100\n",
      "10/10 - 0s - loss: 0.1352 - accuracy: 0.9688 - val_loss: 0.7357 - val_accuracy: 0.7083\n",
      "Epoch 36/100\n",
      "10/10 - 0s - loss: 0.1160 - accuracy: 0.9688 - val_loss: 0.2232 - val_accuracy: 0.9583\n",
      "Epoch 37/100\n",
      "10/10 - 0s - loss: 0.1271 - accuracy: 0.9375 - val_loss: 0.3063 - val_accuracy: 0.9167\n",
      "Epoch 38/100\n",
      "10/10 - 0s - loss: 0.0482 - accuracy: 0.9792 - val_loss: 0.2950 - val_accuracy: 0.9167\n",
      "Epoch 39/100\n",
      "10/10 - 0s - loss: 0.1946 - accuracy: 0.9583 - val_loss: 0.2705 - val_accuracy: 0.9167\n",
      "Epoch 40/100\n",
      "10/10 - 0s - loss: 0.0991 - accuracy: 0.9688 - val_loss: 0.6518 - val_accuracy: 0.7917\n",
      "Epoch 41/100\n",
      "10/10 - 0s - loss: 0.1922 - accuracy: 0.9688 - val_loss: 0.4043 - val_accuracy: 0.9167\n",
      "Epoch 42/100\n",
      "10/10 - 0s - loss: 0.1108 - accuracy: 0.9583 - val_loss: 0.3063 - val_accuracy: 0.9167\n",
      "Epoch 43/100\n",
      "10/10 - 0s - loss: 0.1323 - accuracy: 0.9583 - val_loss: 0.5714 - val_accuracy: 0.7917\n",
      "Epoch 44/100\n",
      "10/10 - 0s - loss: 0.1026 - accuracy: 0.9583 - val_loss: 0.2377 - val_accuracy: 0.9167\n",
      "Epoch 45/100\n",
      "10/10 - 0s - loss: 0.1634 - accuracy: 0.9271 - val_loss: 0.2247 - val_accuracy: 0.8750\n",
      "Epoch 46/100\n",
      "10/10 - 0s - loss: 0.0978 - accuracy: 0.9583 - val_loss: 0.2521 - val_accuracy: 0.8333\n",
      "Epoch 47/100\n",
      "10/10 - 0s - loss: 0.1476 - accuracy: 0.9479 - val_loss: 0.2957 - val_accuracy: 0.9167\n",
      "Epoch 48/100\n",
      "10/10 - 0s - loss: 0.1188 - accuracy: 0.9792 - val_loss: 0.2496 - val_accuracy: 0.9167\n",
      "Epoch 49/100\n",
      "10/10 - 0s - loss: 0.0927 - accuracy: 0.9479 - val_loss: 0.3511 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "10/10 - 0s - loss: 0.0656 - accuracy: 0.9896 - val_loss: 0.3767 - val_accuracy: 0.9167\n",
      "Epoch 51/100\n",
      "10/10 - 0s - loss: 0.1366 - accuracy: 0.9375 - val_loss: 0.2198 - val_accuracy: 0.9167\n",
      "Epoch 52/100\n",
      "10/10 - 0s - loss: 0.0668 - accuracy: 0.9688 - val_loss: 0.3744 - val_accuracy: 0.9167\n",
      "Epoch 53/100\n",
      "10/10 - 0s - loss: 0.0890 - accuracy: 0.9688 - val_loss: 0.3758 - val_accuracy: 0.9167\n",
      "Epoch 54/100\n",
      "10/10 - 0s - loss: 0.0721 - accuracy: 0.9688 - val_loss: 0.2193 - val_accuracy: 0.9167\n",
      "Epoch 55/100\n",
      "10/10 - 0s - loss: 0.0696 - accuracy: 0.9792 - val_loss: 0.4061 - val_accuracy: 0.9167\n",
      "Epoch 56/100\n",
      "10/10 - 0s - loss: 0.1563 - accuracy: 0.9479 - val_loss: 0.2279 - val_accuracy: 0.9167\n",
      "Epoch 57/100\n",
      "10/10 - 0s - loss: 0.0812 - accuracy: 0.9688 - val_loss: 0.5075 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "10/10 - 0s - loss: 0.1429 - accuracy: 0.9479 - val_loss: 0.2794 - val_accuracy: 0.9167\n",
      "Epoch 59/100\n",
      "10/10 - 0s - loss: 0.0497 - accuracy: 0.9896 - val_loss: 0.3285 - val_accuracy: 0.9167\n",
      "Epoch 60/100\n",
      "10/10 - 0s - loss: 0.0795 - accuracy: 0.9688 - val_loss: 0.2164 - val_accuracy: 0.9167\n",
      "Epoch 61/100\n",
      "10/10 - 0s - loss: 0.0518 - accuracy: 0.9792 - val_loss: 0.2496 - val_accuracy: 0.9167\n",
      "Epoch 62/100\n",
      "10/10 - 0s - loss: 0.1670 - accuracy: 0.9375 - val_loss: 0.3386 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "10/10 - 0s - loss: 0.0994 - accuracy: 0.9583 - val_loss: 0.2204 - val_accuracy: 0.9167\n",
      "Epoch 64/100\n",
      "10/10 - 0s - loss: 0.0704 - accuracy: 0.9688 - val_loss: 0.2202 - val_accuracy: 0.9583\n",
      "Epoch 65/100\n",
      "10/10 - 0s - loss: 0.0764 - accuracy: 0.9688 - val_loss: 0.3271 - val_accuracy: 0.9167\n",
      "Epoch 66/100\n",
      "10/10 - 0s - loss: 0.1408 - accuracy: 0.9479 - val_loss: 0.2277 - val_accuracy: 0.9167\n",
      "Epoch 67/100\n",
      "10/10 - 0s - loss: 0.0453 - accuracy: 0.9792 - val_loss: 0.3839 - val_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "10/10 - 0s - loss: 0.0686 - accuracy: 0.9688 - val_loss: 0.2294 - val_accuracy: 0.9583\n",
      "Epoch 69/100\n",
      "10/10 - 0s - loss: 0.0575 - accuracy: 0.9688 - val_loss: 0.3750 - val_accuracy: 0.9167\n",
      "Epoch 70/100\n",
      "10/10 - 0s - loss: 0.0898 - accuracy: 0.9583 - val_loss: 0.4037 - val_accuracy: 0.9167\n",
      "Epoch 71/100\n",
      "10/10 - 0s - loss: 0.0983 - accuracy: 0.9583 - val_loss: 0.2806 - val_accuracy: 0.9167\n",
      "Epoch 72/100\n",
      "10/10 - 0s - loss: 0.0310 - accuracy: 0.9792 - val_loss: 0.2847 - val_accuracy: 0.9167\n",
      "Epoch 73/100\n",
      "10/10 - 0s - loss: 0.1171 - accuracy: 0.9583 - val_loss: 0.4353 - val_accuracy: 0.9167\n",
      "Epoch 74/100\n",
      "10/10 - 0s - loss: 0.0844 - accuracy: 0.9583 - val_loss: 0.3403 - val_accuracy: 0.9167\n",
      "Epoch 75/100\n",
      "10/10 - 0s - loss: 0.0480 - accuracy: 0.9792 - val_loss: 0.3370 - val_accuracy: 0.9167\n",
      "Epoch 76/100\n",
      "10/10 - 0s - loss: 0.0952 - accuracy: 0.9688 - val_loss: 0.4521 - val_accuracy: 0.9167\n",
      "Epoch 77/100\n",
      "10/10 - 0s - loss: 0.0581 - accuracy: 0.9792 - val_loss: 0.3642 - val_accuracy: 0.9167\n",
      "Epoch 78/100\n",
      "10/10 - 0s - loss: 0.0837 - accuracy: 0.9688 - val_loss: 0.2462 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "10/10 - 0s - loss: 0.0908 - accuracy: 0.9479 - val_loss: 0.2212 - val_accuracy: 0.9167\n",
      "Epoch 80/100\n",
      "10/10 - 0s - loss: 0.0424 - accuracy: 0.9792 - val_loss: 0.5277 - val_accuracy: 0.9167\n",
      "Epoch 81/100\n",
      "10/10 - 0s - loss: 0.0754 - accuracy: 0.9688 - val_loss: 0.3742 - val_accuracy: 0.9167\n",
      "Epoch 82/100\n",
      "10/10 - 0s - loss: 0.0864 - accuracy: 0.9688 - val_loss: 0.2824 - val_accuracy: 0.8333\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.0439 - accuracy: 0.9896 - val_loss: 0.4015 - val_accuracy: 0.9167\n",
      "Epoch 84/100\n",
      "10/10 - 0s - loss: 0.0515 - accuracy: 0.9792 - val_loss: 0.2780 - val_accuracy: 0.9167\n",
      "Epoch 85/100\n",
      "10/10 - 0s - loss: 0.1225 - accuracy: 0.9583 - val_loss: 0.2626 - val_accuracy: 0.9167\n",
      "Epoch 86/100\n",
      "10/10 - 0s - loss: 0.0465 - accuracy: 0.9792 - val_loss: 0.4589 - val_accuracy: 0.9167\n",
      "Epoch 87/100\n",
      "10/10 - 0s - loss: 0.1176 - accuracy: 0.9583 - val_loss: 0.2826 - val_accuracy: 0.9167\n",
      "Epoch 88/100\n",
      "10/10 - 0s - loss: 0.0450 - accuracy: 0.9896 - val_loss: 0.4389 - val_accuracy: 0.9167\n",
      "Epoch 89/100\n",
      "10/10 - 0s - loss: 0.0790 - accuracy: 0.9688 - val_loss: 0.3089 - val_accuracy: 0.9167\n",
      "Epoch 90/100\n",
      "10/10 - 0s - loss: 0.0958 - accuracy: 0.9688 - val_loss: 0.2364 - val_accuracy: 0.9167\n",
      "Epoch 91/100\n",
      "10/10 - 0s - loss: 0.0492 - accuracy: 0.9896 - val_loss: 0.2379 - val_accuracy: 0.9583\n",
      "Epoch 92/100\n",
      "10/10 - 0s - loss: 0.1322 - accuracy: 0.9583 - val_loss: 0.2358 - val_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "10/10 - 0s - loss: 0.0505 - accuracy: 0.9688 - val_loss: 0.5881 - val_accuracy: 0.8750\n",
      "Epoch 94/100\n",
      "10/10 - 0s - loss: 0.0849 - accuracy: 0.9688 - val_loss: 0.3705 - val_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "10/10 - 0s - loss: 0.0998 - accuracy: 0.9583 - val_loss: 0.2259 - val_accuracy: 0.9167\n",
      "Epoch 96/100\n",
      "10/10 - 0s - loss: 0.0508 - accuracy: 0.9792 - val_loss: 0.3366 - val_accuracy: 0.9167\n",
      "Epoch 97/100\n",
      "10/10 - 0s - loss: 0.0457 - accuracy: 0.9792 - val_loss: 0.2981 - val_accuracy: 0.9167\n",
      "Epoch 98/100\n",
      "10/10 - 0s - loss: 0.0844 - accuracy: 0.9688 - val_loss: 0.4410 - val_accuracy: 0.9167\n",
      "Epoch 99/100\n",
      "10/10 - 0s - loss: 0.0934 - accuracy: 0.9688 - val_loss: 0.2618 - val_accuracy: 0.9167\n",
      "Epoch 100/100\n",
      "10/10 - 0s - loss: 0.0624 - accuracy: 0.9792 - val_loss: 0.2445 - val_accuracy: 0.9167\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2445 - accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "# モデル生成\n",
    "def generate_model2(X):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=X.shape[1:]))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model2 = generate_model2(X_train2)\n",
    "    \n",
    "# コンパイル\n",
    "def compile_model2(model):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='RMSprop',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model2 = compile_model2(model2)\n",
    "\n",
    "# 学習〜予測〜評価\n",
    "def learning_evaluate2(model, X_train, y_train, X_val, y_val):\n",
    "    model.fit(X_train, y_train, \n",
    "             batch_size=10,\n",
    "             epochs=100,\n",
    "             verbose=2,\n",
    "             validation_data=(X_val, y_val))\n",
    "    pred = model.predict(X_val)\n",
    "    score = model.evaluate(X_val, y_val)\n",
    "    return pred, score\n",
    "\n",
    "pred2, score2 = learning_evaluate2(model2, X_train2, y_train2, X_val2, y_val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+00 2.59248640e-08 5.85907910e-18]\n",
      " [3.00478791e-06 2.23383051e-03 9.97763157e-01]\n",
      " [1.00000000e+00 1.26122810e-08 7.18309995e-19]\n",
      " [1.28562606e-05 9.99644279e-01 3.42887710e-04]\n",
      " [1.21932144e-05 9.99757349e-01 2.30536680e-04]\n",
      " [3.69617956e-05 9.98410344e-01 1.55259727e-03]\n",
      " [5.68936957e-05 1.16195651e-02 9.88323569e-01]\n",
      " [6.75769707e-06 3.37338005e-03 9.96619821e-01]\n",
      " [9.99999881e-01 1.01693225e-07 5.87084955e-17]\n",
      " [1.46327855e-03 1.94461793e-01 8.04074883e-01]\n",
      " [7.05397906e-05 9.97999489e-01 1.92995754e-03]\n",
      " [2.73101762e-07 5.55366219e-04 9.99444306e-01]\n",
      " [1.00000000e+00 5.88556137e-09 1.41568317e-19]\n",
      " [2.85381816e-06 2.01826287e-03 9.97978866e-01]\n",
      " [1.00000000e+00 4.32552909e-08 1.24544019e-17]\n",
      " [1.69192461e-07 4.27974126e-04 9.99571860e-01]\n",
      " [2.73991700e-05 9.99063313e-01 9.09348193e-04]\n",
      " [1.00000000e+00 1.09063925e-10 7.04530791e-23]\n",
      " [2.47192476e-03 3.97610039e-01 5.99918127e-01]\n",
      " [1.00000000e+00 5.60887266e-08 1.21988444e-17]\n",
      " [1.00000000e+00 5.35425961e-08 1.05877911e-17]\n",
      " [6.46805565e-04 1.23278625e-01 8.76074493e-01]\n",
      " [1.61232874e-05 5.68580441e-03 9.94298041e-01]\n",
      " [7.79850234e-04 1.13584712e-01 8.85635436e-01]]\n",
      "--------------------------------------------------\n",
      "0.24452687799930573\n",
      "0.9166666865348816\n"
     ]
    }
   ],
   "source": [
    "print(pred2)\n",
    "print(\"-\"*50)\n",
    "print(score2[0]) # loss\n",
    "print(score2[1]) # accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】House PricesをKerasで学習\n",
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dir_path = '/Users/yuki.tatsuoka/Downloads/house-prices-advanced-regression-techniques/'\n",
    "house_price_train = pd.read_csv(dir_path + 'train.csv')\n",
    "house_price_test = pd.read_csv(dir_path + 'test.csv')\n",
    "pd.set_option('display.max_rows', 300)\n",
    "\n",
    "\n",
    "y = house_price_train['SalePrice']\n",
    "X = house_price_train.drop(['SalePrice'], axis=1)\n",
    "\n",
    "# object型の変換と欠損値を埋めることが必須条件\n",
    "X = X.fillna(0)\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対数と標準化\n",
    "y_log = np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((934, 305), (934,), (234, 305))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y_log, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train3, X_val3, y_train3, y_val3 = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "X_train3.shape, y_train3.shape, X_val3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "94/94 - 1s - loss: 2884.2520 - val_loss: 28.3369\n",
      "Epoch 2/50\n",
      "94/94 - 0s - loss: 213.0573 - val_loss: 132.5678\n",
      "Epoch 3/50\n",
      "94/94 - 0s - loss: 95.8974 - val_loss: 132.4888\n",
      "Epoch 4/50\n",
      "94/94 - 0s - loss: 63.3652 - val_loss: 11.1965\n",
      "Epoch 5/50\n",
      "94/94 - 0s - loss: 123.8372 - val_loss: 7.0566\n",
      "Epoch 6/50\n",
      "94/94 - 0s - loss: 20.1396 - val_loss: 3.1489\n",
      "Epoch 7/50\n",
      "94/94 - 0s - loss: 17.1559 - val_loss: 1.8038\n",
      "Epoch 8/50\n",
      "94/94 - 0s - loss: 15.6823 - val_loss: 1.1308\n",
      "Epoch 9/50\n",
      "94/94 - 0s - loss: 12.5865 - val_loss: 0.9796\n",
      "Epoch 10/50\n",
      "94/94 - 0s - loss: 8.5612 - val_loss: 0.5217\n",
      "Epoch 11/50\n",
      "94/94 - 0s - loss: 82.2444 - val_loss: 2.9310\n",
      "Epoch 12/50\n",
      "94/94 - 0s - loss: 7.5305 - val_loss: 3.2436\n",
      "Epoch 13/50\n",
      "94/94 - 0s - loss: 8.3955 - val_loss: 0.6302\n",
      "Epoch 14/50\n",
      "94/94 - 0s - loss: 6.0256 - val_loss: 0.2879\n",
      "Epoch 15/50\n",
      "94/94 - 0s - loss: 18.6386 - val_loss: 7.2047\n",
      "Epoch 16/50\n",
      "94/94 - 0s - loss: 5.5022 - val_loss: 0.5529\n",
      "Epoch 17/50\n",
      "94/94 - 0s - loss: 4.7134 - val_loss: 2.4725\n",
      "Epoch 18/50\n",
      "94/94 - 0s - loss: 5.3584 - val_loss: 1.2544\n",
      "Epoch 19/50\n",
      "94/94 - 0s - loss: 5.5301 - val_loss: 0.7942\n",
      "Epoch 20/50\n",
      "94/94 - 0s - loss: 4.5324 - val_loss: 0.3219\n",
      "Epoch 21/50\n",
      "94/94 - 0s - loss: 5.4680 - val_loss: 5.8565\n",
      "Epoch 22/50\n",
      "94/94 - 0s - loss: 4.6660 - val_loss: 0.0638\n",
      "Epoch 23/50\n",
      "94/94 - 0s - loss: 4.7074 - val_loss: 0.1510\n",
      "Epoch 24/50\n",
      "94/94 - 0s - loss: 5.8843 - val_loss: 0.4349\n",
      "Epoch 25/50\n",
      "94/94 - 0s - loss: 4.4298 - val_loss: 0.2150\n",
      "Epoch 26/50\n",
      "94/94 - 0s - loss: 4.2546 - val_loss: 0.7293\n",
      "Epoch 27/50\n",
      "94/94 - 0s - loss: 4.0074 - val_loss: 0.0710\n",
      "Epoch 28/50\n",
      "94/94 - 0s - loss: 3.9343 - val_loss: 0.9962\n",
      "Epoch 29/50\n",
      "94/94 - 0s - loss: 4.3954 - val_loss: 6.9002\n",
      "Epoch 30/50\n",
      "94/94 - 0s - loss: 4.1502 - val_loss: 2.4301\n",
      "Epoch 31/50\n",
      "94/94 - 0s - loss: 9.0678 - val_loss: 0.0528\n",
      "Epoch 32/50\n",
      "94/94 - 0s - loss: 4.2692 - val_loss: 1.0494\n",
      "Epoch 33/50\n",
      "94/94 - 0s - loss: 7.2201 - val_loss: 3.9031\n",
      "Epoch 34/50\n",
      "94/94 - 0s - loss: 4.5063 - val_loss: 2.9939\n",
      "Epoch 35/50\n",
      "94/94 - 0s - loss: 3.8079 - val_loss: 0.3920\n",
      "Epoch 36/50\n",
      "94/94 - 0s - loss: 6.4786 - val_loss: 0.7343\n",
      "Epoch 37/50\n",
      "94/94 - 0s - loss: 4.0782 - val_loss: 0.3069\n",
      "Epoch 38/50\n",
      "94/94 - 0s - loss: 4.0934 - val_loss: 0.0403\n",
      "Epoch 39/50\n",
      "94/94 - 0s - loss: 5.0865 - val_loss: 2.2708\n",
      "Epoch 40/50\n",
      "94/94 - 0s - loss: 3.7418 - val_loss: 4.5683\n",
      "Epoch 41/50\n",
      "94/94 - 0s - loss: 3.3936 - val_loss: 0.2757\n",
      "Epoch 42/50\n",
      "94/94 - 0s - loss: 3.6818 - val_loss: 0.5607\n",
      "Epoch 43/50\n",
      "94/94 - 0s - loss: 3.5080 - val_loss: 3.6017\n",
      "Epoch 44/50\n",
      "94/94 - 0s - loss: 5.2484 - val_loss: 0.0514\n",
      "Epoch 45/50\n",
      "94/94 - 0s - loss: 3.3586 - val_loss: 0.0579\n",
      "Epoch 46/50\n",
      "94/94 - 0s - loss: 3.4228 - val_loss: 3.8174\n",
      "Epoch 47/50\n",
      "94/94 - 0s - loss: 4.1418 - val_loss: 0.6650\n",
      "Epoch 48/50\n",
      "94/94 - 0s - loss: 3.2788 - val_loss: 0.0806\n",
      "Epoch 49/50\n",
      "94/94 - 0s - loss: 4.8052 - val_loss: 0.6871\n",
      "Epoch 50/50\n",
      "94/94 - 0s - loss: 3.0874 - val_loss: 2.4213\n",
      "8/8 [==============================] - 0s 730us/step - loss: 2.4213\n"
     ]
    }
   ],
   "source": [
    "# 情報を１度リセット\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# モデル生成\n",
    "def generate_model3(X):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=X.shape[1:]))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    return model\n",
    "\n",
    "model3 = generate_model3(X_train3)\n",
    "    \n",
    "# コンパイル\n",
    "def compile_model3(model):\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                 optimizer='RMSprop')\n",
    "    return model\n",
    "\n",
    "model3 = compile_model3(model3)\n",
    "\n",
    "# 学習〜予測〜評価\n",
    "def learning_evaluate3(model, X_train, y_train, X_val, y_val):\n",
    "    model.fit(X_train, y_train, \n",
    "             batch_size=10,\n",
    "             epochs=50,\n",
    "             verbose=2,\n",
    "             validation_data=(X_val, y_val))\n",
    "    pred = model.predict(X_val)\n",
    "    score = model.evaluate(X_val, y_val)\n",
    "    return pred, score\n",
    "\n",
    "pred3, score3 = learning_evaluate3(model3, X_train3, y_train3, X_val3, y_val3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.294497 ]\n",
      " [ 9.931913 ]\n",
      " [10.59292  ]\n",
      " [10.753576 ]\n",
      " [10.421829 ]\n",
      " [10.369633 ]\n",
      " [10.226046 ]\n",
      " [10.887756 ]\n",
      " [10.697958 ]\n",
      " [10.453474 ]\n",
      " [10.898138 ]\n",
      " [10.759673 ]\n",
      " [10.377462 ]\n",
      " [10.611592 ]\n",
      " [10.519287 ]\n",
      " [10.429358 ]\n",
      " [10.344372 ]\n",
      " [10.326325 ]\n",
      " [ 9.945929 ]\n",
      " [10.182088 ]\n",
      " [10.276302 ]\n",
      " [10.420287 ]\n",
      " [10.381678 ]\n",
      " [10.358595 ]\n",
      " [ 9.964156 ]\n",
      " [10.403975 ]\n",
      " [10.263159 ]\n",
      " [10.661478 ]\n",
      " [10.612439 ]\n",
      " [10.386406 ]\n",
      " [10.291065 ]\n",
      " [10.91334  ]\n",
      " [10.690382 ]\n",
      " [10.227119 ]\n",
      " [10.629871 ]\n",
      " [10.261059 ]\n",
      " [10.371103 ]\n",
      " [10.350756 ]\n",
      " [10.341781 ]\n",
      " [10.378433 ]\n",
      " [10.422536 ]\n",
      " [10.35232  ]\n",
      " [10.237168 ]\n",
      " [10.58633  ]\n",
      " [10.783978 ]\n",
      " [10.755438 ]\n",
      " [10.353922 ]\n",
      " [10.592376 ]\n",
      " [10.238395 ]\n",
      " [10.540099 ]\n",
      " [10.346765 ]\n",
      " [10.166983 ]\n",
      " [10.610328 ]\n",
      " [11.079455 ]\n",
      " [10.270264 ]\n",
      " [11.055691 ]\n",
      " [11.364849 ]\n",
      " [10.425469 ]\n",
      " [10.301411 ]\n",
      " [10.687977 ]\n",
      " [11.250284 ]\n",
      " [10.783877 ]\n",
      " [10.2330475]\n",
      " [10.9694395]\n",
      " [10.246107 ]\n",
      " [10.926512 ]\n",
      " [10.345179 ]\n",
      " [10.415503 ]\n",
      " [10.984261 ]\n",
      " [ 9.980065 ]\n",
      " [10.155104 ]\n",
      " [10.054904 ]\n",
      " [10.728565 ]\n",
      " [ 9.955953 ]\n",
      " [10.942485 ]\n",
      " [10.213846 ]\n",
      " [10.785561 ]\n",
      " [10.4264145]\n",
      " [10.10081  ]\n",
      " [10.785727 ]\n",
      " [10.301739 ]\n",
      " [10.223017 ]\n",
      " [10.2110615]\n",
      " [10.17204  ]\n",
      " [10.905436 ]\n",
      " [10.978259 ]\n",
      " [10.558382 ]\n",
      " [10.635995 ]\n",
      " [10.859015 ]\n",
      " [10.91851  ]\n",
      " [10.400715 ]\n",
      " [10.582542 ]\n",
      " [10.462368 ]\n",
      " [10.098716 ]\n",
      " [10.516165 ]\n",
      " [10.296267 ]\n",
      " [10.628378 ]\n",
      " [ 9.925226 ]\n",
      " [10.155652 ]\n",
      " [10.114433 ]\n",
      " [10.837962 ]\n",
      " [10.11481  ]\n",
      " [10.106232 ]\n",
      " [10.116865 ]\n",
      " [10.304645 ]\n",
      " [10.468533 ]\n",
      " [10.388727 ]\n",
      " [11.014112 ]\n",
      " [10.605785 ]\n",
      " [ 9.964554 ]\n",
      " [10.511427 ]\n",
      " [10.428571 ]\n",
      " [10.185028 ]\n",
      " [10.258256 ]\n",
      " [10.49776  ]\n",
      " [10.965949 ]\n",
      " [10.446977 ]\n",
      " [10.65852  ]\n",
      " [10.48743  ]\n",
      " [10.482658 ]\n",
      " [10.32617  ]\n",
      " [10.5359745]\n",
      " [10.591015 ]\n",
      " [10.481041 ]\n",
      " [10.64683  ]\n",
      " [10.702009 ]\n",
      " [10.72789  ]\n",
      " [10.109235 ]\n",
      " [10.622494 ]\n",
      " [10.216408 ]\n",
      " [10.357555 ]\n",
      " [11.126153 ]\n",
      " [10.764969 ]\n",
      " [ 9.928642 ]\n",
      " [10.66864  ]\n",
      " [10.50217  ]\n",
      " [10.520609 ]\n",
      " [11.116622 ]\n",
      " [10.595062 ]\n",
      " [10.56117  ]\n",
      " [11.062976 ]\n",
      " [11.079991 ]\n",
      " [10.590744 ]\n",
      " [10.494161 ]\n",
      " [10.188288 ]\n",
      " [10.430491 ]\n",
      " [ 9.991276 ]\n",
      " [10.138999 ]\n",
      " [10.664307 ]\n",
      " [10.5626545]\n",
      " [ 9.971028 ]\n",
      " [10.26034  ]\n",
      " [10.323264 ]\n",
      " [10.339205 ]\n",
      " [10.711571 ]\n",
      " [10.273226 ]\n",
      " [10.267626 ]\n",
      " [10.133166 ]\n",
      " [10.559645 ]\n",
      " [10.699179 ]\n",
      " [10.366816 ]\n",
      " [10.385496 ]\n",
      " [10.603033 ]\n",
      " [10.211423 ]\n",
      " [10.330742 ]\n",
      " [10.057067 ]\n",
      " [10.345444 ]\n",
      " [10.653913 ]\n",
      " [10.225995 ]\n",
      " [10.477184 ]\n",
      " [10.803446 ]\n",
      " [11.529391 ]\n",
      " [10.867586 ]\n",
      " [10.1853695]\n",
      " [10.741838 ]\n",
      " [10.1282215]\n",
      " [10.552861 ]\n",
      " [10.149572 ]\n",
      " [10.067757 ]\n",
      " [10.297506 ]\n",
      " [10.032103 ]\n",
      " [10.668647 ]\n",
      " [10.651977 ]\n",
      " [10.826656 ]\n",
      " [10.095074 ]\n",
      " [10.336332 ]\n",
      " [10.565771 ]\n",
      " [10.396349 ]\n",
      " [10.164061 ]\n",
      " [10.346859 ]\n",
      " [10.350126 ]\n",
      " [10.490667 ]\n",
      " [11.489389 ]\n",
      " [11.079229 ]\n",
      " [10.413923 ]\n",
      " [10.080293 ]\n",
      " [ 9.934488 ]\n",
      " [10.179966 ]\n",
      " [10.662071 ]\n",
      " [10.353586 ]\n",
      " [10.298507 ]\n",
      " [10.143829 ]\n",
      " [10.292318 ]\n",
      " [10.079422 ]\n",
      " [10.218989 ]\n",
      " [10.540831 ]\n",
      " [10.127511 ]\n",
      " [11.024666 ]\n",
      " [10.364692 ]\n",
      " [10.151506 ]\n",
      " [10.607832 ]\n",
      " [10.799543 ]\n",
      " [10.598207 ]\n",
      " [10.776316 ]\n",
      " [10.492397 ]\n",
      " [11.088167 ]\n",
      " [10.402048 ]\n",
      " [10.71728  ]\n",
      " [10.960808 ]\n",
      " [10.907089 ]\n",
      " [10.391071 ]\n",
      " [10.399598 ]\n",
      " [10.485465 ]\n",
      " [10.461941 ]\n",
      " [10.167961 ]\n",
      " [10.140504 ]\n",
      " [10.787415 ]\n",
      " [10.85667  ]\n",
      " [10.098928 ]\n",
      " [10.261866 ]\n",
      " [10.343324 ]\n",
      " [11.173262 ]\n",
      " [10.339364 ]\n",
      " [10.185565 ]]\n",
      "--------------------------------------------------\n",
      "2.421299457550049\n"
     ]
    }
   ],
   "source": [
    "print(pred3)\n",
    "print(\"-\"*50)\n",
    "print(score3) # loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】MNISTをKerasで学習\n",
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 28, 28, 1), (48000, 10), (12000, 28, 28, 1))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# さらにtrainとvalに分割\n",
    "X_train4, X_val4, y_train4, y_val4 = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
    "X_train4.shape, y_train4.shape, X_val4.shape\n",
    "\n",
    "# ワンホット\n",
    "y_train4 = to_categorical(y_train4)\n",
    "y_val4 = to_categorical(y_val4)\n",
    "\n",
    "# チャネルの追加\n",
    "X_train4 = X_train4.reshape(-1,28,28,1)\n",
    "X_val4 = X_val4.reshape(-1,28,28,1)\n",
    "\n",
    "X_train4.shape, y_train4.shape, X_val4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "240/240 - 20s - loss: 0.9495 - accuracy: 0.7944 - val_loss: 0.1000 - val_accuracy: 0.9731\n",
      "Epoch 2/10\n",
      "240/240 - 43s - loss: 0.1395 - accuracy: 0.9641 - val_loss: 0.0662 - val_accuracy: 0.9822\n",
      "Epoch 3/10\n",
      "240/240 - 35s - loss: 0.0910 - accuracy: 0.9770 - val_loss: 0.0938 - val_accuracy: 0.9761\n",
      "Epoch 4/10\n",
      "240/240 - 28s - loss: 0.0731 - accuracy: 0.9810 - val_loss: 0.0490 - val_accuracy: 0.9880\n",
      "Epoch 5/10\n",
      "240/240 - 25s - loss: 0.0591 - accuracy: 0.9847 - val_loss: 0.0551 - val_accuracy: 0.9881\n",
      "Epoch 6/10\n",
      "240/240 - 26s - loss: 0.0508 - accuracy: 0.9873 - val_loss: 0.0542 - val_accuracy: 0.9872\n",
      "Epoch 7/10\n",
      "240/240 - 19s - loss: 0.0412 - accuracy: 0.9893 - val_loss: 0.0545 - val_accuracy: 0.9876\n",
      "Epoch 8/10\n",
      "240/240 - 27s - loss: 0.0399 - accuracy: 0.9899 - val_loss: 0.0504 - val_accuracy: 0.9892\n",
      "Epoch 9/10\n",
      "240/240 - 23s - loss: 0.0358 - accuracy: 0.9912 - val_loss: 0.0511 - val_accuracy: 0.9895\n",
      "Epoch 10/10\n",
      "240/240 - 25s - loss: 0.0330 - accuracy: 0.9918 - val_loss: 0.0475 - val_accuracy: 0.9893\n",
      "375/375 [==============================] - 3s 7ms/step - loss: 0.0475 - accuracy: 0.9893\n"
     ]
    }
   ],
   "source": [
    "# モデル生成\n",
    "def generate_model4(X):\n",
    "    model = Sequential()\n",
    "    Conv2D, MaxPool2D\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=(3,3), padding='same', input_shape=X.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Conv2D(64, kernel_size=(3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model4 = generate_model4(X_train4)\n",
    "    \n",
    "# コンパイル\n",
    "def compile_model4(model):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='RMSprop',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model4 = compile_model4(model4)\n",
    "\n",
    "# 学習〜予測〜評価\n",
    "def learning_evaluate4(model, X_train, y_train, X_val, y_val):\n",
    "    history = model.fit(X_train, y_train, \n",
    "             batch_size=200,\n",
    "             epochs=10,\n",
    "             verbose=2,\n",
    "             validation_data=(X_val, y_val))\n",
    "    pred = model.predict(X_val)\n",
    "    score = model.evaluate(X_val, y_val)\n",
    "    return history, pred, score\n",
    "\n",
    "history, pred4, score4 = learning_evaluate4(model4, X_train4, y_train4, X_val4, y_val4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.1871069e-17 1.5434344e-29 3.5443342e-15 ... 9.9585237e-20\n",
      "  5.8374699e-15 2.2344327e-19]\n",
      " [2.1665350e-10 1.1452689e-22 1.9113899e-23 ... 2.0906006e-19\n",
      "  4.4891686e-14 1.1669907e-19]\n",
      " [1.5132775e-08 3.7388636e-17 7.3652129e-17 ... 3.0698825e-15\n",
      "  3.3357520e-12 3.4938464e-15]\n",
      " ...\n",
      " [4.9897803e-14 1.0184955e-21 6.7238731e-19 ... 6.0966293e-10\n",
      "  6.1884601e-13 4.3386274e-11]\n",
      " [7.2186239e-09 9.9999964e-01 7.1533862e-08 ... 3.1197320e-10\n",
      "  1.9082248e-07 4.8933384e-08]\n",
      " [9.1876076e-11 5.1872006e-23 1.3034000e-23 ... 2.5179667e-20\n",
      "  1.6703527e-15 2.7750410e-20]]\n",
      "--------------------------------------------------\n",
      "0.04750441014766693\n",
      "0.9892500042915344\n"
     ]
    }
   ],
   "source": [
    "# 予測数値と損失と評価の確認\n",
    "print(pred4)\n",
    "print(\"-\"*50)\n",
    "print(score4[0]) # loss\n",
    "print(score4[1]) # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[ 0.0507528 , -0.04234311,  0.05209729, -0.10917363,\n",
       "           -0.01865141, -0.07068711,  0.02367098,  0.04977283,\n",
       "           -0.11645245,  0.03383624, -0.03970184,  0.0464965 ,\n",
       "            0.00333867, -0.00424803,  0.01026364,  0.03834292,\n",
       "           -0.07254401, -0.0994952 , -0.01410242, -0.13971601,\n",
       "           -0.06558211, -0.06763384,  0.01114204,  0.02722306,\n",
       "           -0.06036509, -0.12916164, -0.08977292, -0.03491903,\n",
       "           -0.20599626, -0.01597884, -0.0814885 , -0.11269344]],\n",
       " \n",
       "         [[ 0.04543024,  0.08034417, -0.05681614,  0.0529106 ,\n",
       "            0.04466083, -0.10623419,  0.0626259 ,  0.0088357 ,\n",
       "           -0.04772372, -0.12689574, -0.04812716,  0.03832018,\n",
       "           -0.1634425 ,  0.08152449, -0.0209031 , -0.02923365,\n",
       "            0.08367016,  0.08368703, -0.1536215 ,  0.07478874,\n",
       "            0.05923582,  0.00072663, -0.12934716, -0.06011619,\n",
       "           -0.09711666,  0.05176982, -0.01039968,  0.0574679 ,\n",
       "            0.04096891,  0.05059408,  0.1304165 ,  0.07990922]],\n",
       " \n",
       "         [[-0.14554524,  0.03276976,  0.00934362,  0.04665159,\n",
       "            0.10697143, -0.07387035, -0.1100556 , -0.08500864,\n",
       "            0.03646068,  0.0410647 , -0.03302506,  0.06819116,\n",
       "            0.01931466, -0.00763893, -0.0896548 , -0.10115728,\n",
       "           -0.08483189, -0.04502795, -0.11139135,  0.09258191,\n",
       "           -0.02847411,  0.01838646,  0.06011102,  0.02125559,\n",
       "           -0.02067352, -0.03716293,  0.04469389, -0.03146354,\n",
       "            0.04129849, -0.04303499, -0.0457787 , -0.04609501]]],\n",
       " \n",
       " \n",
       "        [[[-0.09366521,  0.03572115, -0.029308  ,  0.07908   ,\n",
       "           -0.17951716,  0.02973586,  0.09020863,  0.03613176,\n",
       "            0.01905411, -0.21209815, -0.00658932,  0.064537  ,\n",
       "           -0.20856449,  0.01328565,  0.08463573, -0.00357322,\n",
       "           -0.08823886, -0.06039536, -0.17063463,  0.05324853,\n",
       "           -0.06602655, -0.01766306,  0.0894268 , -0.0687229 ,\n",
       "            0.0048109 , -0.02120677,  0.10192921, -0.05625126,\n",
       "           -0.08125679,  0.0643225 , -0.00163469,  0.0635521 ]],\n",
       " \n",
       "         [[ 0.01960449, -0.01291154,  0.11547478, -0.09173025,\n",
       "            0.02677639,  0.09606399, -0.04384525,  0.03275119,\n",
       "           -0.0607582 , -0.1003962 ,  0.06973153,  0.02974525,\n",
       "            0.11650082, -0.12611495,  0.06044424,  0.08124049,\n",
       "           -0.05218713,  0.09431018,  0.05298386, -0.10639604,\n",
       "           -0.01723344, -0.09854237, -0.06166393,  0.00973287,\n",
       "            0.01131595,  0.03480218,  0.09170663,  0.05777141,\n",
       "           -0.05116745,  0.08952332,  0.10147069,  0.03177823]],\n",
       " \n",
       "         [[ 0.00711014,  0.11715556, -0.10905987,  0.04669064,\n",
       "           -0.13451889, -0.00622044, -0.02833156,  0.10238299,\n",
       "            0.03125224, -0.02301752,  0.09336273, -0.06151707,\n",
       "            0.03769508, -0.0674853 , -0.10898209,  0.06270561,\n",
       "            0.05556163,  0.08444007, -0.00611264, -0.03363908,\n",
       "           -0.13910082, -0.13243584,  0.03917771, -0.0299495 ,\n",
       "            0.0674955 ,  0.0302703 , -0.0907098 , -0.06752522,\n",
       "            0.06121897, -0.00547299,  0.00273145,  0.01979308]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0580134 , -0.07816149, -0.10405885, -0.0068004 ,\n",
       "            0.10641913, -0.01482448,  0.02829823,  0.01395555,\n",
       "            0.06317331,  0.03724614,  0.02671101, -0.0791311 ,\n",
       "           -0.16381027, -0.04986102,  0.01153233, -0.01522148,\n",
       "           -0.17529844, -0.07511143, -0.17351267, -0.11243659,\n",
       "           -0.07807234,  0.07135475,  0.07400288,  0.00290829,\n",
       "            0.11471828,  0.05225286, -0.06811772, -0.14096084,\n",
       "           -0.10749988, -0.1612382 ,  0.00190228, -0.02813276]],\n",
       " \n",
       "         [[-0.07371073, -0.12025164,  0.0298333 ,  0.04209278,\n",
       "           -0.04368135, -0.02054739, -0.05501436, -0.07977785,\n",
       "           -0.07541474, -0.03439931, -0.01599904,  0.02419549,\n",
       "           -0.07554626,  0.07575656,  0.05648507,  0.02331761,\n",
       "           -0.07604378, -0.11166045,  0.04154015,  0.07697707,\n",
       "           -0.11029228,  0.12568066, -0.04553455,  0.01023991,\n",
       "           -0.07490126, -0.01986715, -0.09831966, -0.10792879,\n",
       "           -0.05862899, -0.07101241, -0.08278299,  0.00828649]],\n",
       " \n",
       "         [[ 0.1042854 , -0.06949274,  0.04577465, -0.01640579,\n",
       "            0.0251666 , -0.06816945,  0.03236341, -0.01501493,\n",
       "           -0.03753081,  0.01015733, -0.07188519, -0.03011339,\n",
       "            0.03631767,  0.01015561,  0.09064231, -0.04489496,\n",
       "           -0.05959759, -0.12334747,  0.08415747, -0.18344353,\n",
       "            0.07110459, -0.08701498, -0.00667806,  0.01296654,\n",
       "            0.0514689 ,  0.03413695,  0.0143922 , -0.00065213,\n",
       "           -0.02057139,  0.0494602 , -0.02662886,  0.00889744]]]],\n",
       "       dtype=float32),\n",
       " array([-0.14675714,  0.08943294,  0.08853037, -0.12430353,  0.18922156,\n",
       "         0.00718419, -0.08266277,  0.1914335 ,  0.1432306 , -0.15806505,\n",
       "        -0.09218463,  0.23298725, -0.06568588,  0.16492704, -0.11595712,\n",
       "        -0.13421547, -0.00161322,  0.1745528 , -0.0223939 ,  0.1409732 ,\n",
       "        -0.01303039,  0.05049044,  0.12598369, -0.18779776,  0.24664514,\n",
       "         0.16446128,  0.20696594, -0.01990511, -0.06864169, -0.10903849,\n",
       "         0.18862608, -0.16703229], dtype=float32),\n",
       " array([[[[ 0.03052911,  0.07629229,  0.08580829, ..., -0.04776844,\n",
       "           -0.03134943, -0.03360716],\n",
       "          [ 0.0459174 , -0.06185709,  0.0566835 , ..., -0.06198327,\n",
       "            0.01788727, -0.0651252 ],\n",
       "          [ 0.068635  , -0.02126308,  0.09877936, ..., -0.05466398,\n",
       "            0.00266763, -0.08808927],\n",
       "          ...,\n",
       "          [-0.04136406, -0.05690024, -0.06955067, ..., -0.05016247,\n",
       "           -0.05131162, -0.04949017],\n",
       "          [ 0.01574282,  0.0756896 ,  0.03824782, ..., -0.07753111,\n",
       "            0.00049945, -0.01009232],\n",
       "          [-0.07462373,  0.04023515,  0.0095217 , ..., -0.03308636,\n",
       "           -0.03790916, -0.09946981]],\n",
       " \n",
       "         [[-0.06818929, -0.07685944,  0.03365813, ..., -0.13864353,\n",
       "            0.03638454,  0.06694323],\n",
       "          [ 0.07765087, -0.02858874,  0.05245732, ...,  0.04002636,\n",
       "            0.08624135, -0.07619707],\n",
       "          [-0.03599616, -0.0403697 ,  0.05043806, ..., -0.03333426,\n",
       "           -0.04103629, -0.07693289],\n",
       "          ...,\n",
       "          [-0.07913402, -0.03255072, -0.07279955, ..., -0.04499608,\n",
       "            0.04036919,  0.05417523],\n",
       "          [-0.01982327, -0.04872703, -0.04702651, ...,  0.06367429,\n",
       "            0.04977739, -0.08420648],\n",
       "          [-0.04867749, -0.04967841,  0.00546976, ..., -0.01396048,\n",
       "            0.00933154, -0.05597097]],\n",
       " \n",
       "         [[ 0.03587355,  0.06127794, -0.03270765, ...,  0.03908584,\n",
       "            0.06729104, -0.02125418],\n",
       "          [ 0.01247995, -0.10218909, -0.03144895, ...,  0.00138153,\n",
       "           -0.1072414 ,  0.02406763],\n",
       "          [ 0.0185064 , -0.03300191,  0.01155839, ..., -0.09270694,\n",
       "            0.04878685, -0.04494788],\n",
       "          ...,\n",
       "          [ 0.02576211, -0.15593094,  0.0299    , ..., -0.09866928,\n",
       "           -0.05185771, -0.11312581],\n",
       "          [-0.03606063, -0.09672797, -0.06320889, ...,  0.00079643,\n",
       "            0.01298221, -0.04910963],\n",
       "          [ 0.01664221, -0.03354888,  0.05424487, ...,  0.08640552,\n",
       "           -0.08072795,  0.00309456]]],\n",
       " \n",
       " \n",
       "        [[[ 0.06437783, -0.02816686,  0.00472099, ..., -0.03090521,\n",
       "           -0.04010085, -0.09711529],\n",
       "          [-0.06572189, -0.04928562,  0.00440137, ...,  0.0868627 ,\n",
       "           -0.04204996, -0.04787254],\n",
       "          [-0.01243985,  0.00241911, -0.00748743, ..., -0.07165628,\n",
       "           -0.07367676, -0.1452819 ],\n",
       "          ...,\n",
       "          [-0.08487536, -0.01128792, -0.01825299, ..., -0.00944849,\n",
       "            0.00209383, -0.1479459 ],\n",
       "          [ 0.04182349,  0.01775679, -0.14288177, ...,  0.08160485,\n",
       "           -0.03781548, -0.10963979],\n",
       "          [ 0.02866816,  0.05263061, -0.02839364, ...,  0.08943488,\n",
       "            0.01776802,  0.00344849]],\n",
       " \n",
       "         [[ 0.03414326, -0.12972207,  0.02999964, ..., -0.13912655,\n",
       "            0.03371123, -0.10297811],\n",
       "          [ 0.05504497, -0.04013301, -0.03075854, ...,  0.05092364,\n",
       "           -0.03975592,  0.09011851],\n",
       "          [-0.02529827, -0.06039724, -0.05760616, ..., -0.04279389,\n",
       "           -0.07691938,  0.05906453],\n",
       "          ...,\n",
       "          [ 0.06920665, -0.02926124,  0.03366628, ...,  0.05745085,\n",
       "           -0.05366202, -0.09007449],\n",
       "          [ 0.05407982, -0.08845665,  0.01479182, ..., -0.04388155,\n",
       "            0.01987405,  0.0262223 ],\n",
       "          [-0.03404863, -0.03562857, -0.04298813, ..., -0.01885064,\n",
       "           -0.01139148, -0.07096481]],\n",
       " \n",
       "         [[-0.00852731, -0.04797467,  0.01628301, ..., -0.13271233,\n",
       "           -0.0126745 , -0.0116447 ],\n",
       "          [ 0.03912828, -0.08471652,  0.03948368, ..., -0.01147602,\n",
       "            0.00128832,  0.07034505],\n",
       "          [-0.1213323 , -0.06858347, -0.00573788, ...,  0.0174482 ,\n",
       "            0.07465467, -0.08419705],\n",
       "          ...,\n",
       "          [-0.00530419,  0.0267267 , -0.01208841, ..., -0.01121165,\n",
       "           -0.04611271,  0.04502311],\n",
       "          [-0.00951287, -0.06084433, -0.04196607, ...,  0.09096433,\n",
       "            0.00297328,  0.08555562],\n",
       "          [-0.02148105, -0.01908841,  0.01476027, ..., -0.05861354,\n",
       "            0.03164873, -0.06190589]]],\n",
       " \n",
       " \n",
       "        [[[ 0.02696332,  0.0884958 , -0.00487604, ...,  0.03820758,\n",
       "            0.03168925, -0.01074412],\n",
       "          [-0.01811737, -0.07346507, -0.02270703, ..., -0.05556239,\n",
       "           -0.02775129, -0.09837908],\n",
       "          [-0.07251642,  0.007925  , -0.06411951, ...,  0.0754476 ,\n",
       "            0.08674531, -0.08455621],\n",
       "          ...,\n",
       "          [ 0.01802128, -0.04784064,  0.03006569, ...,  0.03305451,\n",
       "            0.01020197, -0.03932192],\n",
       "          [-0.07698575, -0.09354675, -0.04328193, ...,  0.06520475,\n",
       "           -0.08307661, -0.10403137],\n",
       "          [ 0.08197765, -0.06983766, -0.00919574, ..., -0.08630217,\n",
       "            0.01772015,  0.08108547]],\n",
       " \n",
       "         [[-0.01827769,  0.00727157, -0.02859446, ...,  0.12532762,\n",
       "           -0.01957717,  0.02046538],\n",
       "          [-0.02849615, -0.03413283,  0.00415811, ...,  0.06780498,\n",
       "           -0.05015037, -0.10608963],\n",
       "          [ 0.01902614,  0.10536069, -0.01817984, ...,  0.02107732,\n",
       "           -0.07639883,  0.06166856],\n",
       "          ...,\n",
       "          [-0.00470809, -0.00796652, -0.10646268, ...,  0.01237959,\n",
       "            0.03121314, -0.041602  ],\n",
       "          [-0.1168669 , -0.10516897, -0.03400434, ..., -0.00440871,\n",
       "           -0.0250458 , -0.08246388],\n",
       "          [-0.02612821,  0.09171985, -0.02415219, ...,  0.02081871,\n",
       "           -0.09355677, -0.01386729]],\n",
       " \n",
       "         [[ 0.05230666, -0.02845621, -0.03976187, ...,  0.01201414,\n",
       "            0.00658844,  0.03918707],\n",
       "          [-0.03375735, -0.04056172, -0.0799782 , ..., -0.04349519,\n",
       "           -0.04350138, -0.0137803 ],\n",
       "          [-0.07986832, -0.0392847 ,  0.0513218 , ...,  0.11459322,\n",
       "            0.01313764, -0.00155816],\n",
       "          ...,\n",
       "          [ 0.02466984, -0.09367663, -0.08859771, ..., -0.09193873,\n",
       "            0.02491747, -0.0534605 ],\n",
       "          [-0.02224424, -0.0352579 ,  0.03320769, ..., -0.15494   ,\n",
       "           -0.04144316, -0.018552  ],\n",
       "          [ 0.04131475,  0.05657952, -0.08483268, ..., -0.06452134,\n",
       "           -0.08573744, -0.03143267]]]], dtype=float32),\n",
       " array([-0.13832872, -0.02098022, -0.07012076, -0.06406052, -0.01798842,\n",
       "         0.0281261 , -0.09104335, -0.06874964, -0.11742526, -0.12237335,\n",
       "        -0.09014865, -0.09176368, -0.09348405, -0.05482086, -0.08927803,\n",
       "        -0.03176233, -0.07015593, -0.06921391, -0.09158763, -0.09046825,\n",
       "        -0.13519172, -0.07070434, -0.11957075, -0.06816182, -0.06256925,\n",
       "        -0.12938426, -0.03779789, -0.10600396, -0.09509995, -0.11391073,\n",
       "        -0.11033321, -0.06104424, -0.13156962, -0.09486871, -0.09774889,\n",
       "        -0.08488874, -0.07760137, -0.09281742, -0.07407494, -0.12314431,\n",
       "        -0.12565306, -0.08342066,  0.02176459, -0.08867308, -0.08631231,\n",
       "        -0.11762314, -0.07775316, -0.1169436 , -0.08848581, -0.07905289,\n",
       "        -0.01998678, -0.08364877, -0.1021131 , -0.07538079, -0.07672469,\n",
       "        -0.10213168, -0.05248967, -0.10387786, -0.11683285, -0.08350469,\n",
       "        -0.06902413, -0.07857703, -0.08331881, -0.14020398], dtype=float32),\n",
       " array([[ 0.04272868,  0.04544929, -0.04298807, ...,  0.03738277,\n",
       "          0.01210142, -0.00039398],\n",
       "        [ 0.0240969 ,  0.06266201, -0.0262643 , ...,  0.01843121,\n",
       "         -0.0325156 , -0.03407513],\n",
       "        [ 0.03967037, -0.01147513, -0.01448674, ...,  0.04899536,\n",
       "         -0.03209843, -0.0097968 ],\n",
       "        ...,\n",
       "        [ 0.03017074,  0.04411155,  0.01818551, ..., -0.00374614,\n",
       "          0.07196883, -0.00732638],\n",
       "        [-0.0205107 , -0.01833403,  0.00776777, ..., -0.02820788,\n",
       "          0.02897698, -0.00010327],\n",
       "        [-0.05390359,  0.02184611,  0.01587404, ..., -0.02619016,\n",
       "         -0.03890383,  0.00524113]], dtype=float32),\n",
       " array([ 0.08834331, -0.01338605, -0.02097802, -0.08749025, -0.03827456,\n",
       "        -0.0104878 , -0.08719275, -0.11489395, -0.00520079, -0.03747476,\n",
       "         0.00301691,  0.03013782, -0.04434531, -0.0019483 , -0.03015894,\n",
       "        -0.07216232, -0.00826801, -0.02137596, -0.00591166, -0.01660633,\n",
       "         0.05409605, -0.03253012, -0.07899711, -0.02657226, -0.00359153,\n",
       "        -0.00234131,  0.01266427, -0.0861932 , -0.08696319, -0.05572478,\n",
       "        -0.00754384, -0.02327579, -0.03614806, -0.04165572, -0.06269149,\n",
       "         0.03346217,  0.01986516, -0.03290851, -0.1339765 , -0.02594749,\n",
       "         0.00675289, -0.01968383, -0.00360625, -0.0354481 , -0.04516971,\n",
       "        -0.01532227, -0.01296416, -0.00549999, -0.04684253, -0.08051782,\n",
       "        -0.07282168,  0.01952486, -0.02977298, -0.06261219, -0.06252052,\n",
       "         0.01761007, -0.09148541,  0.01278926, -0.03195019, -0.08179457,\n",
       "        -0.00260225,  0.03094086, -0.09144635, -0.05440309, -0.03428013,\n",
       "        -0.04468303, -0.04919085, -0.05564486, -0.05524348, -0.01969836,\n",
       "         0.01451294, -0.00070328, -0.04772521, -0.08343862, -0.02018514,\n",
       "        -0.08928053, -0.05259139, -0.05642418, -0.02618968, -0.03021721,\n",
       "        -0.03095407, -0.06943661, -0.10735755,  0.05126618, -0.06873368,\n",
       "        -0.04415263, -0.02297433,  0.01423648, -0.00458925, -0.0491789 ,\n",
       "         0.00436479,  0.0139969 , -0.09295376,  0.02610052, -0.03662524,\n",
       "        -0.04751249,  0.08968344, -0.00463769,  0.01311995,  0.06256684,\n",
       "        -0.10119622, -0.02975378, -0.00951   , -0.02785999, -0.01871213,\n",
       "        -0.0066997 , -0.06383331, -0.02069001, -0.02722296, -0.02842375,\n",
       "        -0.03653119, -0.01787208, -0.09026251,  0.06198986, -0.03844425,\n",
       "         0.00171587,  0.05326362, -0.04489674, -0.03662599, -0.00211366,\n",
       "        -0.05627472, -0.06366155, -0.00664948, -0.06077289, -0.04794493,\n",
       "        -0.09311505, -0.02956719, -0.06608898], dtype=float32),\n",
       " array([[ 0.12620778, -0.13243978,  0.02882789, ..., -0.17757392,\n",
       "         -0.11202057, -0.102288  ],\n",
       "        [ 0.00176447,  0.10363047, -0.07588096, ...,  0.10772363,\n",
       "          0.08960507, -0.17929322],\n",
       "        [-0.04776531, -0.07033937, -0.10832899, ...,  0.10222423,\n",
       "          0.0684135 , -0.00385675],\n",
       "        ...,\n",
       "        [ 0.11234289,  0.00513965, -0.00544916, ..., -0.0571984 ,\n",
       "         -0.14329275, -0.01428564],\n",
       "        [ 0.02079273,  0.16615763,  0.00892289, ..., -0.18464181,\n",
       "          0.11293986, -0.02741585],\n",
       "        [-0.10949837, -0.08291076, -0.00806527, ...,  0.18445589,\n",
       "         -0.12024315, -0.1113534 ]], dtype=float32),\n",
       " array([-0.01509009, -0.00393834, -0.03314264,  0.00234615,  0.0128903 ,\n",
       "        -0.03021533,  0.02090072, -0.01538065,  0.01323627, -0.03430571,\n",
       "        -0.04316077, -0.07095329,  0.05929271, -0.06932118, -0.02071351,\n",
       "        -0.00288096, -0.00651962, -0.02140041, -0.03388948,  0.04902606,\n",
       "        -0.0482126 , -0.02157027, -0.02874898, -0.0330033 , -0.06313879,\n",
       "        -0.05120289, -0.00425646, -0.04039067, -0.03810089, -0.00533436,\n",
       "         0.01360231, -0.04159497, -0.0134693 , -0.02292124, -0.01366931,\n",
       "        -0.02650946,  0.0045597 , -0.01978034, -0.02925166, -0.03743357,\n",
       "        -0.00478724, -0.00213271, -0.01590202, -0.01985645, -0.00626436,\n",
       "        -0.035517  , -0.01073971, -0.06929629, -0.03250717, -0.04104151,\n",
       "        -0.06529345, -0.04748264,  0.00895635, -0.01566745, -0.04266071,\n",
       "         0.01263706, -0.03815928, -0.04938693, -0.0267436 , -0.05487336,\n",
       "        -0.03267105,  0.0116965 ,  0.01759315, -0.01287823], dtype=float32),\n",
       " array([[ 0.2130582 ,  0.23915476, -0.19442576, ...,  0.21733445,\n",
       "          0.12224852,  0.05099089],\n",
       "        [ 0.07194555,  0.22301109, -0.19739336, ..., -0.11824188,\n",
       "          0.08759657,  0.16309083],\n",
       "        [ 0.03699481,  0.07165281, -0.19230218, ..., -0.12098995,\n",
       "          0.20901728,  0.07119919],\n",
       "        ...,\n",
       "        [ 0.28022188, -0.17834267, -0.06100146, ..., -0.03058381,\n",
       "          0.07931388, -0.21989743],\n",
       "        [-0.00491355,  0.06976098, -0.15570174, ...,  0.23011255,\n",
       "         -0.24759568,  0.08401341],\n",
       "        [-0.02930109,  0.0393033 , -0.18636999, ...,  0.08252594,\n",
       "         -0.16261488,  0.21706814]], dtype=float32),\n",
       " array([ 0.08414837,  0.03185783, -0.0289798 ,  0.12235153, -0.06231462,\n",
       "        -0.10012902, -0.0496446 ,  0.01034049, -0.06171032,  0.02313853,\n",
       "        -0.00207969, -0.03330955, -0.02175511, -0.06770409,  0.02510747,\n",
       "         0.01036314, -0.07219198, -0.05976736, -0.03278033, -0.03390712,\n",
       "        -0.00655361, -0.09061582, -0.03129241, -0.07420065,  0.07428479,\n",
       "        -0.04266839, -0.03084253, -0.01072272, -0.04739288,  0.07653291,\n",
       "        -0.07217662, -0.04398242], dtype=float32),\n",
       " array([[ 0.15256378, -0.09259378, -0.10091591, ..., -0.30935207,\n",
       "          0.08695785, -0.09523263],\n",
       "        [-0.1303795 , -0.11097452, -0.01568682, ...,  0.05242138,\n",
       "          0.02512899,  0.08372388],\n",
       "        [-0.13158387,  0.03810525, -0.08265734, ..., -0.12114921,\n",
       "          0.16895773,  0.07668993],\n",
       "        ...,\n",
       "        [-0.15412723, -0.0680474 ,  0.2137022 , ...,  0.17929213,\n",
       "         -0.01879066, -0.1054332 ],\n",
       "        [-0.13207868,  0.26507822,  0.16091163, ...,  0.16006127,\n",
       "         -0.0591081 ,  0.14945468],\n",
       "        [ 0.1368999 , -0.23776431, -0.29792023, ..., -0.24292526,\n",
       "         -0.20827371,  0.19185981]], dtype=float32),\n",
       " array([-0.02135423, -0.04625409, -0.00918586, -0.08492517, -0.10977987,\n",
       "        -0.06615699,  0.03209835, -0.07421219,  0.00528813, -0.00527926,\n",
       "        -0.08374539, -0.10273897, -0.17481688,  0.03833312, -0.07534508,\n",
       "         0.03205657, -0.04702071, -0.09309217, -0.04426732, -0.07771089,\n",
       "         0.02413552, -0.04080836, -0.00118578, -0.12738676, -0.07959731,\n",
       "        -0.08297587, -0.06332724, -0.05643528, -0.1433544 , -0.0885532 ,\n",
       "        -0.07150471, -0.10265002], dtype=float32),\n",
       " array([[ 1.27407566e-01, -4.54500854e-01, -4.65431005e-01,\n",
       "         -3.98483783e-01, -1.12797558e-01, -1.89175978e-01,\n",
       "         -6.70599490e-02, -5.09940565e-01, -2.79437542e-01,\n",
       "          1.47107482e-01],\n",
       "        [-5.80213845e-01, -3.29714298e-01, -6.78134024e-01,\n",
       "         -6.85494542e-01,  1.76758811e-01, -6.64984584e-01,\n",
       "         -2.52989203e-01, -2.09249645e-01, -1.75119191e-01,\n",
       "         -1.99914008e-01],\n",
       "        [-9.21542108e-01, -2.13118985e-01, -2.38401100e-01,\n",
       "         -6.02319360e-01,  2.98144426e-02, -8.88039231e-01,\n",
       "         -5.20837784e-01, -1.85376778e-02, -6.05227053e-01,\n",
       "         -1.94023982e-01],\n",
       "        [-3.94126028e-01, -5.69984376e-01,  1.61977187e-01,\n",
       "         -5.21060750e-02, -4.75456983e-01,  1.90884605e-01,\n",
       "         -3.04423749e-01, -7.40519762e-02, -7.46781006e-02,\n",
       "          3.11362237e-01],\n",
       "        [ 1.81923628e-01, -3.99423331e-01, -2.41467342e-01,\n",
       "         -4.82007354e-01, -9.03164819e-02,  1.04024768e-01,\n",
       "          2.74295896e-01, -5.79036832e-01, -8.78290311e-02,\n",
       "         -1.01116568e-01],\n",
       "        [ 1.09621920e-01, -7.28791237e-01, -3.00091922e-01,\n",
       "          1.61298499e-01, -3.98846030e-01,  1.35369167e-01,\n",
       "          1.50561064e-01, -1.97500177e-02, -1.91395059e-01,\n",
       "         -4.74420875e-01],\n",
       "        [-3.14262927e-01, -6.61547244e-01, -5.32351613e-01,\n",
       "         -4.28234607e-01,  1.85641602e-01, -1.99298829e-01,\n",
       "          3.61645669e-02, -2.94131398e-01,  2.67461300e-01,\n",
       "          3.25262040e-01],\n",
       "        [-3.47163975e-01, -2.64736652e-01, -1.00281432e-01,\n",
       "          2.86630690e-01, -4.42678928e-01, -6.76023588e-02,\n",
       "          1.74176306e-01,  3.59048471e-02,  2.13809803e-01,\n",
       "         -3.19199771e-01],\n",
       "        [-4.79676515e-01, -2.90325671e-01, -4.81813759e-01,\n",
       "          2.70447671e-01,  1.02873042e-01,  2.42776498e-01,\n",
       "         -2.39154726e-01, -5.45423090e-01,  2.48803228e-01,\n",
       "          1.26696229e-01],\n",
       "        [ 2.68346697e-01, -4.37838852e-01, -8.75626802e-01,\n",
       "         -1.72005966e-01, -9.71214622e-02,  2.48118624e-01,\n",
       "          2.50797868e-01,  2.94002630e-02, -2.81310678e-01,\n",
       "         -3.15805644e-01],\n",
       "        [ 3.45204696e-02, -4.96654034e-01,  1.95051685e-01,\n",
       "          9.65080932e-02, -5.53510010e-01, -6.95084333e-01,\n",
       "         -8.14631820e-01,  2.61583384e-02,  1.41877343e-03,\n",
       "         -3.85826558e-01],\n",
       "        [-1.91529959e-01, -1.58142149e-01, -4.04848158e-01,\n",
       "         -2.85675198e-01,  2.12775543e-01,  1.93115801e-01,\n",
       "         -5.80313876e-02,  1.87905580e-01, -4.19396728e-01,\n",
       "         -1.11670524e-01],\n",
       "        [-8.62469971e-02,  1.30415753e-01,  2.39364788e-01,\n",
       "         -4.79954690e-01, -2.70009398e-01, -8.20332766e-01,\n",
       "          3.90202701e-02, -2.76529729e-01, -5.02708614e-01,\n",
       "         -3.70753556e-02],\n",
       "        [-7.13072941e-02, -3.80329788e-01,  1.23149730e-01,\n",
       "         -3.35967660e-01, -1.08764566e-01, -2.50935584e-01,\n",
       "         -7.87678957e-02, -2.93114811e-01,  8.55953470e-02,\n",
       "         -6.69419646e-01],\n",
       "        [ 3.65170464e-02,  1.38132453e-01, -5.91623597e-02,\n",
       "          1.84152171e-01,  7.95799419e-02, -1.88311785e-01,\n",
       "         -3.52075726e-01, -3.43792945e-01, -5.41242883e-02,\n",
       "         -7.70248100e-02],\n",
       "        [-6.05716586e-01, -7.54153877e-02, -3.26586753e-01,\n",
       "         -1.85792834e-01, -5.50821960e-01,  4.06144634e-02,\n",
       "         -4.69883054e-01, -7.25579560e-02,  2.12946646e-02,\n",
       "         -2.30542183e-01],\n",
       "        [-3.11662704e-01,  9.47439950e-03, -3.06407690e-01,\n",
       "         -4.07078892e-01, -8.89965370e-02,  2.42960185e-01,\n",
       "          3.21331173e-01, -3.48251194e-01, -8.91702191e-04,\n",
       "         -7.27384746e-01],\n",
       "        [-4.24058437e-01,  7.83889592e-02,  1.18536174e-01,\n",
       "         -2.29174733e-01, -2.43796613e-02, -2.01944128e-01,\n",
       "         -1.01028800e-01,  1.40855595e-01,  8.75343159e-02,\n",
       "         -1.55170083e-01],\n",
       "        [-4.05556172e-01,  1.09696440e-01, -1.55066237e-01,\n",
       "         -4.62933928e-01, -1.32589370e-01, -5.23061097e-01,\n",
       "         -3.97556335e-01, -3.71852279e-01,  1.78028733e-01,\n",
       "          2.73997813e-01],\n",
       "        [-7.68252090e-02,  3.30651045e-01, -6.36772990e-01,\n",
       "         -3.75614673e-01, -4.34979200e-01,  3.35281372e-01,\n",
       "         -6.44294262e-01, -4.82281625e-01, -2.19339132e-01,\n",
       "         -4.38530564e-01],\n",
       "        [ 2.18726724e-01,  2.17053056e-01, -1.31145775e-01,\n",
       "         -2.88281113e-01, -5.07624269e-01, -6.39085352e-01,\n",
       "         -5.24317622e-01, -4.75828558e-01,  1.80445462e-01,\n",
       "         -3.50950390e-01],\n",
       "        [ 1.30058840e-01, -4.07034606e-01, -6.00077391e-01,\n",
       "         -7.00824857e-01,  1.88179165e-01, -1.26659915e-01,\n",
       "         -4.37320292e-01,  1.00214537e-02, -4.02146399e-01,\n",
       "          9.91186723e-02],\n",
       "        [-5.90517759e-01,  3.93770412e-02,  1.73817836e-02,\n",
       "          2.46153921e-02, -2.12289959e-01, -3.49401444e-01,\n",
       "         -9.11083102e-01,  1.51411101e-01, -1.84397519e-01,\n",
       "          7.51807541e-02],\n",
       "        [-3.78223330e-01, -3.06955814e-01,  1.10068366e-01,\n",
       "          1.76696628e-01,  1.57597080e-01,  3.10719069e-02,\n",
       "          8.36942792e-02, -4.01649386e-01, -1.78719699e-01,\n",
       "          1.22235090e-01],\n",
       "        [ 2.79609174e-01,  2.35466272e-01,  6.82234764e-02,\n",
       "          9.59049314e-02, -1.44938096e-01, -1.96542218e-01,\n",
       "         -1.29295707e-01,  2.68397331e-01, -1.71027079e-01,\n",
       "          2.13853613e-01],\n",
       "        [ 2.70073026e-01,  2.31097952e-01, -1.86047226e-01,\n",
       "         -4.90964711e-01, -1.94462746e-01, -2.54908353e-01,\n",
       "          1.61645487e-01, -7.27114141e-01, -1.88151062e-01,\n",
       "         -2.82891572e-01],\n",
       "        [-1.20519526e-01, -7.09216177e-01, -1.42600499e-02,\n",
       "          1.80922121e-01, -1.54710636e-01,  1.02280490e-01,\n",
       "         -4.84027207e-01,  1.26827851e-01, -4.23364609e-01,\n",
       "         -1.36112183e-01],\n",
       "        [-1.05287600e+00, -4.56762731e-01, -2.45729908e-01,\n",
       "         -2.40742236e-01, -2.66856551e-01, -6.41841829e-01,\n",
       "         -7.75872171e-01,  2.71592975e-01, -3.27858508e-01,\n",
       "          3.36593479e-01],\n",
       "        [-2.95419842e-01, -5.92338145e-02,  2.44447872e-01,\n",
       "          2.85857590e-03, -5.12588680e-01, -3.69517326e-01,\n",
       "         -7.50805259e-01, -4.10589486e-01, -5.90687133e-02,\n",
       "         -2.99181998e-01],\n",
       "        [-3.91450018e-01,  1.39195323e-01,  1.41602322e-01,\n",
       "         -4.99831229e-01,  1.34166822e-01, -7.33485520e-01,\n",
       "         -3.56543344e-03, -5.47407288e-03, -4.83666301e-01,\n",
       "         -1.85582653e-01],\n",
       "        [-4.12084281e-01,  1.26688659e-01, -4.18157667e-01,\n",
       "         -6.62867665e-01, -5.80687188e-02,  1.08401410e-01,\n",
       "          1.90366924e-01, -4.48606640e-01,  7.79619021e-03,\n",
       "         -3.53593737e-01],\n",
       "        [ 2.65416175e-01, -2.39161760e-01, -2.83467233e-01,\n",
       "         -4.28354889e-01, -6.15261018e-01, -3.76808673e-01,\n",
       "          2.63661951e-01,  7.87850171e-02,  1.79750845e-01,\n",
       "         -1.21232912e-01]], dtype=float32),\n",
       " array([-0.10182696, -0.23151574, -0.1275374 ,  0.01071954, -0.16402288,\n",
       "        -0.03189652, -0.21966536, -0.04604431,  0.26697525,  0.18117398],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重みの所得\n",
    "model4.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# accracy可視化\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#loss可視化\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "#　valが最初から高いので過学習気味か？？"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
